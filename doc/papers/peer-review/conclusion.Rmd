# Conclusion and Future Work {-}

This article presented a new survey of authors of Systems conferences, looking at two peer-review policies and two diversity aspects.
Our data suggests that many conference variables and author experience metrics appear to be affected by the blindness policy of the conference. But on deeper examination, double-blind reviewing policies are often conflated with the academic reputation of a conference, which is worth keeping in mind when evaluating other results on peer review. The question of whether double-blind reviews contribute to the prestige of a conference (or are a consequence of it) remains open, and we plan to explore it in future work.

Most respondents found the opportunity to respond to reviewers very helpful, even if it did not change their review scores. The implication for PC chairs, and by extension, educators, may be that while a response process to technical feedback is of little value to experienced practitioners, novices do find it overwhelmingly helpful. Students are well-represented in this survey and their inputs could be be a useful data point to help address better this target audience in conferences and classrooms. In addition to the helpfulness of rebuttals, we confirmed that longer feedback is generally perceived as more helpful, understanding, and fair, which in turn may serve as another factor in improving students' experience.

Women represent an alarmingly small group of authors in Systems research, and this paper looked at whether the peer-review process plays a role in this underrepresentation, as has been found in some grant and job evaluations. For female authors of accepted papers, we found that their papers tend to have a slightly longer history. But we found little evidence of negative effects in the reviews they receive or the experience they perceive, even when their identity is known to the reviewers. Non-native English speakers also show no specific adverse effects from peer review, and in fact often report more positively on their experiences than native speakers. These two negative results can help focus the diversity effort on other policies.


This dataset remains rich for exploration of the many questions that fell outside the scope of this paper. Some of the questions we plan to address in future work include:

* Why is the representation of women in Systems so low?

* What other publication differences and commonalities exist between Systems and the rest of CS?

* How do review grade correlate across categories?

* How might reviewer workload affect our results?

* How do any of these factors affect the eventual success of a paper, as measured by awards or citations?

* How do we correct for, or address, the survivorship bias, so that the voices of rejected papers' authors can be incorporated into this data?
