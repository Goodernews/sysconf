# Methodology and Data {#sec:data}

In addition to the main survey, described in the next section, we collected data from various external sources to complement and corroborate the survey findings, starting with the conferences themselves. We selected `r nrow(all_confs)` conferences from the systems and related areas. These peer-reviewed conferences include some of the most prestigious in the field, as well as others for comparison. They vary in scope and in size (from 7 to 151 papers), but all are rigorously peer-reviewed and all are from 2017.^[The conferences in our set are known by these short names:
ASPLOS,
ATC,
CCGrid,
CCS,
CIDR,
CLOUD,
Cluster,
CoNEXT,
EuroPar,
EuroSys,
FAST,
HCW,
HiPC,
HotCloud,
HotI,
HotOS,
HotStorage,
HPCA,
HPCC,
HPDC,
ICAC,
ICDM,
ICPE,
ICPP,
IGSC,
IISWC,
IMC,
IPDPS,
ISC,
ISCA,
ISPASS,
KDD,
MASCOTS,
MICRO,
Middleware,
MobiCom,
NDSS,
NSDI,
OOPSLA,
PACT,
PLDI,
PODC,
PODS,
PPoPP,
SC,
SIGCOMM,
SIGIR,
SIGMETRICS,
SIGMOD,
SLE,
SOCC,
SOSP,
SP,
SPAA,
SYSTOR,
and VEE.]

For each conference we collected data from the web, including review policies, important dates, the composition of its technical program committee (PC), the number of submitted papers, and some historical metrics from the web sites of IEEE, ACM, and Google Scholar, such as past citations, age, and total publications. We filled some missing data from direct conversations with PC chairs, and downloaded all `r nrow(papers)` papers. From the conference and paper text, we compiled the complete list of authors for all `r nrow(all_confs)` conferences (a total of `r nrow(authors)` unique persons), as well as their email addresses. These addresses not only served for the survey's distribution, but also to infer an author's affiliation, sector, and country of residence. If an email address was not shown in the paper, we attempted to infer authors' affiliation from their Google Scholar (GS) profile, when uniquely identifiable. These profiles also provide indirect metrics on author's research experience, such as their H-index [@hirsch05:index]. Finally, we also manually verified the gender of `r pct(nrow(filter(authors, !is.na(gender))), nrow(authors))`% of authors, by looking up their photos and pronouns on the web.^[We recognize that gender is a complex, non-binary identity that cannot be captured adequately by just photos or pronouns. However, the focus of this study is on perceived gender, not self-identification, which is often judged by the same simplistic criteria as photos and pronouns.]


## Limitations {-}

Our methodology involves several limitations and tradeoffs that we address throughout the paper. First, by focusing only on computer systems, we may be limiting the applicability of our findings to this subfield. By focusing on a single year, we cannot report trends. These choices were deliberate, so as to eliminate extraneous variability in our data. Our survey is also subject to survivorship bias (by polling only authors of accepted papers, since we have no information on all submitted papers) and selection bias (representing only authors who responded to the survey and/or each question). As Sec. \@ref(sec:survey) details, we believe the effect of either bias is benign (see also [@daume15:naacl; @papagiannaki07:author]). Finally, the effort involved in compiling all the data in the preparation for the survey took nearly a year, by which time some authors had difficulty recalling some details, ang generally lead to fewer responses.
