Computer Science researchers rely on peer-reviewed conferences to publish their work and to receive feedback on it.
The influence of the peer-review process on authors can hardly be overstated. Yet conferences and their organizers can make inconsistent or unpredictable choices in their review process, even in the same subfield. These choices are rarely reviewed critically, and when they are, the emphasis revolves around the effects on the technical program. Rarely is the effect on authors analyzed, despite the high stakes involved.

This paper attempts to shed some light on the conference author's perspective, by focusing on a cross-sectional study of 56 conferences from one large subfield of computer science, namely computer systems. We introduce a large author survey (n=918), representing 810 unique papers. This data is combined with information we collected on author demographics, conference policies, and paper statistics. Our quantitative analysis looks specifically at two policies in the peer-review process, double-blind reviews and author rebuttals, and how they interact with gender diversity, English skills, and reputation metrics.

Our results point to no specific evidence of bias in single-blind reviews against women or non-native speakers. They do, however, expose some of the differences in the experience of these populations. Our survey also found strong support for author response to reviewers' comments, especially among students and less experienced researchers, which may have implications for educators.