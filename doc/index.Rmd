---
title: "Statistical Observations of Systems Papers"
author: "Eitan Frachtenberg"
date: "`r Sys.Date()`"
csl: acm-sig-proceedings-long-author-list.csl
bibliography: sysconf.bib
documentclass: book
github-repo: eitanf/sysconf
link-citations: yes
site: bookdown::bookdown_site
biblio-style: acm
---

# Introduction {#ch:intro}

<!-- Build with: rmarkdown::render_site(output_format = "bookdown::html_book", encoding = "UTF-8") -->
<!-- Or rebuild with: -->
<!-- setwd("~/Dropbox/code/sysconf/doc"); bookdown::clean_book(); bookdown::render_book("index.Rmd", "bookdown::gitbook") -->



What makes a research publication stand out?

What makes a journal or conference reputable?

What contributes to an author's publication record?

Almost every scientist has been curious about questions like these at one time or another. And yet much to our frustration, we can't answer them scientifically, because we don't have accurate metrics to measure them by. And even if we did, we wouldn't be able to measure them, because controlled experiments on the publication process are all but impossible.

Instead, what this document attempts to do is to address these questions through the observation of multi-dimensional data. The data has been collected from fifty well-known conferences in the computer systems field throughout 2017. It includes nearly every aspect of the publication process: conference statistics, author statistics, paper metrics, textual analysis, citation graphs, and many more.

The sheer volume and detail of the data reveal some interesting insights about publications in this specific area, and perhaps more broadly as well. The next section lists some of these high-level insights, while the rest of this document delves into the methods and the analysis in much greater detail. It starts with a precise description of both the complete data set that was collected in Chapter \@ref(ch:data), and follows with a description of all derived metrics and variables ("features") in Chapter \@ref(ch:features). I suggest you at least skim both of these chapters to get an understanding of the data collected, and the possible relationships and questions that could arise from it.

The rest of the chapters each deal with a cohesive subset of questions. For example, Chapter \@ref(ch:confs) attempts to measure and compare various metrics of conference "quality", while Chapter \@ref(ch:papers) does the same for individual papers. Although these chapters appear in sequence with later chapters sometimes referring to previous data, feel free to read these out of order or jump straight to the topic that interests you the most. You'll find links to any prerequisite analysis from previous chapters.

TBD: brief description of the content of chapters?

## Research in Computer Systems {-}

In this study we’ll be focusing almost exclusively on a single field of study, *computer systems*. Computer Systems (aka ‘*Systems*’) is the field that deals, in a nutshell, with building programs that use a lot of resources and profiling that resource usage. Computer systems is a large and rapidly evolving field in computer science. This field stands out from other areas of computer science in some key characteristics. It emphasizes scientific exploration through system implementation, and combines a unique blend of mathematical rigor, simulation science, and technical engineering. 

Systems work includes building operating systems, computer architectures, databases, parallel and distributed computing, and networking among others. It is a highly practical field, focused on implementation and understanding what kinds of usage a system will be able to handle. As Craig Partridge writes [@partridge:accepted]:

> "The classic systems paper presents an implementation or planned implementation. The implementation can be in software or hardware or both. The implementation's contribution is usually that it either achieves some new function, never before achieved, or it realizes an existing function more efficiently or effectively than previously."

Because of the applicability of systems work and its rapid pace of development, peer-reviewed conferences hold a special role in scholarly publication. System practitioners often prefer to publish their best work in a conference with a turn-around time of a few months, compared to a few years in some top systems journals [@patterson99:evaluating]. Thus, conference publication takes the lead role in describing innovative research, while journals are often delegated to archival purposes [@vrettas15:conferences]. This is why we chose to focus on the conference publication process in systems.

Specifically, we focus on an expansive, but nevertheless selective, longitudinal set of systems conferences from 2017, all employing a rigorous peer-review process to select their papers (with typical acceptance rates in the vicinity of 20%). We collected statistics about every conference, every peer-reviewed paper in it, and every co-author of every paper. By combinining statistics from all these angles, we are able to explore hundreds of aspects of the field of computer systems, as reflected through its research papers.


## Result Highlights {-}

<!--- These are all correlations. Causation is never implied, unless specifically stated. --->

Add links to sections for each result

Each chapter (starting from Ch. \@ref(ch:confs)) starts with a list of some of the interesting questions in the chapter. Feel free to skip around from chapter to chapter, review the highlights and questions, and then dive deeper into the details of interest to you.

## Reproducibility {-}

`r gh_repo<-"https://github.com/eitanf/sysconf"`

Reproducibility and replication in research is a cornerstone of the scientific method. There's an entire chapter (\@ref(ch:repro)) dedicated to reproducibility in computer systems here. Accordingly, this study also attempts to replicate or approximate numerous past results and assumptions about the publication and peer-review process (and refers to the original results when possible). These results not always be novel, but with reproducibility, that's exactly the point!

It is only fitting then that we would also make every attempt to provide as much data and source code as necessary to reproduce all the results in this analysis [@gandrud13:reproducible]. The complete data, ETL scripts, and analysis code for this document can be found at `r gh_repo`. This document (which itself includes the analysis source code) is included in the repository and is formatted with the Bookdown [@xie16:bookdown] and knitr [@xie14:knitr] R packages.

Every data file or directory has a corresponding markdown file describing it. It resides in the same directory as the data file or sub-directory, and has the same name, with a .md extension.
The description file details the field descriptions and types, as well as the source script that generated it, the git hash of version that generated it, and the location in the source code that generated each field. This information is reproduced in the next two chapters.

The R analysis code embedded in this document ran with the following R session information:

```{r echo=F, warning=F}
source('dependencies.R')
sessionInfo(package = dependencies)
```

## Acknowledgements {-}

<!--
  grants: social justice, dean
  students: Revant Bagaria, Henry Blancheette, Tanmay Dubey, Jillian James, Rhody Kaner, Noah Koster, Joshua Reiss
  feedback:
  The many authors, PC chairs, and other conference organizers who helped with survey responses, suggestions, and feedback.

<!--
## Call for contributions {-}

If you're an author on one or more of these papers, kindly consider improving this data set by sending me (privately) a copy of the paper's review, or participating in the author survey. Your data will be aggregated with the existing set, preserving no personally identifying information.

Please contact me at eitan@reed.edu for details.
-->

## License {-}

Copyright 2017--2019. This work is licensed under [CC-BY-SA 4.0](https://creativecommons.org/licenses/by-sa/4.0/legalcode).
