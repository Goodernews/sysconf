

In this paper, we show that key-value stores backed by an LSM-tree
exhibit an intrinsic trade-off between lookup cost, update cost, and
main memory footprint, yet all existing designs expose a suboptimal and difficult to tune trade-off among these metrics. We pinpoint the problem to the fact that all modern key-value stores suboptimally co-tune the merge policy, the buffer size, and the Bloom
filters’ false positive rates in each level.

We present Monkey, an LSM-based key-value store that strikes
the optimal balance between the costs of updates and lookups with
any given main memory budget. The insight is that worst-case
lookup cost is proportional to the sum of the false positive rates
of the Bloom filters across all levels of the LSM-tree. Contrary
to state-of-the-art key-value stores that assign a fixed number of
bits-per-element to all Bloom filters, Monkey allocates memory
to filters across different levels so as to minimize this sum. We
show analytically that Monkey reduces the asymptotic complexity of the worst-case lookup I/O cost, and we verify empirically
using an implementation on top of LevelDB that Monkey reduces
lookup latency by an increasing margin as the data volume grows
(50% — 80% for the data sizes we experimented with). Furthermore, we map the LSM-tree design space onto a closed-form model
that enables co-tuning the merge policy, the buffer size and the filters’ false positive rates to trade among lookup cost, update cost
and/or main memory, depending on the workload (proportion of
lookups and updates), the dataset (number and size of entries), and
the underlying hardware (main memory available, disk vs. flash).
We show how to use this model to answer what-if design questions about how changes in environmental parameters impact performance and how to adapt the various LSM-tree design elements
accordingly.

