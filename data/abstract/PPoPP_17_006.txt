
We explore a programming approach for concurrency that
synchronizes all accesses to shared memory by default. Synchronization takes place by ensuring that all program code
runs inside atomic sections even if the program code has external side effects. Threads are mapped to atomic sections
that a programmer must explicitly split to increase concurrency.

A naive implementation of this approach incurs a large
amount of overhead. We show how to reduce this overhead
to make the approach suitable for realistic application programs on existing hardware. We present an implementation
technique based on a special-purpose software transactional
memory system. To reduce the overhead, the technique exploits properties of managed, object-oriented programming
languages as well as intraprocedural static analyses and uses
field-level granularity locking in combination with transactional I/O to provide good scaling properties.

We implemented the synchronized-by-default (SBD) approach for the Java language and evaluate its performance
for six programs from the DaCapo benchmark suite. The
evaluation shows that, compared to explicit synchronization,
the SBD approach has an overhead between 0.4% and 102%
depending on the benchmark and the number of threads,
with a mean (geom.) of 23.9%.
