

Database management system (DBMS) configuration tuning is an
essential aspect of any data-intensive application effort. But this
is historically a difficult task because DBMSs have hundreds of
configuration “knobs” that control everything in the system, such
as the amount of memory to use for caches and how often data
is written to storage. The problem with these knobs is that they
are not standardized (i.e., two DBMSs use a different name for the
same knob), not independent (i.e., changing one knob can impact
others), and not universal (i.e., what works for one application may
be sub-optimal for another). Worse, information about the effects
of the knobs typically comes only from (expensive) experience.

To overcome these challenges, we present an automated approach
that leverages past experience and collects new information to tune
DBMS configurations: we use a combination of supervised and unsupervised machine learning methods to (1) select the most impactful knobs, (2) map unseen database workloads to previous workloads from which we can transfer experience, and (3) recommend
knob settings. We implemented our techniques in a new tool called
OtterTune and tested it on three DBMSs. Our evaluation shows that
OtterTune recommends configurations that are as good as or better
than ones generated by existing tools or a human expert.

