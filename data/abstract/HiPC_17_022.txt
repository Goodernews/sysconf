
Tight data movement lower bounds are known for
dense matrix-vector multiplication and dense matrix-matrix
multiplication and practical implementations exist on GPUs
that achieve performance quite close to the roofline bounds
based on operational intensity. For large dense matrices,
matrix-vector multiplication is bandwidth-limited and its performance is significantly lower than matrix-matrix multiplication. However, in contrast, the performance of sparse matrixmatrix multiplication (SpGEMM) is generally much lower than
that of sparse matrix-vector multiplication (SpMV).

In this paper, we use a combination of lower-bounds and
upper-bounds analysis of data movement requirements, as well
as hardware counter based measurements to gain insights into
the performance limitations of existing implementations for
SpGEMM on GPUs. The analysis motivates the development
of an adaptive work distribution strategy among threads and
results in performance enhancement for SpGEMM code on
GPUs.

