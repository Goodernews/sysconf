

Simplifying the task of resource management and scheduling for
customers, while still delivering complex Quality-of-Service (QoS),
is key to cloud computing. Many autoscaling policies have been
proposed in the past decade to decide on behalf of cloud customers
when and how to provision resources to a cloud application utilizing
cloud elasticity features. However, in prior work, when a new policy
is proposed, it is seldom compared to the state-of-the-art, and is often
compared only to static provisioning using a predefined QoS target.
This reduces the ability of cloud customers and of cloud operators to
choose and deploy an autoscaling policy. In our work, we conduct an
experimental performance evaluation of autoscaling policies, using
as application model workflows, a commonly used formalism for
automating resource management for applications with well-defined
yet complex structure. We present a detailed comparative study of
general, state-of-the-art, generic autoscaling policies, along with
two new workflow-specific policies. To understand the performance
differences between the 7 policies, we conduct various forms of
pairwise and group comparisons. We report both individual and
aggregated metrics. Our results highlights the trade-offs between
the suggested policies, and thus enable a better understanding of the
current state-of-the-art.

