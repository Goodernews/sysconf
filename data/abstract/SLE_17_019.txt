

Crowdsourcing has emerged as a novel paradigm where humans are employed to perform computational tasks. In the
context of Domain-Specific Modeling Language (DSML) development, where the involvement of end-users is crucial
to assure that the resulting language satisfies their needs,
crowdsourcing tasks could be defined to assist in the language definition process. By relying on the crowd, it is possible to show an early version of the language to a wider
spectrum of users, thus increasing the validation scope and
eventually promoting its acceptance and adoption. We propose a systematic method for creating crowdsourcing campaigns aimed at refining the graphical notation of DSMLs.
The method defines a set of steps to identify, create and
order the questions for the crowd. As a result, developers
are provided with a set of notation choices that best fit endusersâ€™ needs. We also report on an experiment validating the
approach.
