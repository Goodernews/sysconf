
The onset of cloud computing has brought about computing power that can be provisioned and released on-demand.
This capability has drastically increased the complexity of
workload and resource management for database applications. Existing solutions rely on query latency prediction
models, which are notoriously inaccurate in cloud environments. We argue for a substantial shift away from query
performance prediction models and towards machine learning techniques that directly model the monetary cost of
using cloud resources and processing query workloads on
them. Towards this end, we sketch the design of a learningbased service for IaaS-deployed data management applications that uses reinforcement learning to learn, over time,
low-cost policies for provisioning virtual machines and dispatching queries across them. Our service can effectively
handle dynamic workloads and changes in resource availability, leading to applications that are continuously adaptable,
cost effective, and performance aware. In this paper, we discuss several challenges involved in building such a service,
and we present results from a proof-of-concept implementation of our approach.

