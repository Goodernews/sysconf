

Implementing parallel operators in multicore machines often involves a data partitioning step that divides the data
into cache-size blocks and arranges them so to allow concurrent threads to process them in parallel. Data partitioning
is expensive, in some cases up to 90% of the cost of, e.g.,
a parallel hash join. In this paper we explore the use of an
FPGA to accelerate data partitioning. We do so in the context of new hybrid architectures where the FPGA is located
as a co-processor residing on a socket and with coherent access to the same memory as the CPU residing on the other
socket. Such an architecture reduces data transfer overheads
between the CPU and the FPGA, enabling hybrid operator
execution where the partitioning happens on the FPGA and
the build and probe phases of a join happen on the CPU.
Our experiments demonstrate that FPGA based partitioning is significantly faster and more robust than CPU based
partitioning. The results open interesting options as FPGAs
are gradually integrated tighter with the CPU.

