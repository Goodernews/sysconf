

Learning novel relations from relational databases is an important
problem with many applications. Relational learning algorithms
learn the definition of a new relation in terms of existing relations in
the database. Nevertheless, the same database may be represented
under different schemas for various reasons, such as data quality,
efficiency and usability. The output of current relational learning algorithms tends to vary quite substantially over the choice of
schema. This variation complicates their off-the-shelf application.
We introduce and formalize the property of schema independence
of relational learning algorithms, and study both the theoretical and
empirical dependence of existing algorithms on the common class
of (de) composition schema transformations. We show that current
algorithms are not schema independent. We propose Castor, a relational learning algorithm that achieves schema independence by
leveraging data dependencies.

