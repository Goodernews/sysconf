

Reusing intermediates in databases to speed-up analytical
query processing was studied in prior work. Existing solutions require intermediate results of individual operators
to be materialized using materialization operators. However, inserting such materialization operations into a query
plan not only incurs additional execution costs but also often
eliminates important cache- and register-locality opportunities, resulting in even higher performance penalties. This
paper studies a novel reuse model for intermediates, which
caches internal physical data structures materialized during
query processing (due to pipeline breakers) and externalizes
them so that they become reusable for upcoming operations.
We focus on hash tables, the most commonly used internal
data structure in main memory databases to perform join
and aggregation operations. As queries arrive, our reuseaware optimizer reasons about the reuse opportunities for
hash tables, employing cost models that take into account
hash table statistics together with the CPU and data movement costs within the cache hierarchy. Experimental results,
based on our prototype implementation, demonstrate performance gains of 2x for typical analytical workloads with
no additional overhead for materializing intermediates.

