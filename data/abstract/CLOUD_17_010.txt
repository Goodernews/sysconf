
Mining big data often requires tremendous
computational resources. This has become a major obstacle to
broad applications of big data analytics. Cloud computing
allows data scientists to access computational resources ondemand for building their big data analytics solutions in the
cloud. However, the monetary cost of mining big data in the
cloud can still be unexpectedly high. For example, running 100
m4-xlarge Amazon EC2 instances for a month costs
approximately $17,495.00. On this ground, it is a critical issue
to analyze the cost effectiveness of big data mining in the cloud,
i.e, how to achieve a sufficiently satisfactory result at the
lowest possible computation cost. In certain big data mining
scenarios, 100% accuracy is unnecessary. Instead, it is often
more preferable to achieve a sufficient accuracy, e.g., 99%, ata
much lower cost, e.g., 10%, than the cost of achieving the
100% accuracy. In this paper, we explore and demonstrate the
cost effectiveness of big data mining with a case study using
well known k-means. With the case study, we find that
achieving 99% accuracy only needs 0.32%-46.17%
computation cost of 100% accuracy. This finding lays the
cornerstone for cost-effective big data mining in a variety of
domains.

Keywords-Cloud Computing; Data Mining; Cost-Effective; Big
Data; K-Means

