
In this paper, we present a methodology to understand GPU
microarchitectural features and improve performance for
compute-intensive kernels. The methodology relies on a
reverse engineering approach to crack the GPU ISA encodings in order to build a GPU assembler. An assembly
microbenchmark suite correlates microarchitectural features
with their performance factors to uncover instruction-level
and memory hierarchy preferences. We use SGEMM as a
running example to show the ways to achieve bare-metal
performance tuning. The performance boost is achieved by
tuning FFMA throughput by activating dual-issue, eliminating
register bank conflicts, adding non-FFMA instructions with
little penalty, and choosing proper width of global/shared
load instructions. On NVIDIA Kepler K20m, we develop a
faster SGEMM with 3.1Tflop/s performance and 88% efficiency; the performance is 15% higher than cuBLAS7.0.
Applying these optimizations to convolution, the implementation gains 39%-62% performance improvement compared
with cuDNN4.0. The toolchain is an attempt to automatically crack different GPU ISA encodings and build an assembler adaptively for the purpose of performance enhancements to applications on GPUs.
