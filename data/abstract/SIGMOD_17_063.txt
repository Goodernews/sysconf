

Error detection is the process of identifying problematic data
cells that are different from their ground truth. Functional
dependencies (FDs)} have been widely studied in support of
this process. Oftentimes, it is assumed that FDs are given
by experts. Unfortunately, it is usually hard and expensive
for the experts to define such FDs. In addition, automatic
data profiling over dirty data in order to find correct FDs
is known to be a hard problem. In this paper, we propose
an end-to-end solution to detect FD-detectable errors from
dirty data. The broad intuition is that given a dirty dataset,
it is feasible to automatically find approximate FDs, as well
as data that is possibly erroneous. Arguably, at this point,
only experts can confirm true FDs or true errors. However,
in practice, experts never have enough budget to find all
errors. Hence, our problem is, given a limited budget of
expertâ€™s time, which questions we should ask, either FDs,
cells, or tuples, such that we can find as many data errors as
possible. We present efficient algorithms to interact with the
user. Extensive experiments demonstrate that our proposed
framework is effective in detecting errors from dirty data.

