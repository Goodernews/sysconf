
File systems must allocate space for files without
knowing what will be added or removed in the future.
Over the life of a file system, this may cause suboptimal file placement decisions which eventually lead to
slower performance, or aging. Traditional file systems
employ heuristics, such as collocating related files and
data blocks, to avoid aging, and many file system implementors treat aging as a solved problem.

However, this paper describes realistic as well as synthetic workloads that can cause these heuristics to fail,
inducing large performance declines due to aging. For
example, on ext4 and ZFS, a few hundred git pull operations can reduce read performance by a factor of 2;
performing a thousand pulls can reduce performance by
up to a factor of 30. We further present microbenchmarks
demonstrating that common placement strategies are extremely sensitive to file-creation order; varying the creation order of a few thousand small files in a real-world
directory structure can slow down reads by 15 — 175 x,
depending on the file system.

We argue that these slowdowns are caused by poor layout. We demonstrate a correlation between read performance of a directory scan and the locality within a file
system’s access patterns, using a dynamic layout score.

In short, many file systems are exquisitely prone to
read aging for a variety of write workloads. We show,
however, that aging is not inevitable. BetrFS, a file system based on write-optimized dictionaries, exhibits almost no aging in our experiments. BetrFS typically outperforms the other file systems in our benchmarks; aged
BetrFS even outperforms the unaged versions of these
file systems, excepting Btrfs. We present a framework
for understanding and predicting aging, and identify the
key features of BetrFS that avoid aging.
