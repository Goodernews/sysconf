
Computer systems are increasingly featuring powerful parallel devices with the advent of many-core CPUs and GPUs.
This offers the opportunity to solve computationally-intensive
problems at a fraction of the time traditional CPUs need.
However, exploiting heterogeneous hardware requires the
use of low-level programming language approaches such as
OpenCL, which is incredibly challenging, even for advanced
programmers.

On the application side, interpreted dynamic languages
are increasingly becoming popular in many domains due to
their simplicity, expressiveness and flexibility. However, this
creates a wide gap between the high-level abstractions offered to programmers and the low-level hardware-specific
interface. Currently, programmers must rely on high performance libraries or they are forced to write parts of their application in a low-level language like OpenCL. Ideally, nonexpert programmers should be able to exploit heterogeneous
hardware directly from their interpreted dynamic languages.

In this paper, we present a technique to transparently
and automatically offload computations from interpreted dynamic languages to heterogeneous devices. Using just-intime compilation, we automatically generate OpenCL code
at runtime which is specialized to the actual observed data
types using profiling information. We demonstrate our technique using R, which is a popular interpreted dynamic language predominately used in big data analytic. Our experimental results show the execution on a GPU yields speedups
of over 150x compared to the sequential FastR implementation and the obtained performance is competitive with manually written GPU code. We also show that when taking into
account start-up time, large speedups are achievable, even
when the applications run for as little as a few seconds.

