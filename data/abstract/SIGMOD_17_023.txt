

In domains such as the Web, sensor networks and social
media, sources often provide conflicting information for the
same data item. Several data fusion techniques have been
proposed recently to resolve conflicts and identify correct
data. The performance of these fusion systems, while quite
accurate, is far from perfect. In this paper, we propose
to leverage user feedback for validating data conflicts and
rapidly improving the performance of fusion. To present the
most beneficial data items for the user to validate, we take
advantage of the level of consensus among sources, and the
output of fusion to generate an effective ordering of items.
We first evaluate data items individually, and then define a
novel decision-theoretic framework based on the concept of
value of perfect information (VPI) to order items by their
ability to boost the performance of fusion. We further derive approximate formulae to scale up the decision-theoretic
framework to large-scale data. We empirically evaluate our
algorithms on three real-world datasets with different characteristics, and show that the accuracy of fusion can be
significantly improved even while requesting feedback on a
few data items. We also show that the performance of the
proposed methods depends on the characteristics of data,
and assess the trade-off between the amount of feedback acquired, and the effectiveness and efficiency of the methods.

