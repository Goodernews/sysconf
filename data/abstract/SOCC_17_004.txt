

Graph analytics systems have gained significant popularity due to
the prevalence of graph data. Many of these systems are designed to
run in a shared-nothing architecture whereby a cluster of machines
can process a large graph in parallel. In more recent proposals,
others have argued that a single-machine system can achieve better
performance and/or is more cost-effective. There is however no
clear consensus which approach is better. In this paper, we classify
existing graph analytics systems into four categories based on the
architectural differences, i.e., processing infrastructure (centralized
vs distributed), and memory consumption (in-memory vs out-ofcore). We select eight open-source systems to cover all categories,
and perform a comparative measurement study to compare their
performance and cost characteristics across a spectrum of input
data, applications, and hardware settings. Our results show that
the best performing configuration can depend on the type of applications and input graphs, and there is no dominant winner across
all categories. Based on our findings, we summarize the trends in
performance and cost, and provide several insights that help to illuminate the performance and resource cost tradeoffs across different
graph analytics systems and categories.
