

In today’s data analytics frameworks, many users struggle
to reason about the performance of their workloads. Without an understanding of what factors are most important to
performance, users can’t determine what configuration parameters to set and what hardware to use to optimize runtime.
This paper explores a system architecture designed to make
it easy for users to reason about performance bottlenecks.
Rather than breaking jobs into tasks that pipeline many resources, as in today’s frameworks, we propose breaking jobs
into monotasks: units of work that each use a single resource.
We demonstrate that explicitly separating the use of different
resources simplifies reasoning about performance without
sacrificing performance. Monotasks provide job completion
times within 9% of Apache Spark for typical scenarios, and
lead to a model for job completion time that predicts runtime under different hardware and software configurations
with at most 28% error. Furthermore, separating the use of
different resources allows for new optimizations to improve
performance.
