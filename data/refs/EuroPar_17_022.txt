[1] Austin, W., Ballard, G., Kolda, T.G.: Parallel tensor compression for large-scale

scientiﬁc data. In: International Parallel and Distributed Processing Symposium

(IPDPS’17), pp. 912–922. IEEE (2016)

[2] Baskaran, M., Meister, B., Vasilache, N., Lethin, R.: Eﬃcient and scalable computations with sparse tensors. In: 2012 IEEE Conference on High Performance

Extreme Computing (HPEC), pp. 1–6. IEEE (2012)

[3] Bennett, J., Lanning, S.: The netﬂix prize. In: Proceedings of KDD cup and workshop, vol. 2007, p. 35 (2007)

[4] Carlson, A., Betteridge, J., Kisiel, B., Settles, B., Hruschka, E.R., Mitchell, T.M.:

Toward an architecture for never-ending language learning. In: In AAAI (2010)

[5] Chakaravarthy, V.T., Choi, J.W., Joseph, D.J., Liu, X., Murali, P., Sabharwal, Y.,

Sreedhar, D.: On optimizing distributed tucker decomposition for dense tensors. In:

31st IEEE International Parallel and Distributed Processing Symposium (IPDPS

2017) (2017)

[6] Chi, E.C., Kolda, T.G.: On tensors, sparsity, and nonnegative factorizations. SIAM

J. Matrix Anal. Appl. 33(4), 1272–1299 (2012)

[7] De Lathauwer, L., De Moor, B., Vandewalle, J.: A multilinear singular value decomposition. SIAM J. Matrix Anal. Appl. 21(4), 1253–1278 (2000a)

[8] De Lathauwer, L., De Moor, B., Vandewalle, J.: On the best rank-1 and rank-(r

1, r 2,., rn) approximation of higher-order tensors. SIAM J. Matrix Anal. Appl.

21(4), 1324–1342 (2000b)

[9] Fanaee-T, H., Gama, J.: Tensor-based anomaly detection: an interdisciplinary survey. Knowl.-Based Syst. 98, 130–147 (2016)

[10]  Grasedyck, L.: Hierarchical singular value decomposition of tensors. SIAM J.

Matrix Anal. Appl. 31(4), 2029–2054 (2010)

[11]  Kaya, O., Uçar, B.: High-performance parallel algorithms for the tucker decomposition of higher order sparse tensors. Technical report (2015a)

[12]  Kaya, O., Uçar, B.: Scalable sparse tensor decompositions in distributed memory

systems. In: Proceedings of the International Conference for High Performance

Computing, Networking, Storage and Analysis, p. 77. ACM (2015b)

[13]  Kaya, O., Uçar, B.: Parallel CP decomposition of sparse tensors using dimension

trees. Research report RR-8976, Inria - Research Centre Grenoble - Rhône-Alpes,

November 2016

[14]  Kolda, T.G., Bader, B.W.: Tensor decompositions and applications. SIAM Rev.

51(3), 455–500 (2009)

[15]  Kolda, T.G., Sun, J.: Scalable tensor decompositions for multi-aspect data mining.

In: 2008 Eighth IEEE International Conference on Data Mining, ICDM 2008, pp.

363–372. IEEE (2008)

[16]  Li, J., Battaglino, C., Perros, I., Sun, J., Vuduc, R.: An input-adaptive and inplace approach to dense tensor-times-matrix multiply. In: Proceedings of the International Conference for High Performance Computing, Networking, Storage and

Analysis, p. 76. ACM (2015)

[17]  Li, J., Ma, Y., Yan, C., Vuduc, R.: Optimizing sparse tensor times matrix on

multi-core and many-core architectures. In: Proceedings of the Sixth Workshop

on Irregular Applications: Architectures and Algorithms, pp. 26–33. IEEE Press

(2016)

[18]  Rolinger, T.B., Simon, T.A., Krieger, C.D.: Performance evaluation of parallel

sparse tensor decomposition implementations. In: Proceedings of the 6th Workshop

on Irregular Applications: Architectures and Algorithms. IEEE (2016)

[19]  Shetty, J., Adibi, J.: The enron email dataset database schema and brief statistical

report. Information Sciences Institute Technical report 4, University of Southern

California (2004)

[20]  Shi, Y., Karatzoglou, A., Baltrunas, L., Larson, M., Hanjalic, A., Oliver, N.:

TFMAP: optimizing MAP for top-n context-aware recommendation. In: Proceedings of the 35th international ACM SIGIR Conference on Research and Development in Information Retrieval, pp. 155–164. ACM (2012)

[21]  Smith, S., Choi, J.W., Li, J., Vuduc, R., Park, J., Liu, X., Karypis, G.: FROSTT:

the formidable repository of open sparse tensors and tools (2017a). http://frostt.io/

[22]  Smith, S., Karypis, G.: Tensor-matrix products with a compressed sparse tensor.

In: 5th Workshop on Irregular Applications: Architectures and Algorithms (2015)

[23]  Smith, S., Karypis, G.: SPLATT: The Surprisingly ParalleL spArse Tensor Toolkit

(2016). http://cs.umn.edu/splatt/

[24]  Smith, S., Park, J., Karypis, G.: An exploration of optimization algorithms for high

performance tensor completion. In: Proceedings of the 2016 ACM/IEEE conference

on Supercomputing (2016)

[25]  Smith, S., Park, J., Karypis, G.: Sparse tensor factorization on many-core processors with high-bandwidth memory. In: 31st IEEE International Parallel & Distributed Processing Symposium (IPDPS 2017) (2017b)

[26]  Smith, S., Ravindran, N., Sidiropoulos, N.D., Karypis, G.: SPLATT: eﬃcient and

parallel sparse tensor-matrix multiplication. In: International Parallel and Distributed Processing Symposium (IPDPS 2015) (2015)

[27]  Subramanian, A., Tamayo, P., Mootha, V.K., Mukherjee, S., Ebert, B.L., Gillette,

M.A., Paulovich, A., Pomeroy, S.L., Golub, T.R., Lander, E.S., et al.: Gene set

enrichment analysis: a knowledge-based approach for interpreting genome-wide

expression proﬁles. Proc. Nat. Acad. Sci. 102(43), 15545–15550 (2005)

[28]  Sun, J.T., Zeng, H.J., Liu, H., Lu, Y., Chen, Z.: Cubesvd: a novel approach to

personalized web search. In: Proceedings of the 14th International Conference on

World Wide Web, pp. 382–390. ACM (2005)

[29]  Wang, Y., Chen, R., Ghosh, J., Denny, J.C., Kho, A., Chen, Y., Malin, B.A., Sun,

J.: Rubik: knowledge guided tensor factorization and completion for health data

analytics. In: Proceedings of the 21th ACM SIGKDD International Conference on

Knowledge Discovery and Data Mining, pp. 1265–1274. ACM (2015)
