[1] Steven S. Muchnick. Advanced compiler design implementation. Morgan Kaufmann, 1997.

[2] Randy Allen and Ken Kennedy. Optimizing compilers for
modern architectures a dependence-based approach. Morgan
Kaufmann, 2001.

[3] Jingling Xue. Loop tiling for parallelism, volume 575.
Springer Science & Business Media, 2012.

[4] James Philbin, Jan Edler, Otto J Anshus, Craig C Douglas,
and Kai Li. Thread scheduling for cache locality. In ACM
SIGOPS Operating Systems Review, volume 30, pages 60-71.
ACM, 1996.

[5] David Tam, Reza Azimi, and Michael Stumm. Thread clustering: sharing-aware scheduling on SMP-CMP-SMT multiprocessors. In ACM SIGOPS Operating Systems Review, volume 41, pages 47-58. ACM, 2007.

[6] Erik Lindholm, John Nickolls, Stuart Oberman, and John
Montrym. NVIDIA Tesla: A unified graphics and computing
architecture. IEEE Micro, 28(2):39-55, 2008.

[7] NVIDIA. CUDA Programming Guide, 2015.

[8] Mengjie Mao, Wujie Wen, Xiaoxiao Liu, Jingtong Hu, Danghui Wang, Yiran Chen, and Hai Li. TEMP: thread batch enabled memory partitioning for GPU. In Proceedings of the
53rd Annual Design Automation Conference, page 65. ACM,
2016.

[9] Mark Gebhart, Daniel R. Johnson, David Tarjan, Stephen W.
Keckler, William J. Dally, Erik Lindholm, and Kevin Skadron.
Energy-efficient Mechanisms for Managing Thread Context
in Throughput Processors. In Proceedings of the 38th Annual
International Symposium on Computer Architecture, ISCA
"11, pages 235-246. ACM, 2011.

[10] Wilson W. L. Fung, Ivan Sham, George Yuan, and Tor M.
Aamodt. Dynamic Warp Formation and Scheduling for Efficient GPU Control Flow. In Proceedings of the 40th Annual
IEEE/ACM International Symposium on Microarchitecture,
MICRO-40, pages 407-420. IEEE Computer Society, 2007.

[11] Adwait Jog, Onur Kayiran, Nachiappan Chidambaram Nachiappan, Asit K. Mishra, Mahmut T. Kandemir, Onur Mutlu,
Ravishankar Iyer, and Chita R. Das. OWL: Cooperative
Thread Array Aware Scheduling Techniques for Improving
GPGPU Performance. In Proceedings of the 18th International Conference on Architectural Support for Programming
Languages and Operating Systems, ASPLOS ’13, pages 395-—
406. ACM, 2013.

[12] Ang Li, Gert-Jan van den Braak, Akash Kumar, and Henk
Corporaal. Adaptive and transparent cache bypassing for
GPUs. In Proceedings of the International Conference
for High Performance Computing, Networking, Storage and
Analysis (SC), page 17. ACM, 2015.

[13] Chao Li, Shuaiwen Leon Song, Hongwen Dai, Albert Sidelnik, Siva Kumar Sastry Hari, and Huiyang Zhou. Localitydriven dynamic GPU cache bypassing. In Proceedings of the
29th ACM on International Conference on Supercomputing,
pages 67-77. ACM, 2015.

[14] Xuhao Chen, Li-Wen Chang, Christopher I. Rodrigues, Jie Lv,
Zhiying Wang, and Wen-Mei Hwu. Adaptive Cache Management for Energy-Efficient GPU Computing. In Proceedings of
the 47th Annual IEEE/ACM International Symposium on Microarchitecture, MICRO-47, pages 343-355. IEEE Computer
Society, 2014.

[15] Xiaolong Xie, Yun Liang, Guangyu Sun, and Deming Chen.
An Efficient Compiler Framework for Cache Bypassing on
GPUs. In Proceedings of the International Conference on
Computer-Aided Design, ICCAD ’13, pages 516-523. IEEE
Press, 2013.

[16] R. Ausavarungnirun, S. Ghose, O. Kayiran, G. H. Loh, C. R.
Das, M. T. Kandemir, and O. Mutlu. Exploiting Inter-Warp
Heterogeneity to Improve GPGPU Performance. In 2015 International Conference on Parallel Architecture and Compilation (PACT), pages 25-38, Oct 2015.

[17] Lingda Li, Ari B Hayes, Shuaiwen Leon Song, and Eddy Z
Zhang. Tag-Split Cache for Efficient GPGPU Cache Utilization. In Proceedings of the 2016 International Conference on
Supercomputing, page 43. ACM, 2016.

[18] Minsoo Rhu, Michael Sullivan, Jingwen Leng, and Mattan
Erez. A Locality-aware Memory Hierarchy for Energyefficient GPU Architectures. In Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture, MICRO-46, pages 86-98. ACM, 2013.

[19] Wenhao Jia, Kelly A Shaw, and Margaret Martonosi. Mrpb:
Memory request prioritization for massively parallel processors. In Proceedings of the 20th International Symposium
on High Performance Computer Architecture (HPCA), pages
272-283. IEEE, 2014.

[20] Xiaolong Xie, Yun Liang, Yu Wang, Guangyu Sun, and Tao
Wang. Coordinated static and dynamic cache bypassing for
GPUs. In Proceedings of the 21st International Symposium
on High Performance Computer Architecture (HPCA), pages
76-88. IEEE, 2015.

[21] Ali Bakhoda, George L Yuan, Wilson WL Fung, Henry Wong,
and Tor M Aamodt. Analyzing CUDA workloads using a
detailed GPU simulator. In Proceedings of the International
Symposium on Performance Analysis of Systems and Software
(ISPASS), pages 163-174. IEEE, 2009.

[22] Bo-Cheng Charles Lai, Hsien-Kai Kuo, and Jing-Yang Jou.
A cache hierarchy aware thread mapping methodology for
GPGPUs. IEEE Transactions on Computers (TC), 64(4):884—
898, 2015.

[23] NVIDIA. NVIDIA’s Next Generation CUDA Compute Architecture: Fermi. Comput. Syst, 26:63-72, 2009.

[24] Nikolaj Leischner, Vitaly Osipov, and Peter Sanders. Fermi
architecture white paper.

[25] Bo Wu, Guoyang Chen, Dong Li, Xipeng Shen, and Jeffrey
Vetter. Enabling and exploiting flexible task assignment on
GPU through SM-centric program transformations. In Proceedings of the 29th ACM on International Conference on Supercomputing (ICS), pages 119-130. ACM, 2015.

[26] Kunal Gupta, Jeff A Stuart, and John D Owens. A study
of persistent threads style GPU programming for GPGPU
workloads. In Innovative Parallel Computing (InPar), pages
1-14. IEEE, 2012.

[27] Minseok Lee, Seokwoo Song, Joosik Moon, Jung-Ho Kim,
Woong Seo, Yeongon Cho, and Soojung Ryu. Improving
GPGPU resource utilization through alternative thread block
scheduling. In Proceedings of 20th International Symposium
on High Performance Computer Architecture (HPCA), pages
260-271. IEEE, 2014.

[28] NVIDIA. GTX980 Whitepaper: Featuring Maxwell, the Most
Advanced GPU Ever Made, 2014.

[29] Inderpreet Singh, Arrvindh Shriraman, Wilson WL Fung,
Mike O’Connor, and Tor M Aamodt. Cache coherence for
GPU architectures. In Proceedings of the 19th International Symposium on High Performance Computer Architecture (HPCA), pages 578-590. IEEE, 2013.

[30] Sara S. Baghsorkhi, Isaac Gelado, Matthieu Delahaye, and
Wen-Mei Hwu. Efficient Performance Evaluation of Memory
Hierarchy for Highly Multithreaded Graphics Processors. In
Proceedings of the 17th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming (PPoPP). ACM,
2012.

[31] Onur Kayiran, Adwait Jog, Mahmut Taylan Kandemir, and
Chita Ranjan Das. Neither more nor less: optimizing threadlevel parallelism for GPGPUs. In Proceedings of the 22nd
international conference on Parallel architectures and compilation techniques (PACT), pages 157-166. IEEE Press, 2013.

[32] Hyeran Jeon, Gunjae Koo, and Murali Annavaram. CTAaware Prefetching for GPGPU. Computer Engineering Technical Report Number CENG-2014-08, 2014.

[33] Jin Wang, Norm Rubin, Albert Sidelnik, and Sudhakar Yalamanchili. LaPerm: Locality Aware Scheduler for Dynamic
Parallelism on GPUs. In Proceedings of the 43rd International Symposium on Computer Architecture (ISCA), pages
583-595. IEEE Press, 2016.

[34] Veynu Narasiman, Michael Shebanow, Chang Joo Lee, Rustam Miftakhutdinov, Onur Mutlu, and Yale N Patt. Improving GPU performance via large warps and two-level warp
scheduling. In Proceedings of the 44th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), pages
308-317. ACM, 2011.

[35] A. Sethia, D. A. Jamshidi, and S. Mahlke. Mascar: Speeding
up GPU warps by reducing memory pitstops. In Proceedings
of the 21st International Symposium on High Performance
Computer Architecture (HPCA), pages 174-185, Feb 2015.

[36] Adwait Jog, Onur Kayiran, Asit K. Mishra, Mahmut T. Kandemir, Onur Mutlu, Ravishankar Iyer, and Chita R. Das. Orchestrated Scheduling and Prefetching for GPGPUs. In Proceedings of the 40th Annual International Symposium on
Computer Architecture, ISCA ’13, pages 332-343. ACM,
2013.

[37] Lingda Li, Ari B Hayes, Stephen A Hackler, Eddy Z Zhang,
Mario Szegedy, and Shuaiwen Leon Song. A Graphbased Model for GPU Caching Problems. arXiv preprint
arXiv: 1605.02043, 2016.

[38] Eddy Z. Zhang, Yunlian Jiang, Ziyu Guo, Kai Tian, and
Xipeng Shen. On-the-fly elimination of dynamic irregularities
for gpu computing. In Proceedings of the Sixteenth International Conference on Architectural Support for Programming
Languages and Operating Systems, ASPLOS ’11, pages 369380. ACM, 2011.

[39] Jiangiao Liu, Nikhil Hegde, and Milind Kulkarni. Hybrid
CPU-GPU scheduling and execution of tree traversals. In Pro
ceedings of the 2016 International Conference on Supercomputing (ICS), page 2. ACM, 2016.

[40] NVIDIA. CUDA SDK Code Samples, 2015.

[41] Konstantin Andreev and Harald Racke. Balanced graph partitioning. Theory of Computing Systems, 39(6):929-939, 2006.

[42] Ang Li, Shuaiwen Leon Song, Mark Wijtvliet, Akash Kumar,
and Henk Corporaal. SFU-Driven Transparent Approximation
Acceleration on GPUs. In Proceedings of the International
Conference on Supercomputing (ICS), page 15. ACM, 2016.

[43] Sreepathi Pai, Matthew J. Thazhuthaveetil, and R. Govindarajan. Improving gpgpu concurrency with elastic kernels. In
Proceedings of the Eighteenth International Conference on
Architectural Support for Programming Languages and Operating Systems, ASPLOS 13, pages 407-418. ACM, 2013.

[44] Jaekyu Lee, Nagesh B Lakshminarayana, Hyesoon Kim, and
Richard Vuduc. Many-thread aware prefetching mechanisms for GPGPU applications. In Proceedings of the 43rd
Annual International Symposium on Microarchitecture (MICRO), pages 213-224. IEEE, 2010.

[45] Nagesh B Lakshminarayana and Hyesoon Kim. Spare register
aware prefetching for graph algorithms on GPUs. In High Performance Computer Architecture (HPCA), 2014 IEEE 20th
International Symposium on, pages 614-625. IEEE, 2014.

[46] Shuai Che, Michael Boyer, Jiayuan Meng, David Tarjan,
Jeremy W Sheaffer, Sang-Ha Lee, and Kevin Skadron. Rodinia: A benchmark suite for heterogeneous computing. In
Proceedings of the International Symposium on Workload
Characterization (IISWC), pages 44-54. TEEE, 2009.

[47] John A Stratton, Christopher Rodrigues, I-Jui Sung, Nady
Obeid, Li-Wen Chang, Nasser Anssari, Geng Daniel Liu, and
Wen-Mei W Hwu. Parboil: A revised benchmark suite for
scientific and commercial throughput computing. Center for
Reliable and High-Performance Computing, 2012.

[48] Scott Grauer-Gray, Lifan Xu, Robert Searles, Sudhee Ayalasomayajula, and John Cavazos. Auto-tuning a high-level language targeted to GPU codes. In Innovative Parallel Computing (InPar). TEEE, 2012.

[49] NVIDIA. CUDA Profiler User’s Guide, 2015.

[50] Wenhao Jia, Kelly A Shaw, and Margaret Martonosi. Characterizing and improving the use of demand-fetched caches in
GPUs. In Proceedings of the 26th ACM international conference on Supercomputing (ICS), pages 15-24. ACM, 2012.

[51] Timothy G. Rogers, Mike O’Connor, and Tor M. Aamodt.
Cache-conscious wavefront scheduling. In Proceedings of
the 45th Annual IEEE/ACM International Symposium on Microarchitecture, MICRO-45, pages 72-83. IEEE Computer
Society, 2012.

[52] Timothy G. Rogers, Mike O’Connor, and Tor M. Aamodt.
Divergence-aware Warp Scheduling. In Proceedings of the
46th Annual International Symposium on Microarchitecture,
MICRO-46, pages 99-110. ACM, 2013.

[53] Jayesh Gaur, Raghuram Srinivasan, Sreenivas Subramoney,
and Mainak Chaudhuri. Efficient Management of Last-level
Caches in Graphics Processors for 3D Scene Rendering Workloads. In Proceedings of the 46th Annual IEEE/ACM International Symposium on Microarchitecture, MICRO-46, pages
395-407. ACM, 2013.