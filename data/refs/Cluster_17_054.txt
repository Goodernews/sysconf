[1] T. Shimokawabe, T. Aoki, C. Muroi, J. Ishida, K. Kawano,
T. Endo, A. Nukada, N. Maruyama, and S. Matsuoka,
“An 80-fold speedup, 15.0 TFlops full GPU acceleration of
non-hydrostatic weather model ASUCA production code,” in
Proceedings of the 2010 ACM/IEEE International Conference
for High Performance Computing, Networking, Storage and
Analysis, ser. SC ’10. New Orleans, LA, USA: IEEE
Computer Society, 2010, pp. 1–11. [Online]. Available:
http://dx.doi.org/10.1109/SC.2010.9

[2] T. Shimokawabe, T. Aoki, J. Ishida, K. Kawano, and
C. Muroi, “145 TFlops performance on 3990 GPUs
of TSUBAME 2.0 supercomputer for an operational
weather prediction,” Procedia Computer Science, vol. 4, pp.
1535 – 1544, 2011, proceedings of the International
Conference on Computational Science, ICCS 2011.
[Online]. Available: http://www.sciencedirect.com/science/
article/pii/S1877050911002249

[3] T. Shimokawabe, T. Aoki, T. Takaki, A. Yamanaka,
A. Nukada, T. Endo, N. Maruyama, and S. Matsuoka, “Petascale phase-ﬁeld simulation for dendritic solidiﬁcation on the
TSUBAME 2.0 supercomputer,” in Proceedings of the 2011
ACM/IEEE International Conference for High Performance
Computing, Networking, Storage and Analysis, ser. SC ’11.
Seattle, WA, USA: ACM, 2011, pp. 1–11.

[4] P. Johnsen, M. Straka, M. Shapiro, A. Norton, and
T. Galarneau, “Petascale WRF simulation of hurricane
sandy deployment of NCSA’s Cray XE6 Blue Waters,”
in Proceedings of the International Conference on High
Performance Computing, Networking, Storage and Analysis,
ser. SC ’13. New York, NY, USA: ACM, 2013, pp.
63:1–63:7. [Online]. Available: http://doi.acm.org/10.1145/
2503210.2503231

[5] G. Jin, T. Endo, and S. Matsuoka, “A multi-level optimization
method for stencil computation on the domain that is bigger
than memory capacity of GPU,” in 2013 IEEE International
Symposium on Parallel Distributed Processing, Workshops
and Phd Forum, May 2013, pp. 1080–1087.

[6] G. Jin, T. Endo, and S. Matsuoka, “A parallel optimization
method for stencil computation on the domain that is bigger
than memory capacity of GPUs,” in 2013 IEEE International
Conference on Cluster Computing (CLUSTER), Sept 2013,
pp. 1–8.
[7] T. Endo and G. Jin, “Software technologies coping with memory hierarchy of GPGPU clusters for stencil computations,”
in Cluster Computing (CLUSTER), 2014 IEEE International
Conference on, Sept 2014, pp. 132–139.

[8] T. Endo, Y. Takasaki, and S. Matsuoka, “Realizing extremely
large-scale stencil applications on gpu supercomputers,” in
2015 IEEE 21st International Conference on Parallel and
Distributed Systems (ICPADS), Dec 2015, pp. 625–632.

[9] M. E. Wolf and M. S. Lam, “A data locality
optimizing algorithm,” in Proceedings of the ACM
SIGPLAN 1991 Conference on Programming Language
Design and Implementation, ser. PLDI ’91. New York,
NY, USA: ACM, 1991, pp. 30–44. [Online]. Available:
http://doi.acm.org/10.1145/113445.113449


[10] D. Wonnacott, “Using time skewing to eliminate idle time
due to memory bandwidth and network limitations,” in Proceedings of the 14th International Symposium on Parallel and
Distributed Processing, ser. IPDPS ’00, 2000, pp. 171–180.
[11] M. Wittmann, G. Hager, and G. Wellein, “Multicore-aware
parallel temporal blocking of stencil codes for shared and
distributed memory,” in 2010 IEEE International Symposium
on Parallel Distributed Processing, Workshops and Phd Forum (IPDPSW), April 2010, pp. 1–7.
[12] A. Nguyen, N. Satish, J. Chhugani, C. Kim, and P. Dubey,
“3.5-d blocking optimization for stencil computations on
modern cpus and gpus,” in 2010 ACM/IEEE International
Conference for High Performance Computing, Networking,
Storage and Analysis, Nov 2010, pp. 1–13.
[13] N. Maruyama, T. Nomura, K. Sato, and S. Matsuoka,
“Physis: an implicitly parallel programming model
for stencil computations on large-scale GPU-accelerated
supercomputers,” in Proceedings of 2011 International
Conference for High Performance Computing, Networking,
Storage and Analysis, ser. SC ’11. New York, NY,
USA: ACM, 2011, pp. 11:1–11:12. [Online]. Available:
http://doi.acm.org/10.1145/2063384.2063398
[14] D. Unat, X. Cai, and S. B. Baden, “Mint: realizing
CUDA performance in 3D stencil methods with annotated
C,” in Proceedings of the international conference on
Supercomputing, ser. ICS ’11. New York, NY, USA:
ACM, 2011, pp. 214–224. [Online]. Available: http:
//doi.acm.org/10.1145/1995896.1995932
[15] C. Lengauer, S. Apel, M. Bolten, A. Größlinger, F. Hannig,
H. Köstler, U. Rüde, J. Teich, A. Grebhahn, S. Kronawitter,
S. Kuckuk, H. Rittich, and C. Schmitt, ExaStencils: Advanced
Stencil-Code Engineering. Cham: Springer International
Publishing, 2014, pp. 553–564. [Online]. Available: http:
//dx.doi.org/10.1007/978-3-319-14313-2 47
[16] T. Shimokawabe, T. Aoki, and N. Onodera, “Highproductivity framework on GPU-rich supercomputers for operational weather prediction code ASUCA,” in Proceedings
of the 2014 ACM/IEEE International Conference for High
Performance Computing, Networking, Storage and Analysis,
ser. SC ’14.
New Orleans, LA, USA: IEEE Computer
Society, 2014, pp. 1–11.
[17] T. Shimokawabe, T. Aoki, and N. Onodera, “Highproductivity framework for large-scale GPU/CPU stencil
applications,” Procedia Computer Science, vol. 80, pp. 1646
– 1657, 2016. [Online]. Available: http://www.sciencedirect.
com/science/article/pii/S1877050916309863
[18] T. Endo, “Realizing out-of-core stencil computations using
multi-tier memory hierarchy on gpgpu clusters,” in 2016 IEEE
International Conference on Cluster Computing (CLUSTER),
Sept 2016, pp. 21–29.

[19] N. Onodera, T. Aoki, T. Shimokawabe, T. Miyashita, and
H. Kobayashi, “Large-eddy simulation of ﬂuid-structure interaction using lattice boltzmann method on multi-gpu clusters,”
in proceedings of the 5th Asia Paciﬁc Congress on Computational Mechanics and 4th International Symposium on
Computational Mechanics, 2013.