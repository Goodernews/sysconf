[1] TOP500.org, “Top 500 list,” https://www.top500.org/lists/2016/11/, 2016.
[2] D. G. Holmberg, S. T. Bushby, and D. B. Hardin, “Facility smart grid
interface and a demand response conceptual model,” NIST, Tech. Rep.
NIST Technical Note 1832, 2014.
[3] Federal Energy Regulatory Commission, “Assessment of demand response and advanced metering,” https://www.ferc.gov/legal/staff-reports/
2016/DR-AM-Report2016.pdf, 2016.
[4] PJM Interconnect, “Demand response and why its important,” https:
//www.pjm.com/∼/media/markets-ops/dsr/end-use-customer-fact-sheet.
ashx, 2014.
[5] The Energy Collective, “Demand response in the US electricity market,” http://theenergycollective.com/rasika-athawale/195536/
demand-response-us-electricity-market, 2013.
[6] J. McAnany, “2016 demand response operations markets activity report: April 2017,” http://www.pjm.com/∼/media/markets-ops/dsr/
2016-demand-response-activity-report.ashx, 2017.
[7] H. Marianne and W. Eric, “Market data: Demand response. residential,
commercial, and industrial demand response participation and sites,
load curtailment, and spending: Global and regional market sizing and
forecasts,” 2013.
[8] A. Wierman, Z. Liu, I. Liu, and H. Mohsenian-Rad, “Opportunities
and challenges for data center demand response,” in Green Computing
Conference (IGCC), 2014 International. IEEE, 2014, pp. 1–10.
[9] E. Bilgin, M. C. Caramanis, I. C. Paschalidis, and C. G. Cassandras,
“Provision of regulation service by smart buildings,” IEEE Transactions
on Smart Grid, vol. 7, no. 3, pp. 1683–1693, 2016.
[10] P. Fox-Penner, “Why apple is getting into the energy business,” https:
//hbr.org/2016/11/why-apple-is-getting-into-the-energy-business, 2016.
[11] Mission Critical Power, “Equinix in r&d phase of demand response experiments,” https://missioncriticalpower.uk/equinix-tests-demand-response/,
2015.
[12] G. Ghatikar, V. Ganti, N. Matson, and M. A. Piette, “Demand response
opportunities and enabling technologies for data centers: Findings from
ﬁeld studies,” 2014.
[13] N. Bates, G. Ghatikar, G. Abdulla, G. A. Koenig, S. Bhalachandra,
M. Sheikhalishahi, T. Patki, B. Rountree, and S. Poole, “Electrical
grid and supercomputing centers: an investigative analysis of emerging
opportunities and challenges,” Informatik-Spektrum, vol. 38, no. 2, pp.
111–127, 2015.
[14] T. Patki, N. Bates, G. Ghatikar, A. Clausen, S. Klingert, G. Abdulla,
and M. Sheikhalishahi, “Supercomputing centers and electricity service
providers: a geographically distributed perspective on demand management in Europe and the United States,” in International Conference on
High Performance Computing. Springer, 2016, pp. 243–260.
[15] O. Sarood, A. Langer, A. Gupta, and L. Kale, “Maximizing throughput
of overprovisioned HPC data centers under a strict power budget,” in
Proceedings of the International Conference for High Performance
Computing, Networking, Storage and Analysis. IEEE Press, 2014,
pp. 807–818.
[16] M. Etinski, J. Corbalan, J. Labarta, and M. Valero, “Parallel job
scheduling for power constrained HPC systems,” Parallel Computing,
vol. 38, no. 12, pp. 615–630, 2012.
[17] R. Ge, X. Feng, W.-c. Feng, and K. W. Cameron, “CPU MISER: A
performance-directed, run-time system for power-aware clusters,” in
Parallel Processing, 2007. ICPP 2007. International Conference on.
IEEE, 2007, pp. 18–18.
[18] W. Bao, C. Hong, S. Chunduri, S. Krishnamoorthy, L.-N. Pouchet,
F. Rastello, and P. Sadayappan, “Static and dynamic frequency scaling
on multicore CPUs,” ACM Transactions on Architecture and Code
Optimization (TACO), vol. 13, no. 4, p. 51, 2016.
[19] K. Singh, M. Bhadauria, and S. A. McKee, “Real time power estimation
and thread scheduling via performance counters,” ACM SIGARCH
Computer Architecture News, vol. 37, no. 2, pp. 46–55, 2009.
[20] H. Shoukourian, T. Wilde, A. Auweter, and A. Bode, “Predicting
the energy and power consumption of strong and weak scaling HPC
applications,” Supercomputing frontiers and innovations, vol. 1, no. 2,
pp. 20–41, 2014.
[21] X. Wu, V. Taylor, J. Cook, and P. Mucci, “Using performance-power
modeling to improve energy efﬁciency of HPC applications,” IEEE
Computer, vol. 49, no. 10, pp. 20–29, 2016.
[22] B. Rountree, D. K. Lownenthal, B. R. De Supinski, M. Schulz, V. W.
Freeh, and T. Bletsch, “Adagio: making dvs practical for complex HPC
applications,” in Proceedings of the 23rd international conference on
Supercomputing. ACM, 2009, pp. 460–469.
[23] V. W. Freeh, F. Pan, N. Kappiah, D. K. Lowenthal, and R. Springer,
“Exploring the energy-time tradeoff in MPI programs on a powerscalable cluster,” in Parallel and Distributed Processing Symposium,
2005. Proceedings. 19th IEEE International. IEEE, 2005, pp. 10–pp.
[24] X. Yang, Z. Zhou, S. Wallace, Z. Lan, W. Tang, S. Coghlan, and
M. E. Papka, “Integrating dynamic pricing of electricity into energy
aware scheduling for HPC systems,” in Proceedings of the International
Conference on High Performance Computing, Networking, Storage and
Analysis. ACM, 2013, p. 60.
[25] T. Cao, Y. He, and M. Kondo, “Demand-aware power management for
power-constrained HPC systems,” in Cluster, Cloud and Grid Computing
(CCGrid), 2016 16th IEEE/ACM International Symposium on. IEEE,
2016, pp. 21–31.
[26] M. E. Haque, I. Goiri, R. Bianchini, and T. D. Nguyen, “Greenpar:
Scheduling parallel high performance applications in green datacenters,”
in Proceedings of the 29th ACM on International Conference on
Supercomputing. ACM, 2015, pp. 217–227.
[27] F. Yang and A. A. Chien, “Zccloud: Exploring wasted green power for
high-performance computing,” in Parallel and Distributed Processing
Symposium, 2016 IEEE International. IEEE, 2016, pp. 1051–1060.
[28] H. Chen, M. C. Caramanis, and A. K. Coskun, “Reducing the data center
electricity costs through participation in smart grid programs,” in Green
Computing Conference (IGCC), 2014 International. IEEE, 2014, pp.
1–10.
[29] A. Auweter, A. Bode, M. Brehm, L. Brochard, N. Hammer, H. Huber,
R. Panda, F. Thomas, and T. Wilde, “A case study of energy aware
scheduling on SuperMUC,” in International Supercomputing Conference.
Springer, 2014, pp. 394–409.
[30] B. Austin and N. J. Wright, “Measurement and interpretation of
microbenchmark and application energy use on the Cray XC30,” in
Proceedings of the 2nd International Workshop on Energy Efﬁcient
Supercomputing. IEEE Press, 2014, pp. 51–59.
[31] P. Giannozzi, S. Baroni, N. Bonini, M. Calandra, R. Car, C. Cavazzoni,
D. Ceresoli, G. L. Chiarotti, M. Cococcioni, I. Dabo et al., “Quantum
espresso: a modular and open-source software project for quantum
simulations of materials,” Journal of physics: Condensed matter, vol. 21,
no. 39, p. 395502, 2009.
[32] V. Springel, “The cosmological simulation code gadget-2,” Monthly
notices of the royal astronomical society, vol. 364, no. 4, pp. 1105–1134,
2005.
[33] M. Käser, J. d. a. Puente, C. Castro, V. Hermann, and M. Dumbser,
“Seismic wave ﬁeld modelling using high performance computing,”
in SEG Technical Program Expanded Abstracts 2008. Society of
Exploration Geophysicists, 2008, pp. 2884–2888.
[34] C. Feichtinger, S. Donath, H. Köstler, J. Götz, and U. Rüde, “Walberla:
HPC software design for computational engineering simulations,” Journal
of Computational Science, vol. 2, no. 2, pp. 105–112, 2011.
[35] J. D. McCalpin, “Stream benchmark,” URL: http://www. cs. virginia.
edu/stream/stream2, 2002.
[36] T. Patki, D. K. Lowenthal, B. L. Rountree, M. Schulz, and B. R.
d. Supinski, “Economic viability of hardware overprovisioning in powerconstrained high performance computing,” in 2016 4th International
Workshop on Energy Efﬁcient Supercomputing (E2SC), Nov 2016, pp.
8–15.
[37] K. De Vogeleer, G. Memmi, P. Jouvelot, and F. Coelho, “The energy/frequency convexity rule: Modeling and experimental validation on
mobile devices,” in International Conference on Parallel Processing and
Applied Mathematics. Springer Berlin Heidelberg, 2013, pp. 793–803.
[38] M. J. Powell, “A fast algorithm for nonlinearly constrained optimization
calculations,” in Numerical analysis. Springer, 1978, pp. 144–157.
[39] Parallel Systems Lab, “Python scheduler simulator,” https://code.google.
com/archive/p/pyss/, 2010.
[40] Y. Georgiou, D. Glesser, K. Rzadca, and D. Trystram, “A scheduler-level
incentive mechanism for energy efﬁciency in HPC,” in Cluster, Cloud
and Grid Computing (CCGrid), 2015 15th IEEE/ACM International
Symposium on. IEEE, 2015, pp. 617–626.
[41] F. Liu and J. B. Weissman, “Elastic job bundling: An adaptive resource
request strategy for large-scale parallel applications,” in Proceedings
of the International Conference for High Performance Computing,
Networking, Storage and Analysis. ACM, 2015, p. 33.
[42] “CQsim,” http://bluesky.cs.iit.edu/cqsim/, 2012.
[43] W. Tang, Z. Lan, N. Desai, and D. Buettner, “Fault-aware, utility-based
job scheduling on Blue Gene/P systems,” in 2009 IEEE International
Conference on Cluster Computing and Workshops, Aug 2009, pp. 1–10.
[44] W. Tang, D. Ren, Z. Lan, and N. Desai, “Adaptive metric-aware
job scheduling for production supercomputers,” in Parallel Processing
Workshops (ICPPW), 2012 41st International Conference on. IEEE,
2012, pp. 107–115.
[45] C. L. Janssen, H. Adalsteinsson, S. Cranford, J. P. Kenny, A. Pinar, D. A.
Evensky, and J. Mayo, “A simulator for large-scale parallel computer
architectures,” Technology Integration Advancements in Distributed
Systems and Computing, vol. 179, 2012.
[46] N. Jain, A. Bhatele, S. White, T. Gamblin, and L. V. Kale,
“Evaluating HPC networks via simulation of parallel workloads,” in
Proceedings of the International Conference for High Performance
Computing, Networking, Storage and Analysis, ser. SC ’16. Piscataway,
NJ, USA: IEEE Press, 2016, pp. 14:1–14:12. [Online]. Available:
http://dl.acm.org/citation.cfm?id=3014904.3014923
[47] N. Santhi, S. Eidenzenz, and J. Liu, “The Simian concept: parallel
discrete event simulation with interpreted languages,” in Proceedings
of the 2015 Winter Simulation Conference, L. Yilmaz, W. K. V. Chan,
I. Moon, T. M. K. Roeder, C. Macal, and M. D. Rossetti, Eds., 2015.
[48] G. Chapuis, S. Eidenbenz, N. Santhi, and E. J. Park, “Simian integrated
framework for parallel discrete event simulation on GPUs,” in 2015
Winter Simulation Conference (WSC), Dec 2015, pp. 1127–1138.
[49] G. Chapuis, D. Nicholaeff, S. Eidenbenz, and R. S. Pavel, “Predicting
performance of smoothed particle hydrodynamics codes at large scales,”
in Winter Simulation Conference (WSC), 2016. IEEE, 2016, pp. 1825–
1835.
[50] K. Ahmed, M. Obaida, J. Liu, S. Eidenbenz, N. Santhi, and G. Chapuis,
“An integrated interconnection network model for large-scale performance
prediction,” in Proceedings of the 2016 annual ACM Conference on
SIGSIM Principles of Advanced Discrete Simulation. ACM, 2016, pp.
177–187.
[51] K. Ahmed, J. Liu, S. Eidenbenz, and J. Zerr, “Scalable interconnection
network models for rapid performance prediction of HPC applications,”
in 2016 IEEE 18th International Conference on High Performance
Computing and Communications (HPCC), Dec 2016, pp. 1069–1078.
[52] S. Srinivasan, R. Kettimuthu, V. Subramani, and P. Sadayappan, “Characterization of backﬁlling strategies for parallel job scheduling,” in Parallel
Processing Workshops, 2002. Proceedings. International Conference on.
IEEE, 2002, pp. 514–519.
[53] D. G. Feitelson, D. Tsafrir, and D. Krakov, “Experience with using
the parallel workloads archive,” Journal of Parallel and Distributed
Computing, vol. 74, no. 10, pp. 2967 – 2982, 2014. [Online]. Available:
http://www.sciencedirect.com/science/article/pii/S0743731514001154
[54] K. Deng, J. Song, K. Ren, and A. Iosup, “Exploring portfolio scheduling
for long-term execution of scientiﬁc workloads in IaaS clouds,” in
Proceedings of the International Conference on High Performance
Computing, Networking, Storage and Analysis. ACM, 2013, p. 55.
[55] K. Kianfar, G. Moslehi, and R. Yahyapour, “A novel metaheuristic
algorithm and utility function for qos based scheduling in user-centric
grid systems,” The Journal of Supercomputing, vol. 71, no. 3, pp. 1143–
1162, 2015.
[56] Arch Linux, “CPU frequency scaling,” https://wiki.archlinux.org/index.
php/CPU frequency scaling, 2017.
[57] E. Ipek, B. R. de Supinski, M. Schulz, and S. A. McKee, “An approach to
performance prediction for parallel applications,” Euro-Par 2005 Parallel
Processing, pp. 627–628, 2005.
[58] B. C. Lee, D. M. Brooks, B. R. de Supinski, M. Schulz, K. Singh,
and S. A. McKee, “Methods of inference and learning for performance
modeling of parallel applications,” in Proceedings of the 12th ACM
SIGPLAN symposium on Principles and practice of parallel programming.
ACM, 2007, pp. 249–258.
[59] R. Ge, X. Feng, and X. H. Sun, “SERA-IO: Integrating energy consciousness into parallel i/o middleware,” in 2012 12th IEEE/ACM International
Symposium on Cluster, Cloud and Grid Computing (CCGRID 2012),
May 2012, pp. 204–211.