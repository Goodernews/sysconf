[1] NVIDIA NSight 3.0 User Guide.
[2] NVIDIA CUDA Programming Guide, 5 March 2015, 2015.

[3] N. Bell and M. Garland. Implementing Sparse Matrix-Vector Multiplication on Throughput-Oriented Processors. In Proceedings of the
Conference on High Performance Computing Networking, Storage and
Analysis, page 18. ACM, 2009.

[4] L.-W. Chang, I. El Hajj, C. Rodrigues, J. G6mez-Luna, and W.-m. Hwu.
Efficient kernel synthesis for performance portable programming. In
Microarchitecture (MICRO), 2016 49th Annual IEEE/ACM International
Symposium on, pages 1-13. IEEE, 2016.

[5] L. Dagum and R. Menon. OpenMP: an Industry Standard Api for SharedMemory Programming. IEEE Computational Science and Engineering,
5(1):46-55, 1998.

[6] T. A. Davis and Y. Hu. The University of Florida Sparse Matrix
Collection. ACM Transactions on Mathematical Software (TOMS),
38(1):1, 2011.

[7] H. C. Edwards, D. Sunderland, V. Porter, C. Amsler, and S. Mish.
Manycore Performance-Portability: Kokkos Multidimensional Array
Library. Scientific Programming, 20(2):89-114, 2012.

[8] H. C. Edwards, C. R. Trott, and D. Sunderland. Kokkos: Enabling
Manycore Performance Portability through Polymorphic Memory Access
Patterns. Journal of Parallel and Distributed Computing, 74(12):3202—
3216, 2014.

[9] K. Fatahalian, D. R. Horn, T. J. Knight, L. Leem, M. Houston, J. Y. Park,
M. Erez, M. Ren, A. Aiken, W. J. Dally, et al. Sequoia: Programming the
memory hierarchy. In Proceedings of the 2006 ACM/IEEE conference
on Supercomputing, page 83. ACM, 2006.

[10] K. Gregory and A. Miller. C++ AMP: Accelerated Massive Parallelism
with Microsoft Visual C++. 2014.

[11] R.D. Hornung and J. A. Keasler. The RAJA Poratability Layer: Overview
and Status. Technical Report LLNL-TR-661403, Lawrence Livermore
National Laboratory, CA, USA, 2014.

[12] J. Jeffers and J. Reinders. Intel Xeon Phi Coprocessor High-Performance
Programming. Newnes, 2013.

[13] NVIDIA. Nvidia tesla p100 - the most advanced datacenter accelerator
ever built featuring pascal gp100 the worlds fastest gpu. Technical
report, 2016.

[14] J. Ragan-Kelley, C. Bares, A. Adams, S. Paris, KF Durand, and
S. Amarasinghe. Halide: a language and compiler for optimizing
parallelism, locality, and recomputation in image processing pipelines.
ACM SIGPLAN Notices, 48(6):519-530, 2013.

[15] J. Reinders. VZune Performance Analyzer Essentials. Intel Press, 2005.

[16] E. Rotem and S. P. Engineer. Intel architecture, code name skylake
deep dive: A new architecture to manage power performance and energy
efficiency. In Intel Developer Forum, 2015.

[17] A. Sodani. Knights landing (KNL): 2nd Generation Intel Xeon Phi
Processor. In Hot Chips 27 Symposium (HCS), 2015 IEEE, pages 1-24.
TEEE, 2015.

[18] A. Sodani et al. Knights Landing: Second-Generation Intel Xeon Phi
Product. IEEE Micro, 36(2):34—46, 2016.

[19] J. E. Stone, D. Gohara, and G. Shi. OpenCL: a Parallel Programming
Standard for Heterogeneous Computing Systems. Computing in science
& engineering, 12(1-3):66-73, 2010.

[20] C.R. Trott, M. Hoemmen, S$. D. Hammond, and H. C. Edwards. Kokkos:
the Programming Guide. 2015.

[21] R. W. Vuduc. Automatic Performance Tuning of Sparse Matrix Kernels.
PhD thesis, University of California, Berkeley, 2003.

[22] S. Wienke, P. Springer, C. Terboven, and D. an Mey. OpenACC First
Experiences with Real-World Applications. In European Conference on
Parallel Processing, pages 859-870. Springer, 2012.