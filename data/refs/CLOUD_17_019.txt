[1] M. Al-Fares, A. Loukissas, and A. Vahdat. A scalable, commodity data
center network architecture. In ACM SIGCOMM Computer Communication Review, volume 38, pages 63–74. ACM, 2008.
[2] C.-h. Chiu, N. Lewis, D. K. Singh, A. K. Das, M. M. Jalazai, R. Platania,
S. Goswami, K. Lee, and S.-J. Park. Bic-lsu: Big data research
integration with cyberinfrastructure for lsu. In Proceedings of the
XSEDE16 Conference on Diversity, Big Data, and Science at Scale,
XSEDE16, pages 28:1–28:8, New York, NY, USA, 2016. ACM.
[3] M. Chowdhury and I. Stoica. Coflow: A networking abstraction for
cluster applications. In Proceedings of the 11th ACM Workshop on Hot
Topics in Networks, pages 31–36. ACM, 2012.
[4] M. Chowdhury, M. Zaharia, J. Ma, M. I. Jordan, and I. Stoica. Managing
data transfers in computer clusters with orchestra. In ACM SIGCOMM
Computer Communication Review, volume 41, pages 98–109. ACM,
2011.
[5] M. Chowdhury, Y. Zhong, and I. Stoica. Efficient coflow scheduling
with varys. In ACM SIGCOMM Computer Communication Review,
volume 44, pages 443–454. ACM, 2014.
[6] R. S. F. Community. Ryu SDN Framework, 2017.
[7] R. C. Computing. OpenStack, 2017.
[8] I. Corp. sFlow-RT, 2017.
[9] J. Dean and S. Ghemawat. Mapreduce: simplified data processing on
large clusters. Communications of the ACM, 51(1):107–113, 2008.
[10] L. Foundation. Open vSwitch, 2017.
[11] O. Foundation. OpenStack Swift, 2017.
[12] R. L. Grossman, M. Greenway, A. P. Heath, R. Powell, R. D. Suarez,
W. Wells, K. P. White, M. P. Atkinson, I. A. Klampanos, H. L. Alvarez,
C. Harvey, and J. Mambretti. The design of a community science cloud:
The open science data cloud perspective. In SC Companion, pages 1051–
1057, 2012.
[13] J. Jiang, S. Ma, B. Li, and B. Li. Tailor: Trimming coflow completion times in datacenter networks. In Computer Communication and
Networks (ICCCN), 2016 25th International Conference on, pages 1–9.
IEEE, 2016.
[14] G. K. Lockwood, M. Tatineni, and R. Wagner. Storage utilization in the
long tail of science. In Proceedings of the 2015 XSEDE Conference:
Scientific Advancements Enabled by Enhanced Cyberinfrastructure,
XSEDE ’15, pages 32:1–32:8, New York, NY, USA, 2015. ACM.
[15] G. Malewicz, M. H. Austern, A. J. Bik, J. C. Dehnert, I. Horn, N. Leiser,
and G. Czajkowski. Pregel: a system for large-scale graph processing.
In Proceedings of the 2010 ACM SIGMOD International Conference on
Management of data, pages 135–146. ACM, 2010.
[16] M. Mathis, J. Semke, J. Mahdavi, and T. Ott. The macroscopic
behavior of the tcp congestion avoidance algorithm. SIGCOMM Comput.
Commun. Rev., 27(3):67–82, July 1997.
[17] S. McGillicuddy. Pica8 doubles flow rule capacity in its new OpenFlow
1.3 switch, 2014.
[18] L. Xue, C.-H. Chiu, S. Kumar, P. Kondikoppa, and S.-J. Park. Fall: A
fair and low latency queuing scheme for data center networks. In Computing, Networking and Communications (ICNC), 2015 International
Conference on, pages 771–777. IEEE, 2015.
[19] Y. Zhao, K. Chen, W. Bai, M. Yu, C. Tian, Y. Geng, Y. Zhang, D. Li, and
S. Wang. Rapier: Integrating routing and scheduling for coflow-aware
data center networks. In Computer Communications (INFOCOM), 2015
IEEE Conference on, pages 424–432. IEEE, 2015.
