[1] P. Balaji, D. Buntinas, D. Goodell, W. Gropp, and R. Thakur, “Toward
efficient support for multithreaded MPI communication,” in EuroMPI
’08, pp. 120–129.
[2] G. Dózsa, S. Kumar, P. Balaji, D. Buntinas, D. Goodell, W. Gropp,
J. Ratterman, and R. Thakur, “Enabling concurrent multithreaded MPI
communication on multicore petascale systems,” in EuroMPI ’10, pp.
11–20.
[3] D. Dice, V. J. Marathe, and N. Shavit, “Lock cohorting: A general
technique for designing NUMA locks,” in PPoPP ’12, pp. 247–256.
[4] M. Chabbi and J. Mellor-Crummey, “Contention-conscious, localitypreserving locks,” in PPoPP ’16, pp. 22:1–22:14.
[5] D. Dice, “Malthusian locks,” CoRR, vol. abs/1511.06035, 2015.
[6] A. Amer, H. Lu, Y. Wei, P. Balaji, and S. Matsuoka, “MPI+threads:
Runtime contention and remedies,” in PPoPP ’15, pp. 239–248.
[7] A. Amer, H. Lu, Y. Wei, J. Hammond, S. Matsuoka, and P. Balaji,
“Locking aspects in multithreaded MPI implementations,” Argonne
National Lab., Tech. Rep. P6005-0516, 2016.
[8] J. M. Mellor-Crummey and M. L. Scott, “Algorithms for scalable
synchronization on shared-memory multiprocessors,” ACM Transactions
on Computer Systems (TOCS), vol. 9, no. 1, pp. 21–65, 1991.
[9] T. Craig, “Building FIFO and priority-queuing spin locks from atomic
swap,” University of Washington, Tech. Rep. TR 93-02-02, 1993.
[10] “MPICH: A high-performance and widely portable implementation of
the MPI standard,” http://www.mpich.org/.
[11] P. Dhabaleswar, “OSU Micro-Benchmarks 5.3,” http://mvapich.cse.
ohio-state.edu/benchmarks/.
[12] L. Adhianto, S. Banerjee, M. Fagan, M. Krentel, G. Marin, J. MellorCrummey, and N. R. Tallent, “HPCToolkit: Tools for performance analysis of optimized parallel programs,” Concurrency and Computation:
Practice and Experience, vol. 22, no. 6, pp. 685–701, 2010.
[13] H. Dang, M. Snir, and W. Gropp, “Towards millions of communicating
threads,” in EuroMPI ’16.
[14] “TACC Stampede Cluster,” http://www.xsede.org/resources/overview.
[15] “Graph 500,” http://www.graph500.org/.
[16] A. Amer, H. Lu, P. Balaji, and S. Matsuoka, “Characterizing MPI and
hybrid MPI+Threads applications at scale: case study with BFS,” in
PPMM ’15, 2015, pp. 1075–1083.
[17] M. A. Heroux, D. W. Doerfler, P. S. Crozier, J. M. Willenbring, H. C.
Edwards, A. Williams, M. Rajan, E. R. Keiter, H. K. Thornquist, and
R. W. Numrich, “Improving performance via mini-applications,” Sandia
National Laboratories, Tech. Rep. SAND2009-5574, 2009.
[18] F. Garcia, A. Calderón, and J. Carretero, “MiMPI: A multithred-safe
implementation of MPI,” in EuroMPI ’99, pp. 207–214.
[19] A. Skjellum, B. Protopopov, and S. Hebert, “A thread taxonomy for
MPI,” in MPIDC ’96.
[20] C. Huang, O. Lawlor, and L. V. Kalé, “Adaptive MPI,” in LCPC ’03,
pp. 306–322.
[21] H. Tang, K. Shen, and T. Yang, “Compile/run-time support for threaded
MPI execution on multiprogrammed shared memory machines,” in
PPoPP ’99.
[22] E. D. Demaine, “A threads-only MPI implementation for the development of parallel programs,” in HPCS ’97, pp. 156–163.
[23] E. R. Rodrigues, P. O. A. Navaux, J. Panetta, and C. L. Mendes, “A
new technique for data privatization in user-level threads and its use in
parallel applications,” in SAC ’10.
[24] M. Pérache, H. Jourdren, and R. Namyst, “MPC: A unified parallel
runtime for clusters of NUMA machines,” in Euro-Par ’08, pp. 78–88.
[25] L. V. Kale and S. Krishnan, “Charm++: A portable concurrent object
oriented system based on C++,” in OOPSLA ’93, pp. 91–108.
[26] K. Vaidyanathan, D. D. Kalamkar, K. Pamnany, J. R. Hammond, P. Balaji, D. Das, J. Park, and B. Joó, “Improving concurrency and asynchrony
in multithreaded MPI applications using software offloading,” in SC ’15.