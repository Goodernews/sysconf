[1] Ahmad Abdelfattah, Azzam Haidar, Stanimire Tomov, and Jack Dongarra. 2016.
Performance, Design, and Autotuning of Batched GEMM for GPUs. Springer International Publishing, Cham, 21–38. https://doi.org/10.1007/978-3-319-41321-1_2
[2] Yifeng Chen, Xiang Cui, and Hong Mei. 2010. Large-scale FFT on GPU Clusters.
In Proceedings of the 24th ACM International Conference on Supercomputing (ICS
’10). ACM, New York, NY, USA, 315–324. https://doi.org/10.1145/1810085.1810128
[3] B. A. Cipra. 2000. The Best of the 20th Century: Editors Name Top 10 Algorithms.
SIAM News 33 (2000).
[4] James W. Cooley and John W. Tukey. 1965. An Algorithm for the Machine
Calculation of Complex Fourier Series. Math. Comp. 19, 90 (1965), 297–301.
http://www.jstor.org/stable/2003354
[5] J Dongarra, J Hittinger, J Bell, L Chacon, R Falgout, M Heroux, P Hovland, E Ng, C
Webster, and S Wild. 2014. Applied Mathematics Research for Exascale Computing.
https://doi.org/10.2172/1149042
[6] A. Dutt, M. Gu, and V. Rokhlin. 1996. Fast Algorithms for Polynomial Interpolation, Integration, and Differentiation. SIAM J. Numer. Anal. 33, 5 (1996), 1689–1711.
https://doi.org/10.1137/0733082 arXiv:http://dx.doi.org/10.1137/0733082
[7] A. Dutt and V. Rokhlin. 1995. Fast Fourier Transforms for Nonequispaced Data,
II. Applied and Computational Harmonic Analysis 2, 1 (1995), 85 – 100. https:
//doi.org/10.1006/acha.1995.1007
[8] Alan Edelman, Peter McCorquodale, and Sivan Toledo. 1998.
The
Future Fast Fourier Transform?
SIAM Journal on Scientific Computing 20, 3 (1998), 1094–1114.
https://doi.org/10.1137/S1064827597316266
arXiv:http://dx.doi.org/10.1137/S1064827597316266
[9] William Fong and Eric Darve. 2009. The black-box fast multipole method. J.
Comput. Phys. 228, 23 (2009), 8712 – 8725. https://doi.org/10.1016/j.jcp.2009.08.031
[10] M. Frigo and S. G. Johnson. 1998. FFTW: an adaptive software architecture for
the FFT. In Acoustics, Speech and Signal Processing, 1998. Proceedings of the 1998
IEEE International Conference on, Vol. 3. 1381–1384 vol.3. https://doi.org/10.1109/
ICASSP.1998.681704
[11] Amir Gholami, Judith Hill, Dhairya Malhotra, and George Biros. 2015. AccFFT:
A library for distributed-memory FFT on CPU and GPU architectures. arXiv
preprint arXiv:1506.07933 (2015).
[12] Q. Hu, N. A. Gumerov, and R. Duraiswami. 2012. Scalable Distributed Fast
Multipole Methods. In 2012 IEEE 14th International Conference on High Performance Computing and Communication 2012 IEEE 9th International Conference on
Embedded Software and Systems. 270–279. https://doi.org/10.1109/HPCC.2012.44
[13] Huda Ibeid, Rio Yokota, and David Keyes. 2016. A performance model for
the communication in fast multipole methods on high-performance computing platforms. The International Journal of High Performance Computing Applications 30, 4 (2016), 423–437. https://doi.org/10.1177/1094342016634819
arXiv:http://dx.doi.org/10.1177/1094342016634819
[14] Intel. 2017. Intel MKL DFTI Library. (2017).
[15] M. H. Langston, M. Baskaran, B. Meister, N. Vasilache, and R. Lethin. 2013.
Re-Introduction of communication-avoiding FMM-accelerated FFTs with GPU
acceleration. In High Performance Extreme Computing Conference (HPEC), 2013
IEEE. 1–6. https://doi.org/10.1109/HPEC.2013.6670352
[16] Ilya Lashuk, Aparna Chandramowlishwaran, Harper Langston, Tuan-Anh
Nguyen, Rahul Sampath, Aashay Shringarpure, Richard Vuduc, Lexing Ying,
Denis Zorin, and George Biros. 2012. A Massively Parallel Adaptive Fast Multipole Method on Heterogeneous Architectures. Commun. ACM 55, 5 (May 2012),
101–109. https://doi.org/10.1145/2160718.2160740
[17] Hatem Ltaief, Piotr Luszczek, and Jack Dongarra. 2012. Profiling high performance dense linear algebra algorithms on multicore architectures for power and
energy efficiency. Computer Science - Research and Development 27, 4 (2012),
277–287. https://doi.org/10.1007/s00450-011-0191-z
[18] Lingchuan Meng, Jeremy Johnson, Franz Franchetti, Yevgen Voronenko,
Marc Moreno Maza, and Yuzhen Xie. 2010. Spiral-Generated Modular FFT Algorithms. In Parallel Symbolic Computation (PASCO). 169–170.
[19] Nvidia. 2017. CUDA cuFFT Library. (2017).
[20] Jongsoo Park, Ganesh Bikshandi, Karthikeyan Vaidyanathan, Ping Tak Peter
Tang, Pradeep Dubey, and Daehyun Kim. 2013. Tera-scale 1D FFT with Lowcommunication Algorithm and Intel Xeon Phi Coprocessors. In Proceedings of
the International Conference on High Performance Computing, Networking, Storage
and Analysis (SC ’13). ACM, New York, NY, USA, Article 34, 12 pages. https:
//doi.org/10.1145/2503210.2503242
[21] Yang Shi, U.N. Niranjan, Animashree Anandkumar, and Cris Cecka. 2016. Tensor
Contractions with Extended BLAS Kernels on CPU and GPU. In 2016 IEEE 23rd
International Conference on High Performance Computing (HiPC). 193–202. https:
//doi.org/10.1109/HiPC.2016.031
[22] Paul N. Swarztrauber. 1984. FFT Algorithms for Vector Computers. Parallel
Comput. 1, 1 (Aug. 1984), 45–63. https://doi.org/10.1016/S0167-8191(84)90413-7
[23] Toru Takahashi, Cris Cecka, William Fong, and Eric Darve. 2012. Optimizing the
multipole-to-local operator in the fast multipole method for graphical processing
units. Internat. J. Numer. Methods Engrg. 89, 1 (2012), 105–133. https://doi.org/10.
1002/nme.3240
[24] P. T. P. Tang, J. Park, D. Kim, and V. Petrov. 2012. A framework for lowcommunication 1-D FFT. In High Performance Computing, Networking, Storage
and Analysis (SC), 2012 International Conference for. 1–12. https://doi.org/10.1109/
SC.2012.5
[25] C. Van Loan. 1992. Computational Frameworks for the Fast Fourier Transform. Society for Industrial and Applied Mathematics. https://doi.org/10.1137/1.
9781611970999 arXiv:http://epubs.siam.org/doi/pdf/10.1137/1.9781611970999
[26] Rio Yokota and Lorena A Barba. 2012. A tuned and scalable fast multipole method
as a preeminent algorithm for exascale systems. The International Journal of
High Performance Computing Applications 26, 4 (2012), 337–346. https://doi.org/
10.1177/1094342011429952 arXiv:http://dx.doi.org/10.1177/1094342011429952
