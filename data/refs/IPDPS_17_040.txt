[1] M. Snir, R. Wisniewski, J. Abraham, S. Adve et al., “Ad-
dressing failures in exascale computing,” IJHPCA, vol. 28,
no. 2, pp. 129–173, 2014.

[2] E. N. Elnozahy, L. Alvisi, Y.-M. Wang, and D. B. Johnson,
“A survey of rollback-recovery protocols in message-passing
systems,” ACM Comput. Surv., vol. 34, no. 3, pp. 375–408,
2002.

[3] J. T. Daly, “A higher order estimate of the optimum check-
point interval for restart dumps,” FGCS, vol. 22, no. 3, pp.
303–312, 2006.

[4] W. Ma and S. Krishnamoorthy, “Data-driven fault tolerance

for work stealing computations,” in ICS, 2012, pp. 79–90.

[5] J. S. Plank and K. Li, “Faster checkpointing with N+1 parity,”

in FTCS, 1994, pp. 288–297.

[6] R. Blumofe and P. Lisiecki, “Adaptive and reliable parallel
computing on networks of workstations,” in USENIX, 1997,
pp. 133–147.

[7] M. Frigo, C. E. Leiserson, and K. H. Randall, “The imple-
mentation of the Cilk-5 multithreaded language,” in PLDI,
1998, pp. 212–223.

[8] J. E. Baldeschwieler, R. D. Blumofe, and E. A. Brewer,
“ATLAS: An infrastructure for global computing,” in The
Workshop on Systems Support for Worldwide Applications,
1996, pp. 165–172.

[9] M. Frigo, P. Halpern, C. E. Leiserson, and S. Lewin-Berlin,
“Reducers and other Cilk++ hyperobjects,” in SPAA, 2009,
pp. 79–90.

[10] J. Lifﬂander, S. Krishnamoorthy, and L. Kal´e, “Steal tree:
low-overhead tracing of work stealing schedulers,” in PLDI,
2013, pp. 507–518.

[11] J. Dinan, D. B. Larkins, P. Sadayappan, S. Krishnamoorthy,
and J. Nieplocha, “Scalable work stealing,” in SC, 2009, pp.
53:1–53:11.

[12] S. Olivier, J. Huan, J. Liu, J. Prins, J. Dinan, P. Sadayappan,
and C.-W. Tseng, “UTS: An unbalanced tree search bench-
mark,” in LCPC, 2007, pp. 235–250.

[13] R. Kendall, E. Apra, D. Bernholdt et al., “High performance
computational chemistry: An overview of NWChem a dis-
tributed parallel application,” Comp. Phys. Comm., vol. 128,
no. 1-2, pp. 260–283, 2000.

[14] K. Ferreira, J. Stearley, J. H. Laros, III, R. Oldﬁeld et al.,
“Evaluating the viability of process replication reliability for
exascale systems,” in SC, 2011, pp. 44:1–44:12.

[15] J. Elliott, K. Kharbas, D. Fiala, F. Mueller, K. Ferreira, and
C. Engelmann, “Combining partial redundancy and check-
pointing for HPC,” in ICDCS, 2012, pp. 615–626.

[16] N. Ali, S. Krishnamoorthy, N. Govind, and B. Palmer, “A
redundant communication approach to scalable fault tolerance
in PGAS programming models,” in PDP, 2011, pp. 24–31.
[17] D. A. Patterson, G. Gibson, and R. H. Katz, “A case for
redundant arrays of inexpensive disks (RAID),” in ICDM,
1988, pp. 109–116.

[18] K. Huang and J. Abraham, “Algorithm-based fault tolerance
for matrix operations,” IEEE Trans. Comp., vol. C-33, no. 6,
pp. 518 –528, 1984.

[19] F. C. H. Lin and R. M. Keller, “Distributed recovery in

applicative systems,” in ICPP, 1986, pp. 405–412.

[20] G. Wrzesi´nska, R. V. Van Nieuwpoort, J. Maassen, T. Kiel-
mann, and H. E. Bal, “Fault-tolerant scheduling of ﬁne-
grained tasks in grid environments,” IJHPCA, vol. 20, no. 1,
pp. 103–114, 2006.

[21] D. Cunningham, D. Grove, B. Herta, A.

Iyengar,
K. Kawachiya, H. Murata, V. Saraswat, M. Takeuchi,
and O. Tardieu, “Resilient X10: efﬁcient
failure-aware
programming,” in PPoPP, 2014, pp. 67–80.

[22] S. Crafa, D. Cunningham, V. Saraswat, A. Shinnar, and
O. Tardieu, “Semantics of (resilient) X10,” in ECOOP, 2014,
pp. 670–696.

[23] C. Fohry, M. Bungart, and J. Posner, “Fault tolerance schemes
load balancing in X10,” Scalable Computing:

for global
Practice and Experience, vol. 16, no. 2, 2015.

[24] V. Saraswat, P. Kambadur, S. Kodali, D. Grove, and S. Krish-
namoorthy, “Lifeline-based global load balancing,” in PPoPP,
2011, pp. 201–212.

[25] M. C. Kurt, S. Krishnamoorthy, K. Agrawal, and G. Agrawal,
“Fault-tolerant dynamic task graph scheduling,” in SC, 2014,
pp. 719–730.

[26] C. Cao, T. Herault, G. Bosilca, and J. Dongarra, “Design for
a soft error resilient dynamic task-based runtime,” in IPDPS,
2015, pp. 765–774.
