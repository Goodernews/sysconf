
[1] M. Anderson, D. Antenucci, V. Bittorf, M. Burgess,
M. Cafarella, A. Kumar, F. Niu, Y. Park, C. Ré, and
C. Zhang. Brainwash: A Data System for Feature En-
gineering. In CIDR, 2013.

[2] J. Snoek, H. Larochelle, and R. P. Adams. Practical
Bayesian Optimization of Machine Learning Algorithms.
In NIPS, 2012.

[3] D. Maclaurin, D. Duvenaud, and R. P. Adams. Gradient-
based Hyperparameter Optimization through Reversible
Learning. 2015.

[4] S. Han, H. Mao, and W. J. Dally. Deep Compres-
sion: Compressing Deep Neural Network with Prun-
ing, Trained Quantization and Huffman Coding. CoRR,
abs/1510.00149, 2015.

[5] X. Meng, J. K. Bradley, B. Yavuz, E. R. Sparks,
S. Venkataraman, D. Liu, J. Freeman, D. B. Tsai,
M. Amde, S. Owen, D. Xin, R. Xin, M. J. Franklin,
R. Zadeh, M. Zaharia, and A. Talwalkar. MLlib: Ma-
chine Learning in Apache Spark. CoRR, abs/1505.06807,
2015.

[6] H2O: Open Source Platform for AI.

Retrieved

04/20/2017, URL: https://docs.h2o.ai.

[7] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean,
M. Devin, S. Ghemawat, G. Irving, M. Isard, M. Kud-
lur, J. Levenberg, R. Monga, S. Moore, D. G. Murray,
B. Steiner, P. Tucker, V. Vasudevan, P. Warden, M. Wicke,
Y. Yu, and X. Zheng. TensorFlow: A System for Large-
scale Machine Learning. In USENIX OSDI, 2016. ISBN
978-1-931971-33-1.

[8] Caffe2.

Retrieved 04/20/2017, URL: https://

github.com/caffe2/caffe2.

[9] Apache Hadoop YARN. Retrieved 02/08/2017, URL:
http://hadoop.apache.org/docs/current/
hadoop-yarn/hadoop-yarn-site/YARN.
html.

[10] B. Hindman, A. Konwinski, M. Zaharia, A. Ghodsi, A. D.
Joseph, R. Katz, S. Shenker, and I. Stoica. Mesos: A
Platform for Fine-grained Resource Sharing in the Data
Center. In USENIX NSDI, 2011.

[11] A. Ghodsi, M. Zaharia, B. Hindman, A. Konwinski,
S. Shenker, and I. Stoica. Dominant Resource Fairness:
Fair Allocation of Multiple Resource Types. In USENIX
NSDI, 2011.

[12] A. A. Bhattacharya, D. Culler, E. Friedman, A. Ghodsi,
S. Shenker, and I. Stoica. Hierarchical Scheduling for
Diverse Datacenter Workloads. In ACM SoCC, 2013.

[13] Capacity Scheduler.

Retrieved 04/20/2017, URL:

https://hadoop.apache.org/docs/r2.
4.1/hadoop-yarn/hadoop-yarn-site/
CapacityScheduler.html.

[14] M. Isard, V. Prabhakaran, J. Currey, U. Wieder, K. Talwar,
and A. Goldberg. Quincy: Fair Scheduling for Distributed
Computing Clusters. In ACM SOSP, 2009.

[15] S. Venkataraman, Z. Yang, M. Franklin, B. Recht, and

403

I. Stoica. Ernest: Efﬁcient Performance Prediction for
Large-Scale Advanced Analytics.
In USENIX NSDI,
2016.

[16] K. Zeng, S. Agarwal, and I. Stoica.

Uncertainty for Efﬁcient Incremental OLAP.
SIGMOD, 2016.

iOLAP: Managing
In ACM

[17] S. Agarwal, B. Mozafari, A. Panda, H. Milner, S. Mad-
den, and I. Stoica. BlinkDB: Queries with Bounded Er-
rors and Bounded Response Times on Very Large Data.
In ACM EuroSys, 2013.

[18] S. Zilberstein. Using anytime algorithms in intelligent

systems. AI magazine, 17(3):73, 1996.

[19] M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma,
M. McCauley, M. J. Franklin, S. Shenker, and I. Sto-
ica. Resilient Distributed Datasets: A Fault-tolerant Ab-
straction for In-memory Cluster Computing. In USENIX
NSDI, 2012.

[20] I. Goodfellow, Y. Bengio, and A. Courville. Deep Learn-

ing. MIT Press, 2016.

[21] L. Bottou and O. Bousquet. The Tradeoffs of Large Scale

Learning. In NIPS, 2008.

[22] S. Boyd and L. Vandenberghe. Convex Optimization.

Cambridge University Press, 2004.

[23] B. Babcock, S. Chaudhuri, and G. Das. Dynamic Sample
In ACM

Selection for Approximate Query Processing.
SIGMOD, 2003.

[24] G. Ananthanarayanan, M. C.-C. Hung, X. Ren, I. Stoica,
A. Wierman, and M. Yu. GRASS: Trimming Stragglers
in Approximation Analytics. In USENIX NSDI, 2014.

[25] S. Venkataraman, A. Panda, G. Ananthanarayanan, M. J.
Franklin, and I. Stoica. The Power of Choice in Data-
aware Cluster Scheduling. In USENIX OSDI, 2014.

[26] J. M. Hellerstein, P. J. Haas, and H. J. Wang. Online Ag-

gregation. In ACM SIGMOD, 1997.

[27] N. Pansare, V. R. Borkar, C. Jermaine, and T. Condie. On-
line Aggregation for Large MapReduce Jobs. Proceed-
ings of the VLDB Endowment, 4(11), 2011.

[28] Y. Tohkura. A Weighted Cepstral Distance Measure for
IEEE Transactions on Acoustics,

Speech Recognition.
Speech, and Signal Processing, 35:1414–1422, 1987.

[29] Y. L. Cun, J. S. Denker, and S. A. Solla. Optimal Brain

Damage. In NIPS. 1990.

[30] T. Chilimbi, Y. Suzue, J. Apacible, and K. Kalyanaraman.
Project Adam: Building an Efﬁcient and Scalable Deep
Learning Training System. In USENIX OSDI, 2014.

[31] Apache Hadoop. Retrieved 02/08/2017, URL: http:

//hadoop.apache.org.

[32] E. Boutin, J. Ekanayake, W. Lin, B. Shi, J. Zhou, Z. Qian,
M. Wu, and L. Zhou. Apollo: Scalable and Coordinated
Scheduling for Cloud-Scale Computing.
In USENIX
OSDI, 2014.

[33] PASCAL Challenge 2008.

Retrieved 04/20/2017,
http://largescale.ml.tu-berlin.

URL:
de/instructions/.

[34] MNIST Database. Retrieved 04/20/2017, URL: http:

//yann.lecun.com/exdb/mnist/.

[35] Million Song Dataset.

Retrieved 04/20/2017, URL:

https://labrosa.ee.columbia.edu/
millionsong/.

[36] Associated Press Dataset - LDA. Retrieved 04/20/2017,
URL: http://www.cs.columbia.edu/~blei/
lda-c/.

[37] D. Powers. Evaluation: From Precision, Recall and F-
Measure to ROC, Informedness, Markedness & Correla-
tion. Journal of Machine Learning Technologies, 2(1):
37–63, 2011.

[38] O. Alipourfard, H. H. Liu, J. Chen, S. Venkataraman,
M. Yu, and M. Zhang. CherryPick: Adaptively Un-
earthing the Best Cloud Conﬁgurations for Big Data An-
alytics. In USENIX NSDI, 2017.

[39] M. Li, D. G. Andersen, J. W. Park, A. J. Smola,
A. Ahmed, V. Josifovski, J. Long, E. J. Shekita, and B.-Y.
Su. Scaling Distributed Machine Learning with the Pa-
rameter Server. In USENIX OSDI, 2014.

[40] H. Cui, J. Cipar, Q. Ho, J. K. Kim, S. Lee, A. Kumar,
J. Wei, W. Dai, G. R. Ganger, P. B. Gibbons, G. A. Gib-
son, and E. P. Xing. Exploiting Bounded Staleness to
Speed Up Big Data Analytics. In USENIX ATC, 2014.

[41] E. R. Sparks, A. Talwalkar, D. Haas, M. J. Franklin, M. I.
Jordan, and T. Kraska. Automating Model Search for
Large Scale Machine Learning. In ACM SoCC, 2015.

[42] T. Hastie, R. Tibshirani, and J. Friedman. The Elements
of Statistical Learning: Data Mining, Inference and Pre-
diction. Springer, 2nd edition, 2009.

[43] LibSVM Data.

Retrieved

04/20/2017, URL:

https://www.csie.ntu.edu.tw/~cjlin/
libsvmtools/datasets/.

[44] Q. V. Le, R. Monga, M. Devin, G. Corrado, K. Chen,
M. Ranzato, J. Dean, and A. Y. Ng. Building High-
Level Features Using Large Scale Unsupervised Learn-
ing. CoRR, abs/1112.6209, 2011.

[45] K. Ni, R. A. Pearce, K. Boakye, B. V. Essen, D. Borth,
B. Chen, and E. X. Wang. Large-Scale Deep Learning on
the YFCC100M Dataset. CoRR, abs/1502.03409, 2015.
Retrieved 04/20/2017, URL:

[46] Arimo TensorSpark.

https://goo.gl/SYPMIZ.

[47] W. Xiao, J. Xue, Y. Miao, Z. Li, C. Chen, M. Wu, W. Li,
and L. Zhou. Tux²: Distributed Graph Computation for
Machine Learning. In USENIX NSDI, 2017.

[48] P. Moritz, R. Nishihara, I. Stoica, and M. I. Jordan.
SparkNet: Training Deep Networks in Spark. CoRR,
abs/1511.06051, 2015.

[49] N. Boumal, P.-A. Absil, and C. Cartis. Global Rates of
Convergence for Nonconvex Optimization on Manifolds.
ArXiv e-prints, May 2016.

[50] S. Lacoste-Julien. Convergence Rate of Frank-Wolfe for

Non-Convex Objectives. ArXiv e-prints, July 2016.

[51] J. M. Hellerstein, P. J. Haas, and H. J. Wang. Online Ag-

gregation. In ACM SIGMOD, 1997.

[52] C. Jermaine, S. Arumugam, A. Pol, and A. Dobra. Scal-
able Approximate Query Processing with the DBO En-
gine. ACM Transactions on Database Systems, 33(4):23,
2008.

[53] T. Chen, M. Li, Y. Li, M. Lin, N. Wang, M. Wang,
T. Xiao, B. Xu, C. Zhang, and Z. Zhang. MXNet: A
Flexible and Efﬁcient Machine Learning Library for Het-
erogeneous Distributed Systems. CoRR, abs/1512.01274,
2015.

[54] F. Seide and A. Agarwal. CNTK: Microsoft’s Open-

Source Deep-Learning Toolkit. In KDD, 2016.

[55] PyTorch.

Retrieved 04/20/2017, URL: http://

pytorch.org/.

[56] E. Coppa and I. Finocchi. On Data Skewness, Stragglers,
In ACM SoCC,

and MapReduce Progress Indicators.
2015.

[57] L. Amini, N. Jain, A. Sehgal, J. Silber, and O. Verscheure.
Adaptive Control of Extreme-Scale Stream Processing
Systems. In IEEE ICDCS, July 2006.

[58] A. Verma, L. Cherkasova, and R. H. Campbell. ARIA:
Automatic Resource Inference and Allocation for Mapre-
duce Environments. In ICAC, 2011.

[59] S. A. Jyothi, C. Curino, I. Menache, S. M. Narayana-
murthy, A. Tumanov, J. Yaniv, Í. Goiri, S. Krishnan,
J. Kulkarni, and S. Rao. Morpheus: towards automated
SLOs for enterprise clusters. In USENIX OSDI, 2016.

[60] C. Curino, D. E. Difallah, C. Douglas, S. Krishnan, R. Ra-
makrishnan, and S. Rao. Reservation-based Scheduling:
If You’re Late Don’t Blame Us! In ACM SoCC, 2014.

[61] A. D. Ferguson, P. Bodik, S. Kandula, E. Boutin, and
R. Fonseca. Jockey: Guaranteed Job Latency in Data Par-
allel Clusters. In ACM EuroSys, 2012.

[62] E. Wandeler and L. Thiele. Real-time Interfaces for
Interface-based Design of Real-time Systems with Fixed
Priority Scheduling.
In 5th ACM International Confer-
ence on Embedded Software, 2005.

[63] E. D. Jensen, P. Li, and B. Ravindran. On Recent Ad-
vances in Time/Utility Function Real-Time Scheduling
and Resource Management. IEEE International Sympo-
sium on Object and Component-Oriented Real-Time Dis-
tributed Computing, 2005.

[64] R. Johari and J. N. Tsitsiklis. Efﬁciency Loss in a Net-
work Resource Allocation Game. Math. Oper. Res., 29:
407–435, 2004.

[65] F. P. Kelly, A. K. Maulloo, and D. K. H. Tan. Rate Con-
trol for Communication Networks: Shadow Prices, Pro-
portional Fairness and Stability. The Journal of the Oper-
ational Research Society, 49:237–252, 1998.

[66] S. H. Low and D. E. Lapsley.

Optimization
Flow Control—I: Basic Algorithm and Convergence.
IEEE/ACM Transactions on Networking, 7(6):861–874.
[67] H. Zhang, G. Ananthanarayanan, P. Bodik, M. Philipose,
P. Bahl, and M. J. Freedman. Live Video Analytics
at Scale with Approximation and Delay-Tolerance.
In
USENIX NSDI, 2017.

