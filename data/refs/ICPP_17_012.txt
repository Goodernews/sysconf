[1] Y. Shi, A. Karatzoglou, L. Baltrunas, M. Larson, A. Hanjalic,
and N. Oliver, “Tfmap: optimizing map for top-n contextaware recommendation,” in Proceedings of the 35th international ACM SIGIR conference on Research and development
in information retrieval. ACM, 2012, pp. 155-164.

[2] Y. Wang, R. Chen, J. Ghosh, J. C. Denny, A. Kho, Y. Chen,
B. A. Malin, and J. Sun, “Rubik: Knowledge guided tensor
factorization and completion for health data analytics,” in Proceedings of the 21th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining. ACM, 2015, pp.
1265-1274.

[3] H. Fanaee-T and J. Gama, “Tensor-based anomaly detection: An interdisciplinary survey,” Knowledge-Based Systems,
vol. 98, pp. 130-147, 2016.

[4] Q. Zhang, M. W. Berry, B. T. Lamb, and T. Samuel, “A
parallel nonnegative tensor factorization algorithm for mining
global climate data,” in Computational Science-ICCS 2009.
Springer, 2009, pp. 405-415.

[5] A. Cichocki and P. Anh-Huy, “Fast local algorithms for large
scale nonnegative matrix and tensor factorizations,’ IEICE
transactions on fundamentals of electronics, communications
and computer sciences, vol. 92, no. 3, pp. 708-721, 2009.

[6] G. Zhou, A. Cichocki, Q. Zhao, and S. Xie, “Nonnegative
matrix and tensor factorizations: An algorithmic perspective,”
IEEE Signal Processing Magazine, vol. 31, no. 3, pp. 54-65,
2014.

[7] K. Huang, N. D. Sidiropoulos, and A. P. Liavas, “A flexible
and efficient algorithmic framework for constrained matrix
and tensor factorization,” IEEE Transactions on Signal Processing, vol. 64, no. 19, pp. 5052-5065, 2016.

[8] ——, “Efficient algorithms for ‘universally’ constrained matrix and tensor factorization,” in Signal Processing Conference
(EUSIPCO), 2015 23rd European. TYEEE, 2015, pp. 25212525.

[9] T. G. Kolda and B. Bader, “The TOPHITS model for higherorder web link analysis,” in Proceedings of Link Analysis,
Counterterrorism and Security 2006, 2006.

[10] T. G. Kolda and B. W. Bader, “Tensor decompositions and
applications,” SIAM review, vol. 51, no. 3, pp. 455-500, 2009.

[11] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein,
“Distributed optimization and statistical learning via the alternating direction method of multipliers,’ Foundations and
Trends in Machine Learning, vol. 3, no. 1, pp. 1-122, 2011.

[12] A. P. Liavas and N. D. Sidiropoulos, “Parallel algorithms
for constrained tensor factorization via the alternating direction method of multipliers,” arXiv preprint arXiv: 1409.2383,
2014.

[13] R. Kannan, G. Ballard, and H. Park, “A high-performance
parallel algorithm for nonnegative matrix factorization,’ in
Proceedings of the 21st ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming. ACM, 2016,
p. 9.

[14] A. Cichocki, R. Zdunek, A. H. Phan, and S.-i. Amari,
Nonnegative matrix and tensor factorizations: applications
to exploratory multi-way data analysis and blind source
separation. John Wiley & Sons, 2009.

[15] M. Baskaran, B. Meister, and R. Lethin, “Low-overhead loadbalanced scheduling for sparse tensor computations,” in High
Performance Extreme Computing Conference (HPEC), 2014
IEEE, IEEE, 2014, pp. 1-6.

[16] S. Smith, N. Ravindran, N. D. Sidiropoulos, and G. Karypis,
“SPLATT: Efficient and parallel sparse tensor-matrix multiplication,” in International Parallel & Distributed Processing
Symposium (IPDPS’15), 2015.

[17] O. Kaya and B. Ucar, “Scalable sparse tensor decompositions in distributed memory systems,” in Proceedings of the
International Conference for High Performance Computing,
Networking, Storage and Analysis. ACM, 2015, p. 77.

[18] O. Kaya and B. Ugar, “Parallel CP decomposition of sparse
tensors using dimension trees,” Inria - Research Centre
Grenoble - Rhéne-Alpes, Research Report RR-8976, Nov.
2016.

[19] S. Smith, J. Park, and G. Karypis, “Sparse tensor factorization on many-core processors with high-bandwidth memory,”
31st IEEE International Parallel & Distributed Processing
Symposium (IPDPS’1I7), 2017.

[20] J. Li, J. W. Choi, I. Perros, J. Sun, and R. Vuduc, “Modeldriven sparse CP decomposition for higher-order tensors,”
31st IEEE International Parallel & Distributed Processing
Symposium (IPDPS’1I7), 2017.

[21] S. Smith and G. Karypis, “Tensor-matrix products with a
compressed. sparse tensor,” in Proceedings of the 5th Workshop on Irregular Applications: Architectures and Algorithms.
ACM, 2015, p. 7.

[22] G. H. Golub and C. F. Van Loan, Matrix computations. JHU
Press, 2012, vol. 3.

[23] S. Smith and G. Karypis, “A medium-grained algorithm
for distributed sparse tensor factorization,” in 30th IEEE
International Parallel & Distributed Processing Symposium
(UIPDPS’16), 2016.

[24] J. Baumgartner, “Reddit comment dataset,”
https://www.reddit.com/r/datasets/comments/3bxlg7/i_
have_every_publicly_available_reddit_comment/, 2015.

[25] A. Carlson, J. Betteridge, B. Kisiel, B. Settles, E. R. Hruschka, and T. M. Mitchell, “Toward an architecture for neverending language learning,” in In AAAI, 2010.

[26] J. McAuley and J. Leskovec, “Hidden factors and hidden
topics: understanding rating dimensions with review text,” in
Proceedings of the 7th ACM conference on Recommender
systems. ACM, 2013, pp. 165-172.

[27] S. Smith, J. W. Choi, J. Li, R. Vuduc, J. Park, X. Liu,
and G. Karypis. (2017) FROSTT: The formidable repository
of open sparse tensors and tools. [Online]. Available:
http://frostt.io/

[28] S. Smith and G. Karypis, “SPLATT: The Surprisingly ParalleL spArse Tensor Toolkit,” http://cs-umn.edu/~splatt/.