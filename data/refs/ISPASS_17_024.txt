[1] DOE ASCAC Subcommittee, “Top ten exascale research
challenges,” U.S. Department of Energy Office of Science,
Tech. Rep., 2014. Available: http://science.energy.gov/ /media/ascr/ascac/pdf/meetings/20140210/Top10reportFEB14.pdf
[2] N. Binkert et al., “The gem5 simulator,” SIGARCH Comput. Archit.
News, vol. 39, no. 2, pp. 1–7, Aug. 2011.
[3] A. Sandberg et al., “Full speed ahead: Detailed architectural simulation
at near-native speed,” in IEEE Int. Symp. on Workload Characterization,
2015, pp. 183–192.
[4] T. Sherwood et al., “Automatically characterizing large scale program
behavior,” in 10th Int. Conf. on Architectural Support for Programming
Languages and Operating Systems, 2002, pp. 45–57.
[5] R. E. Wunderlich et al., “SMARTS: Accelerating microarchitecture
simulation via rigorous statistical sampling,” in 30th Annual Int. Symp.
on Computer Architecture, 2003, pp. 84–97.
[6] T. Carlson et al., “Sampled simulation of multi-threaded applications,”
in IEEE Int. Symp. on Performance Analysis of Systems and Software,
2013, pp. 2–12.
[7] ——, “BarrierPoint: Sampled simulation of multi-threaded applications,”
in IEEE Int. Symp. on Performance Analysis of Systems and Software,
2014, pp. 2–12.
[8] D. Sunwoo et al., “A structured approach to the simulation, analysis
and characterization of smartphone applications,” in IEEE Int. Symp. on
Workload Characterization, 2013, pp. 113–122.
[9] Y. S. Shao et al., “ISA-independent workload characterization and
its implications for specialized architectures,” in IEEE Int. Symp. on
Performance Analysis of Systems and Software, 2013, pp. 245–255.
[10] E. Blem et al., “Power struggles: Revisiting the RISC vs. CISC debate
on contemporary ARM and x86 architectures,” in IEEE 19th Int. Symp.
on High Performance Computer Architecture, 2013, pp. 1–12.
[11] “Top500 Supercomputer Sites,” http://www.top500.org/.
[12] M. Feldman, “Fujitsu switches horses for Post-K supercomputer, will
ride ARM into exascale.” Available: https://www.top500.org/news/fujitsuswitches-horses-for-post-k-supercomputer-will-ride-arm-into-exascale/
[13] “ARM discloses technical details of the next version of the ARM architecture,” http://www.arm.com/about/newsroom/arm-discloses-technicaldetails-of-the-next-version-of-the-arm-architecture.php, retrieved May
2016.
[14] M. A. Laurenzano et al., “Characterizing the performance-energy tradeoff
of small ARM cores in HPC computation,” in 20th Euro-Par Int. Conf.
on Parallel Processing, 2014, pp. 124–137.
[15] J. Maqbool et al., “Evaluating ARM HPC clusters for scientific
workloads,” Concurrency and Computation: Practice and Experience,
vol. 27, no. 17, pp. 5390–5410, Jul. 2015.
[16] Z. Ou et al., “Energy- and cost-efficiency analysis of ARM-based clusters,”
in 12th IEEE/ACM Int. Symp. on Cluster, Cloud and Grid Computing,
2012, pp. 115–123.
[17] Intel Inc., “Introduction to Intel Advanced Vector Instructions,”
https://software.intel.com/en-us/articles/introduction-to-intel-advancedvector-extensions.
[18] ARM
Ltd.,
“ARM
Neon
SIMD
Engine,”
http://www.arm.com/products/processors/technologies/neon.php.

[19] N. Stephens, “ARMv8-A Next Generation Vector Architecture for HPC,”
in Hot Chips: A Symposium on High Performance Chips, 2016.
[20] Lawrence Livermore National Labs. (2008) ASC sequoia benchmark
codes. Available: https://asc.llnl.gov/sequoia/benchmarks/
[21] ExMatEx. (2013) CoMD: Classical molecular dynamics proxy
application. Available: https://github.com/exmatex/CoMD
[22] R. C. Murphy et al., “Introducing the graph 500,” Cray Users Group
(CUG), 2010. Available: https://github.com/graph500/graph500
[23] J. Dongarra et al., “HPCG benchmark: a new metric for ranking high
performance computing systems,” University of Tennessee, Knoxville,
Tech. Rep. UT-EECS-15-736, 2015. Available: http://www.hpcgbenchmark.org/downloads/hpcg-3.0.tar.gz
[24] M. F. Adams et al., “HPGMG 1.0: A benchmark for ranking
high performance computing systems,” Lawrence Livermore
National Lab, Tech. Rep. LBNL-6630E, 2014. Available:
https://bitbucket.org/hpgmg/hpgmg
[25] I. Karlin et al., “Exploring traditional and emerging parallel
programming models using a proxy application,” in 27th IEEE Int.
Parallel and Distributed Processing Symp., 2013, pp. 1–14. Available:
https://codesign.llnl.gov/lulesh/lulesh2.0.3.tgz
[26] Lawrence Livermore National Lab. (2013) Monte Carlo Benchmark.
Available: https://asc.llnl.gov/CORAL-benchmarks/Throughput/mcb20130723.tar.gz
[27] M. A. Heroux et al., “Improving Performance via Mini-applications,”
Sandia National Laboratories, Tech. Rep. SAND2009-5574, 2009.
Available: http://mantevo.org/downloads/miniFE ref 2.0.html
[28] A. M. Deshpande et al., “PathFinder: A signature-search miniapp
and its runtime characteristics,” in 5th Workshop on Irregular
Applications: Architectures and Algorithms, 2015, pp. 9:1–9:4. Available:
https://mantevo.org/downloads/PathFinder 1.0.0.html
[29] J. R. Tramm et al., “Performance analysis of a reduced data movement
algorithm for neutron cross section data in Monte Carlo simulations,” in
Solving Software Challenges for Exascale. Springer, 2014, pp. 39–56.
Available: https://github.com/ANL-CESAR/RSBench
[30] ——, “XSBench: the development and verification of a performance
abstraction for Monte Carlo reactor analysis,” The Role of Reactor
Physics toward a Sustainable Future (PHYSOR), 2014. Available:
https://github.com/ANL-CESAR/XSBench
[31] S. Browne et al., “A scalable cross-platform infrastructure for application
performance tuning using hardware counters,” in ACM/IEEE Conf. on
Supercomputing, 2000, pp. 42–42.
[32] C.-K. Luk et al., “Pin: Building customized program analysis tools with
dynamic instrumentation,” in ACM SIGPLAN Conf. on Programming
Language Design and Implementation, 2005, pp. 190–200.
