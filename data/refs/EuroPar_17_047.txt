[1] Ali, N., Krishnamoorthy, S., Govind, N., Palmer, B.: A redundant communication

approach to scalable fault tolerance in PGAS programming models. In: 2011 19th

International Euromicro Conference on Parallel, Distributed and Network-Based

Processing, pp. 24–31, February 2011

[2] Amoon, M.: A framework for providing a hybrid fault tolerance in cloud computing.

In: 2015 Science and Information Conference (SAI), pp. 844–849, July 2015

[3] Bent, J., Gibson, G., Grider, G., McClelland, B., Nowoczynski, P., Nunez, J.,

Polte, M., Wingate, M.: PLFS: a checkpoint ﬁlesystem for parallel applications.

In: Proceedings of the Conference on High Performance Computing Networking,

Storage and Analysis, SC 2009, pp. 21:1–21:12. ACM, New York (2009). http://

doi.acm.org/10.1145/1654059.1654081

[4] Breitbart, J., Schmidtobreick, M., Heuveline, V.: Evaluation of the global address

space programming interface (GASPI). In: 2014 IEEE International Parallel Distributed Processing Symposium Workshops (IPDPSW), pp. 717–726, May 2014

[5] Chen, W.Y., et al.: A Performance Analysis of the Berkeley UPC Compiler (2003)

[6] Dun, N., Fujita, H., Fang, A., Liu, Y., Chien, A.A., Balaj, P., Iskra, K., Bland, W.,

Siegel, A.: Flexible error recovery using versions in global view resilience. In: 2015

IEEE International Conference on Cluster Computing, pp. 512–513, September

2015

[7] El-Ghazawi, T., et al.: UPC: Distributed Shared-Memory Programming. Wiley,

Hoboken (2005)

[8] Fajerski, J., et al.: Fast in-memory checkpointing with POSIX API for legacy

exascale-applications. In: SPPEXA Symposium 2016 (2016, accepted for publication)

[9] Gamell, M., Katz, D.S., Kolla, H., Chen, J., Klasky, S., Parashar, M.: Exploring

automatic, online failure recovery for scientiﬁc applications at extreme scales. In:

International Conference for High Performance Computing, Networking, Storage

and Analysis, SC 2014, pp. 895–906, November 2014

[10]  GASPI Forum: GASPI: Global Address Space Programming Interface version 16.1

(2016)

[11]  Machado, R.: (2016). https://github.com/cc-hpc-itwm/gpi cp

[12]  Machado, R., Lojewski, C.: The fraunhofer virtual machine: a communication

library and runtime system based on the RDMA model. Comput. Sci. Res. Dev.

23, 125–132 (2009)

[13]  Numrich, R.W., Reid, J.: Co-array fortran for parallel programming. SIGPLAN

Fortran Forum 17(2), 1–31 (1998). http://doi.acm.org/10.1145/289918.289920

[14]  Rotaru, T.: Best Practice Guide for Writing GASPI-MPI Interoperable Programs

(2016)

[15]  Shahzad, F., et al.: Building a fault tolerant application using the GASPI communication layer. In: 2015 IEEE International Conference on Cluster Computing, pp.

580–587 (2015)

[16]  Vishnu, A., et al.: Fault-tolerant communication runtime support for data-centric

programming models. In: 2010 International Conference on High Performance

Computing, pp. 1–9, December 2010
