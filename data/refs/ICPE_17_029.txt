[1] S. Balsamo, A. D. Marco, P. Inverardi, and M. Simeoni.
Model-based performance prediction in software
development: a survey. IEEE Transactions on Software
Engineering, 30(5), 2004.
[2] V. Bergmann. ContiPerf. http://databene.org/contiperf,
2012.
[3] C. Bezemer, E. Milon, A. Zaidman, and J. Pouwelse.
Detecting and analyzing I/O performance regressions.
Journal of Software: Evolution and Process, 26(12),
2014.
[4] P. Brebner. Thoughts on the ABS Census website crash
on census night (9 August 2016).
http://www.performance-assurance.com.au/thoughtson-the-abs-census-website-crash-on-census-night-9august-2016/, 2016.
[5] L. Bulej et al. Capturing Performance Assumptions
Using Stochastic Performance Logic. In Proc. of ICPE
’12. ACM, 2012.
[6] L. Bulej et al. Unit testing performance with Stochastic
Performance Logic. Accepted for Automated Software
Engineering, 2016.
[7] Clarkware Consulting, Inc. JUnitPerf.
http://clarkware.com/software/JUnitPerf.html, 2009.
[8] E. Daka and G. Fraser. A Survey on Unit Testing
Practices and Problems. In Proc. of ISSRE ’14. IEEE
Computer Society, 2014.
[9] A. B. de Oliveira, J.-C. Petkovich, T. Reidemeister,
and S. Fischmeister. DataMill: Rigorous Performance
Evaluation Made Easy. In Proce. of ICPE ’13. ACM,
2013.
[10] E. Engström and P. Runeson. A Qualitative Survey of
Regression Testing Practices. In Product-Focused
Software Process Improvement. Springer, Berlin,
Heidelberg, 2010.
[11] D. G. Feitelson, E. Frachtenberg, and K. L. Beck.
Development and Deployment at Facebook. IEEE
Internet Computing, 17(4), 2013.
[12] B. George and L. Williams. An Initial Investigation of
Test Driven Development in Industry. In Proc. of SAC
’03. ACM, 2003.
[13] W. Gottesheim. Challenges, Benefits and Best
Practices of Performance Focused DevOps. In Proc. of
LT ’15. ACM, 2015.
[14] M. Greiler, A. v. Deursen, and M.-A. Storey. Test
Confessions: A Study of Testing Practices for Plug-in
Systems. In Proc. of ICSE ’12. IEEE Press, 2012.
[15] C. Heger, J. Happe, and R. Farahbod. Automated Root
Cause Isolation of Performance Regressions During
Software Development. In Proc. of ICPE ’13. ACM,
2013.
[16] V. Horký et al. Performance Regression Unit Testing:
A Case Study. In Computer Performance Engineering,
8168 in LNCS. Springer Berlin Heidelberg, 2013.
[17] G. Jin, L. Song, X. Shi, J. Scherpelz, and S. Lu.
Understanding and Detecting Real-world Performance
Bugs. In Proc. of PLDI ’12. ACM, 2012.
[18] JUnit. JUnit. http://junit.org/, 2006.
[19] G. Kick, C. Decker, P. Duffin, et al. Caliper.
https://github.com/google/caliper, 2015.
[20] P. S. Kochhar, T. F. Bissyandé, D. Lo, and L. Jiang.
Adoption of Software Testing in Open Source
Projects–A Preliminary Study on 50,000 Projects. In
Proc. of CSMR ’13, 2013.
[21] J. Kroß, F. Willnecker, T. Zwickl, and H. Krcmar.
PET: Continuous Performance Evaluation Tool. In
Proc. of QUDOS ’16. ACM, 2016.
[22] M. Linares-Vásquez, C. Vendome, Q. Luo, and
D. Poshyvanyk. How developers detect and fix
performance bottlenecks in Android apps. In Proc. of
ICSME ’15, 2015.
[23] Y. Liu, C. Xu, and S.-C. Cheung. Characterizing and
Detecting Performance Bugs for Smartphone
Applications. In Proc. of ICSE ’14. ACM, 2014.
[24] J. D. McGregor. Test early, test often. The Journal of
Object Technology, 6(4), 2007.
[25] N. Nagappan, E. M. Maximilien, T. Bhat, and
L. Williams. Realizing quality improvement through
test driven development: results and experiences of four
industrial teams. Empirical Software Engineering,
13(3), 2008.
[26] A. Nistor, T. Jiang, and L. Tan. Discovering,
Reporting, and Fixing Performance Bugs. In Proc. of
MSR ’13. IEEE Press, 2013.
[27] Oracle Corporation. Java Microbenchmarking Harness
(JMH).
http://openjdk.java.net/projects/code-tools/jmh/, 2016.
[28] Oracle Corporation, Project Kenai, and Cognisync.
Japex Micro-benchmark Framework.
https://japex.java.net/, 2014.
[29] P. Runeson. A Survey of Unit Testing Practices. IEEE
Softw., 23(4), 2006.
[30] P. Stefan, V. Horký, L. Bulej, and P. Tůma.
Supplementary Material.
http://d3s.mff.cuni.cz/resources/icpe2017, 2017.
[31] TestNG. TestNG. http://testng.org/, 2006.
[32] A. van Hoorn, J. Waller, and W. Hasselbring. Kieker:
A Framework for Application Performance Monitoring
and Dynamic Software Analysis. In Proc. of ICPE ’12.
ACM, 2012.
[33] J. Waller, N. C. Ehmke, and W. Hasselbring. Including
Performance Benchmarks into Continuous Integration
to Enable DevOps. SIGSOFT Softw. Eng. Notes, 40(2),
2015.
[34] J. Walter, A. van Hoorn, H. Koziolek, D. Okanovic,
and S. Kounev. Asking ”What”?, Automating the
”How”?: The Vision of Declarative Performance
Engineering. In Proc. of ICPE ’16. ACM, 2016.
[35] E. J. Weyuker and F. I. Vokolos. Experience with
Performance Testing of Software Systems: Issues, an
Approach, and Case Study. IEEE Trans. Softw. Eng.,
26(12), 2000.
[36] M. Woodside, G. Franks, and D. C. Petriu. The Future
of Software Performance Engineering. In Proc. of
FOSE ’07. IEEE Computer Society, 2007.
