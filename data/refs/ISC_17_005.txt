[1] Hoeﬂer, T., Siebert, C., Lumsdaine, A.: Scalable communication protocols for

dynamic sparse data exchange. In: Proceedings of the 15th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, ser. PPoPP 2010, pp.

159–168. ACM, New York (2010)

[2] Appel, A.W.: An eﬃcient program for many-body simulation. SIAM J. Sci. Stat.

Comput. 6(1), 85–103 (1985)

[3] Greengard, L., Rokhlin, V.: A fast algorithm for particle simulations. J. Comput.

Phys. 73(2), 325–348 (1987)

[4] Beatson, R., Greengard, L.: A short course on fast multipole methods. Wavelets

Multilevel Methods Elliptic PDEs 1, 1–37 (1997)

[5] Lu, B., Cheng, X., Huang, J., McCammon, J.A.: Order N algorithm for computation of electrostatic interactions in biomolecular systems. Proc. Natl. Acad. Sci.

103(51), 19314–19319 (2006)

[6] Yokota, R., Bardhan, J.P., Knepley, M.G., Barba, L.A., Hamada, T.: Biomolecular electrostatics using a fast multipole BEM on up to 512 GPUs and a billion

unknowns. Comput. Phys. Commun. 182(6), 1272–1283 (2011)

[7] Ohno, Y., Yokota, R., Koyama, H., Morimoto, G., Hasegawa, A., Masumoto, G.,

Okimoto, N., Hirano, Y., Ibeid, H., Narumi, T., et al.: Petascale molecular dynamics simulation using the fast multipole method on K computer. Comput. Phys.

Commun. 185(10), 2575–2585 (2014)

[8] Rui, P., Chen, R.: An eﬃcient sparse approximate inverse preconditioning for FMM

implementation. Microw. Opt. Technol. Lett. 49(7), 1746–1750 (2007)

[9] Bédorf, J., Gaburov, E., Zwart, S.P.: A sparse octree gravitational N -body code

that runs entirely on the GPU processor. J. Comput. Phys. 231(7), 2825–2839

(2012)

[10]  Price, D., Monaghan, J.: An energy-conserving formalism for adaptive gravitational

force softening in smoothed particle hydrodynamics and N -body codes. Mon. Not.

R. Astron. Soc. 374(4), 1347–1358 (2007)

[11]  Asanovic, K., Bodik, R., Catanzaro, B.C., Gebis, J.J., Husbands, P., Keutzer, K.,

Patterson, D.A., Plishker, W.L., Shalf, J., Williams, S.W., et al.: The landscape of

parallel computing research: a view from Berkeley. Technical report UCB/EECS2006-183, EECS Department, University of California, Berkeley (2006)

[12]  Warren, M.S., Salmon, J.K.: A fast tree code for many-body problems. Los Alamos

Sci. 22(10), 88–97 (1994)

[13]  Bédorf, J., Gaburov, E., Fujii, M.S., Nitadori, K., Ishiyama, T., Portegies Zwart, S.:

24.77 Pﬂops on a gravitational tree-code to simulate the Milky Way Galaxy with

18600 GPUs. In: Proceedings of the 2014 ACM/IEEE International Conference for

High Performance Computing, Networking, Storage and Analysis, pp. 1–12 (2014)

[14]  Speck, R., Ruprecht, D., Krause, R., Emmett, M., Minion, M., Winkel, M., Gibbon, P.: A massively space-time parallel N -body solver. In: Proceedings of the

International Conference on High Performance Computing, Networking, Storage

and Analysis, p. 92. IEEE Computer Society Press (2012)

[15]  Winkel, M., Speck, R., Hubner, H., Arnold, L., Krause, R., Gibbon, P.: A massively parallel, multi-disciplinary barnes-hut tree code for extreme-scale N -body

simulations. Comput. Phys. Commun. 183(4), 880–889 (2012)

[16]  Lashuk, I., Chandramowlishwaran, A., Langston, H., Nguyen, T.-A., Sampath, R.,

Shringarpure, A., Vuduc, R., Ying, L., Zorin, D., Biros, G.: A massively parallel

adaptive fast multipole method on heterogeneous architectures. Commun. ACM

55(5), 101–109 (2012)

[17]  Zandifar, M., Abdul Jabbar, M., Majidi, A., Keyes, D., Amato, N.M., Rauchwerger, L.: Composing algorithmic skeletons to express high-performance scientiﬁc

applications. In: Proceedings of the 29th ACM on International Conference on

Supercomputing, ser. ICS 2015, pp. 415–424. ACM, New York (2015)

[18]  AbdulJabbar, M., Yokota, R., Keyes, D.: Asynchronous execution of the fast multipole method using charm++. arXiv preprint arXiv:1405.7487 (2014)

[19]  Salmon, J.K.: Parallel hierarchical N-body methods. Ph.D. dissertation, California

Institute of Technology (1991)

[20]  Warren, M.S., Salmon, J.K.: A parallel hashed oct-tree N -body algorithm. In:

Proceedings of the 1993 ACM/IEEE Conference on Supercomputing, pp. 12–21.

ACM (1993)

[21]  Makino, J.: A fast parallel treecode with GRAPE. Publ. Astron. Soc. Jpn. 56,

521–531 (2004)

[22]  Solomonik, E., Kalé, L.V.: Highly scalable parallel sorting. In: Proceedings of

the 2010 IEEE International Symposium on Parallel and Distributed Processing

(IPDPS), pp. 1–12 (2010)

[23]  Haverkort, H.: An inventory of three-dimensional Hilbert space-ﬁlling curves. arXiv

preprint arXiv:1109.2323 (2011)

[24]  Dubinski, J.: A parallel tree code. New Astron. 1, 133–147 (1996)

[25]  Warren, M.S., Salmon, J.K.: Astrophysical N -body simulations using hierarchical tree data structures. In: Proceedings of the 1992 ACM/IEEE Conference on

Supercomputing, ser. Supercomputing 1992, pp. 570–576. IEEE Computer Society

Press, Los Alamitos (1992)

[26]  Lashuk, I., Chandramowlishwaran, A., Langston, H., Nguyen, T.-A., Sampath, R.,

Shringarpure, A., Vuduc, R., Ying, L., Zorin, D., Biros, G.: A massively parallel

adaptive fast multipole method on heterogeneous architectures. In: Proceedings of

the Conference on High Performance Computing Networking, Storage and Analysis

(2009)

[27]  Teng, S.-H.: Provably good partitioning and load balancing algorithms for parallel

adaptive N -body simulation. SIAM J. Sci. Comput. 19(2), 635–656 (1998)

[28]  Yokota, R., Turkiyyah, G., Keyes, D.: Communication complexity of the fast multipole method and its algebraic variants. Supercomput. Front. Innov.: Int. J. 1(1),

63–84 (2014)

[29]  Malhotra, D., Biros, G.: PVFMM: a parallel kernel independent fmm for particle

and volume potentials. Commun. Comput. Phys. 18(3), 808–830 (2015)
