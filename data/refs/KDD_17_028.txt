[1] Yoshua Bengio, Holger Schwenk, Jean-Sébastien Senécal, Fréderic Morin, and Jean-Luc Gauvain. 2006. Neural probabilistic language models. In Innovations in Machine Learning. Springer, 137–186.
[2] David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. the Journal of machine Learning research 3 (2003), 993–1022.
[3] Elia Bruni, Gemma Boleda, Marco Baroni, and Nam-Khanh Tran. 2012. Distribu- tional semantics in technicolor. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1. Association for Computational Linguistics, 136–145.
[4] Ronan Collobert, Jason Weston, Léon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. The Journal of Machine Learning Research 12 (2011), 2493–2537.
[5] Rajarshi Das, Manzil Zaheer, and Chris Dyer. 2015. Gaussian LDA for Topic Models with Word Embeddings.. In ACL (1). 795–804.
[6] Scott Deerwester, Susan T Dumais, George W Furnas, Thomas K Landauer, and Richard Harshman. 1990. Indexing by latent semantic analysis. Journal of the American society for information science 41, 6 (1990), 391.
[7] Chris Ding, Tao Li, and Wei Peng. 2006. Nonnegative matrix factorization and probabilistic latent semantic indexing: Equivalence chi-square statistic, and a hybrid method. In AAAI, Vol. 6. 137–143.
[8] Lev Finkelstein, Evgeniy Gabrilovich, Yossi Matias, Ehud Rivlin, Zach Solan, Gadi Wolfman, and Eytan Ruppin. 2001. Placing search in context: The concept revisited. In Proceedings of the 10th international conference on World Wide Web. ACM, 406–414.
[9] Zellig S Harris. 1954. Distributional structure. Word 10, 2-3 (1954), 146–162.
[10] Felix Hill, Roi Reichart, and Anna Korhonen. 2016. Simlex-999: Evaluating semantic models with (genuine) similarity estimation. Computational Linguistics
(2016).
[11] Thomas Hofmann. 1999. Probabilistic latent semantic indexing. In Proceedings of
the 22nd annual international ACM SIGIR conference on Research and development
in information retrieval. ACM, 50–57.
[12] Eric H Huang, Richard Socher, Christopher D Manning, and Andrew Y Ng. 2012.
Improving word representations via global context and multiple word prototypes.
In ACL (1). 873–882.
[13] Quoc V Le and Tomas Mikolov. 2014. Distributed Representations of Sentences
and Documents.. In ICML, Vol. 14. 1188–1196.
[14] Daniel D Lee and H Sebastian Seung. 2001. Algorithms for non-negative matrix
factorization. In Advances in neural information processing systems. 556–562.
[15] Omer Levy and Yoav Goldberg. 2014. Neural word embedding as implicit matrix
factorization. In Advances in neural information processing systems. 2177–2185.
[16] Omer Levy, Yoav Goldberg, and Israel Ramat-Gan. 2014. Linguistic Regularities
in Sparse and Explicit Word Representations.. In CoNLL. 171–180.
[17] Shaohua Li, Tat-Seng Chua, Jun Zhu, and Chunyan Miao. 2016. Generative topic embedding: a continuous representation of documents. In Proceedings of The
54th Annual Meeting of the Association for Computational Linguistics (ACL).
[18] Yang Liu, Zhiyuan Liu, Tat-Seng Chua, and Maosong Sun. 2015. Topical Word
Embeddings.. In AAAI. 2418–2424.
[19] Thang Luong, Richard Socher, and Christopher D Manning. 2013. Better word
representations with recursive neural networks for morphology.. In CoNLL.
104–113.
[20] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013.
Distributed representations of words and phrases and their compositionality. In
Advances in neural information processing systems. 3111–3119.
[21] Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013. Linguistic Regularities
in Continuous Space Word Representations.. In Hlt-naacl, Vol. 13. 746–751.
[22] David Mimno, Hanna M Wallach, Edmund Talley, Miriam Leenders, and Andrew McCallum. 2011. Optimizing semantic coherence in topic models. In Proceed- ings of the Conference on Empirical Methods in Natural Language Processing.
Association for Computational Linguistics, 262–272.
[23] Dat Quoc Nguyen, Richard Billingsley, Lan Du, and Mark Johnson. 2015. Im-
proving topic models with latent feature word representations. Transactions of
the Association for Computational Linguistics 3 (2015), 299–313.
[24] Liqiang Niu, Xinyu Dai, Jianbing Zhang, and Jiajun Chen. 2015. Topic2Vec: learning distributed representations of topics. In Asian Language Processing
(IALP), 2015 International Conference on. IEEE, 193–196.
[25] Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove:
Global Vectors for Word Representation.. In EMNLP, Vol. 14. 1532–1543.
[26] Kira Radinsky, Eugene Agichtein, Evgeniy Gabrilovich, and Shaul Markovitch. 2011. A word at a time: computing word relatedness using temporal semantic analysis. In Proceedings of the 20th international conference on World wide web.
ACM, 337–346.
[27] Guangxu Xun, Vishrawas Gopalakrishnan, Fenglong Ma, Yaliang Li, Jing Gao, and
Aidong Zhang. 2016. Topic Discovery for Short Texts Using Word Embeddings. In
Data Mining (ICDM), 2016 IEEE 16th International Conference on. IEEE, 1299–1304.
[28] Guangxu Xun, Yaliang Li, Wayne Xin Zhao, Jing Gao, and Aidong Zhang. 2017. A Correlated Topic Model Using Word Embeddings. In Proceedings of the 26th
International Joint Conference on Artificial Intelligence.
[29] Wayne Xin Zhao, Jing Jiang, Jianshu Weng, Jing He, Ee-Peng Lim, Hongfei Yan,
and Xiaoming Li. 2011. Comparing twitter and traditional media using topic models. In Advances in Information Retrieval. Springer, 338–349.
