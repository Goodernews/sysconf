
[1] https://translate.google.com/.
[2] https://www.duolingo.com/.
[3] https://www.facebook.com/translations/.
[4] https://translate.twitter.com/.
[5] http://www.imdb.com/interfaces.
[6] Y. Amsterdamer, Y. Grossman, T. Milo, and

P. Senellart. Crowd mining. In SIGMOD, pages
241–252, 2013.

[7] R. A. Bradley and M. E. Terry. Rank analysis of
incomplete block designs: I. the method of paired
comparisons. Biometrika, 39(3/4):324–345, 1952.

[8] R. Busa-Fekete, B. Sz¨or´enyi, W. Cheng, P. Weng, and

E. H¨ullermeier. Top-k selection based on adaptive
sampling of noisy preferences. In ICML, pages
1094–1102, 2013.

[9] X. Chen, P. N. Bennett, K. Collins-Thompson, and

E. Horvitz. Pairwise ranking aggregation in a
crowdsourced setting. In WSDM, pages 193–202, 2013.
[10] W. Chu and Z. Ghahramani. Preference learning with

gaussian processes. In ICML, pages 137–144, 2005.

[11] E. Ciceri, P. Fraternali, D. Martinenghi, and

M. Tagliasacchi. Crowdsourcing for top-k query
processing over uncertain data. IEEE Trans. Knowl.
Data Eng., 28(1):41–53, 2016.

[12] S. B. Davidson, S. Khanna, T. Milo, and S. Roy.

Using the crowd for top-k and group-by queries. In
ICDT, pages 225–236, 2013.

[13] S. B. Davidson, S. Khanna, T. Milo, and S. Roy.

Top-k and clustering with noisy comparisons. ACM
Trans. Database Syst., 39(4):35:1–35:39, 2014.

[14] P. Diaconis and R. L. Graham. Spearman’s footrule as
a measure of disarray. JRSS: Series B, pages 262–268,
1977.

[15] A. Doan, M. J. Franklin, D. Kossmann, and

T. Kraska. Crowdsourcing applications and platforms:
A data management perspective. Proceedings of the
VLDB Endowment, 4(12):1508–1509, 2011.

[16] C. Dwork, R. Kumar, M. Naor, and D. Sivakumar.
Rank aggregation methods for the web. In WWW,
pages 613–622, 2001.

[17] J. Fan, G. Li, B. C. Ooi, K. Tan, and J. Feng. icrowd:

An adaptive crowdsourcing framework. In SIGMOD,
pages 1015–1030, 2015.

[18] B. Frei. Paid crowdsourcing. Current State & Progress

toward Mainstream Business Use, Smartsheet. com
Report, Smartsheet. com, 9, 2009.

[19] K. Y. Goldberg, T. Roeder, D. Gupta, and C. Perkins.

Eigentaste: A constant time collaborative ﬁltering
algorithm. Inf. Retr., 4(2):133–151, 2001.

[20] A. Gottlieb, R. Hoehndorf, M. Dumontier, and R. B.

Altman. Ranking adverse drug reactions with
crowdsourcing. Journal of medical Internet research,
17(3):e80, 2015.

[21] S. Guo, A. G. Parameswaran, and H. Garcia-Molina.

So who won?: dynamic max discovery with the crowd.
In SIGMOD, pages 385–396, 2012.

[22] C. A. R. Hoare. Algorithm 65: Find. Commun. ACM,

4(7):321–322, July 1961.

[23] R. Hogg, E. Tanis, and D. Zimmerman. Probability
and Statistical Inference. Pearson, 9 edition, 2013.

[24] K. J¨arvelin and J. Kek¨al¨ainen. Cumulated gain-based

evaluation of IR techniques. TOIS, 20(4):422–446,
2002.

[25] J. G. Kemeny. Mathematics without numbers.

Daedalus, 88(4):577–591, 1959.

[26] A. Khan and H. Garcia-Molina. Hybrid strategies for

ﬁnding the max with the crowd. Technical report,
Technical report, 2014.

[27] R. Likert. A technique for the measurement of

attitudes. Arch. Psychol., 140:1–55, 1932.

[28] R. D. Luce. Individual choice behavior : a theoretical

analysis. Wiley, 1959.

[29] A. Marcus, E. Wu, D. R. Karger, S. Madden, and

R. C. Miller. Human-powered sorts and joins.
PVLDB, 5(1):13–24, 2011.

[30] T. Matsui, Y. Baba, T. Kamishima, and H. Kashima.

Crowdordering. In PAKDD, pages 336–347, 2014.

[31] J. Nocedal and S. Wright. Numerical optimization.

Springer Science & Business Media, 2006.

[32] L. Page, S. Brin, R. Motwani, and T. Winograd. The

PageRank citation ranking: bringing order to the web.
Technical Report 422, Stanford InfoLab, Stanford
University, 1999.

[33] V. Polychronopoulos, L. de Alfaro, J. Davis,

H. Garcia-Molina, and N. Polyzotis. Human-powered
top-k lists. In WebDB, pages 25–30, 2013.

[34] J. Snyder. Estimating the distribution of voter

preferences using partially aggregated voting data.
Political Methodol., 13(1):2–5, 2005.

[35] C. Stein. A two-sample test for a linear hypothesis

whose power is independent of the variance.
Ann. Math. Stat., 16(3):243–258, 1945.

[36] L. L. Thurstone. A law of comparative judgement.

Psychol. Rev., 34:273–286, 1927.

[37] P. Venetis and H. Garcia-Molina. Quality control for

comparison microtasks. In CrowdKDD, 2012.
[38] P. Venetis, H. Garcia-Molina, K. Huang, and

N. Polyzotis. Max algorithms in crowdsourcing
environments. In WWW, pages 989–998, 2012.

[39] E. M. Voorhees. Variations in relevance judgments and

the measurement of retrieval eﬀectiveness. Inf.
Process. Manage., 36(5):697–716, 2000.

[40] J. Wang, G. Li, T. Kraska, M. J. Franklin, and

J. Feng. Leveraging transitive relations for
crowdsourced joins. In SIGMOD, pages 229–240, 2013.

[41] P. Ye and D. Doermann. Combining preference and
absolute judgements in a crowd-sourced setting. In
Machine Learning Meets Crowdsourcing, 2013.

[42] J. Yi, R. Jin, S. Jain, and A. K. Jain. Inferring users’
preferences from crowdsourced pairwise comparisons:
A matrix completion approach. In HCOMP, 2013.

[43] O. F. Zaidan and C. Callison-Burch. Crowdsourcing

translation: Professional quality from
non-professionals. In ACL, pages 1220–1229, 2011.
[44] X. Zhang, G. Li, and J. Feng. Crowdsourced top-k

algorithms: An experimental evaluation. Proceedings
of the VLDB Endowment, 9(8):612–623, 2016.

[45] C. Ziegler, S. M. McNee, J. A. Konstan, and

G. Lausen. Improving recommendation lists through
topic diversiﬁcation. In WWW, pages 22–32, 2005.

