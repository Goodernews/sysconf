[1] “Top 500 Supercomputer Sites : 2005-2013,” http://www.top500.org.
[2] M. J. Schulte, M. Ignatowski, G. H. Loh, B. M. Beckmann, W. C.
Brantley, S. Gurumurthi, N. Jayasena, I. Paul, S. K. Reinhardt, and
G. Rodgers, “Achieving exascale capabilities through heterogeneous
computing,” IEEE Micro, vol. 35, no. 4, pp. 26–36, July 2015.
[3] J. Kim and Y. Kim, “HBM: Memory solution for bandwidth-hungry
processors,” in A Symposium on High Performance Chips (HOTCHIPS),
2014.
[4] NVIDIA, “CUDA Programming Guide,” http://docs.nvidia.com/cuda/
cuda-c-programming-guide.
[5] AMD,
“Radeon
Open
Compute
Runtime
1.2,”
https:
//radeonopencompute.github.io/.
[6] HSA Foundation, “HSA Runtime Specification 1.1,” http://www.
hsafoundation.com/standards.
[7] T. Henretty, K. Stock, L.-N. Pouchet, F. Franchetti, J. Ramanujam, and
P. Sadayappan, “Data layout transformation for stencil computations on
short-vector simd architectures,” in Proceedings of the 20th International
Conference on Compiler Construction: Part of the Joint European
Conferences on Theory and Practice of Software, ser. CC’11/ETAPS’11,
2011.
[8] Q. Lu, C. Alias, U. Bondhugula, T. Henretty, S. Krishnamoorthy,
J. Ramanujam, A. Rountev, P. Sadayappan, Y. Chen, H. Lin, and
T. f. Ngai, “Data layout transformation for enhancing data locality on
nuca chip multiprocessors,” in 18th International Conference on Parallel
Architectures and Compilation Techniques (PACT09), 2009.
[9] R. M. Yong Li, Ahmed Abousamra and A. K. Jones, “Compiler-assisted
data distribution and network configuration for chip multiprocessors,”
IEEE Transactions on Parallel and Distributed Systems, vol. 23, no. 11,
pp. 2058–2066, 2012.
[10] W. O. C. Haifeng Xu, Yong Li, L. A. Schaefer, M. M. Bilec, A. K.
Jones, and A. E. Landis, “Improving efficiency of wireless sensor
networks through lightweight in-memory compression,” in 2015 Sixth
International Green and Sustainable Computing Conference (IGSC),
2015, pp. 1–8.
[11] M. M. Baskaran, U. Bondhugula, S. Krishnamoorthy, J. Ramanujam,
A. Rountev, and P. Sadayappan, “A compiler framework for optimization
of affine loop nests for gpgpus,” in Proceedings of the 22nd Annual
International Conference on Supercomputing, ICS 2008, Island of Kos,
Greece, June 7-12, 2008, 2008, pp. 225–234.
[12] S. Lee, S.-J. Min, and R. Eigenmann, “OpenMP to GPGPU: A Compiler
Framework for Automatic Translation and Optimization,” in Proceedings
of the 14th ACM SIGPLAN Symposium on Principles and Practice of
Parallel Programming, ser. PPOPP09, 2009.
[13] J. Liu, W. Ding, O. Jang, and M. Kandemir, “Data Layout Optimization
for GPGPU Architectures,” in Proceedings of the 18th ACM SIGPLAN
Symposium on Principles and Practice of Parallel Programming, ser.
PPoPP ’13, 2013, pp. 283–284.
[14] B. Wu, Z. Zhao, E. Z. Zhang, Y. Jiang, and X. Shen, “Complexity
analysis and algorithm design for reorganizing data to minimize noncoalesced memory accesses on GPU,” in Proceedings of the 18th
ACM SIGPLAN Symposium on Principles and Practice of Parallel
Programming, 2013.
[15] I.-J. Sung, J. A. Stratton, and W.-M. W. Hwu, “Data Layout Transformation Exploiting Memory-level Parallelism in Structured Grid Many-core
Applications,” in 19th International Conference on Parallel Architectures and Compilation Techniques, ser. PACT10, 2010.
[16] S. Che, J. W. Sheaffer, and K. Skadron, “Dymaxion: Optimizing
Memory Access Patterns for Heterogeneous Systems,” in Proceedings
of 2011 International Conference for High Performance Computing,
Networking, Storage and Analysis, ser. SC ’11. New York, NY, USA:
ACM, 2011, pp. 13:1–13:11.
[17] D. Majeti, R. Barik, J. Zhao, M. Grossman, and V. Sarkar, “CompilerDriven Data Layout Transformation for Heterogeneous Platforms,” in
Euro-Par 2013: Parallel Processing Workshops, 2013, pp. 188–197.
[18] D. Majeti, K. S. Meel, R. Barik, and V. Sarkar, “Automatic data layout
generation and kernel mapping for cpu+gpu architectures,” in 25th
International Conference on Compiler Construction, ser. CC 2016. New
York, NY, USA: ACM, 2016, pp. 240–250.
[19] S. Williams, A. Waterman, and D. Patterson, “Roofline: an insightful
visual performance model for multicore architectures,” Commun. ACM,
vol. 52, April 2009.