[1] Matthew D Zeiler and Rob Fergus. Visualizing and under- standing convolutional networks. In European Conference on Computer Vision, pages 818–833. Springer, 2014.
[2] Karen Simonyan and Andrew Zisserman. Very deep convo- lutional networks for large-scale image recognition. arXiv preprint arXiv:1409.1556, 2014.
[3] Yi Sun, Xiaogang Wang, and Xiaoou Tang. Deeply learned face representations are sparse, selective, and robust. In Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition, pages 2892–2900, 2015.
[4] Geoffrey Hinton, Li Deng, et al. Deep neural networks for acoustic modeling in speech recognition: The shared views of four research groups. IEEE Signal Processing Magazine, 29(6):82–97, 2012.
[5] George E Dahl, Dong Yu, Li Deng, and Alex Acero. Context-dependent pre-trained deep neural networks for large-vocabulary speech recognition. IEEE Transactions on Audio, Speech, and Language Processing, 20(1):30–42, 2012.
[6] Volodymyr Mnih, Koray Kavukcuoglu, et al. Playing atari with deep reinforcement learning. arXiv preprint arXiv:1312.5602, 2013.
[7] DavidSilver,AjaHuang,etal.Masteringthegameofgowith deep neural networks and tree search. Nature, 529(7587):484– 489, 2016.
[8] NVIDIA. Nvidia tegra drive px: Self-driving car computer. http://www.nvidia.com/object/drive-px.html, 2015.
[9] Sharan Chetlur, Cliff Woolley, et al. cudnn: Efficient primi- tives for deep learning. arXiv preprint arXiv:1410.0759, 2014. [10] Alex Krizhevsky, Ilya Sutskever, and Geoffrey E Hinton. Im- agenet classification with deep convolutional neural networks. In Advances in neural information processing systems, pages
1097–1105, 2012.
[11] Tianshi Chen, Zidong Du, et al. Diannao: A small-footprint
high-throughput accelerator for ubiquitous machine-learning. In ACM Sigplan Notices, volume 49, pages 269–284. ACM, 2014.
[12] Yunji Chen, Tao Luo, Shaoli Liu, et al. Dadiannao: A machine-learning supercomputer. In Proceedings of the 47th Annual IEEE/ACM International Symposium on Microarchi- tecture, pages 609–622. IEEE Computer Society, 2014.
[13] Daofu Liu, Tianshi Chen, et al. Pudiannao: A polyvalent machine learning accelerator. In ACM SIGARCH Computer Architecture News, volume 43, pages 369–381. ACM, 2015.
[14] Zidong Du, Robert Fasthuber, et al. Shidiannao: shifting vision processing closer to the sensor. In ACM SIGARCH Computer Architecture News, volume 43, pages 92–104. ACM, 2015.
[15] Haohuan Fu, Junfeng Liao, et al. The sunway taihulight supercomputer: system and applications. Science China Information Sciences, pages 1–16, 2016.
[16] https://github.com/THUHPGC/swDNN.
[17] Yangqing Jia, Evan Shelhamer, Jeff Donahue, et al. Caffe:
Convolutional architecture for fast feature embedding. In
Proceedings of the 22nd ACM international conference on
Multimedia, pages 675–678. ACM, 2014.
[18] Martın Abadi, Ashish Agarwal, et al. Tensorflow: Large-scale
machine learning on heterogeneous distributed systems. arXiv
preprint arXiv:1603.04467, 2016.
[19] Andrew Lavin. maxdnn: an efficient convolution kernel for
deep learning with maxwell gpus. arXiv:1501.06633, 2015. [20] Stefan Hadjis, Firas Abuzaid, Ce Zhang, and Christopher Re ́. Caffe con troll: Shallow ideas to speed up deep learning. In Proceedings of the Fourth Workshop on Data analytics in the
Cloud, page 2. ACM, 2015.
[21] Nicolas Vasilache, Jeff Johnson, at al. Fast convolutional
nets with fbfft: A gpu performance evaluation. arXiv preprint
arXiv:1412.7580, 2014.
[22] Andrew Lavin. Fast algorithms for convolutional neural
networks. arXiv preprint arXiv:1509.09308, 2015.
[23] Chen Zhang, Peng Li, Guangyu Sun, Yijin Guan, et al. Opti- mizing fpga-based accelerator design for deep convolutional neural networks. In Proceedings of the 2015 ACM/SIGDA In- ternational Symposium on Field-Programmable Gate Arrays,
pages 161–170. ACM, 2015.
[24] Jiantao Qiu, Jie Wang, et al. Going deeper with embedded
fpga platform for convolutional neural network. In Proceed- ings of the 2016 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays, pages 26–35. ACM, 2016.
[25] Naveen Suda, Vikas Chandra, et al. Throughput-optimized opencl-based fpga accelerator for large-scale convolutional neural networks. In Proceedings of the 2016 ACM/SIGDA In- ternational Symposium on Field-Programmable Gate Arrays, pages 16–25. ACM, 2016.
[26] Chen Zhang, Di Wu, Jiayu Sun, at al. Energy-efficient cnn implementation on a deeply pipelined fpga cluster. In Proceedings of the 2016 International Symposium on Low Power Electronics and Design, pages 326–331. ACM, 2016.
[27] Williams S, Waterman A, Patterson D. Roofline: an insight- ful visual performance model for multicore architectures[J]. Communications of the ACM, 2009, 52(4): 65-76.
