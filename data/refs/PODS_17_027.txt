
[1] P. K. Agarwal, G. Cormode, Z. Huang, J. M. Phillips, Z. Wei,
and K. Yi. Mergeable summaries. ACM Transactions on
Database Systems (TODS), 38(4):26, 2013.
[2] P. Beame, P. Koutris, and D. Suciu. Communication steps for
parallel query processing. In PODS. ACM, 2013.
[3] P. Beame, P. Koutris, and D. Suciu. Skew in parallel query
processing. In PODS. ACM, 2014.
[4] S. Bhojanapalli, P. Jain, and S. Sanghavi. Tighter low-rank
approximation via sampling the leveraged element. In SODA.
SIAM, 2015.
[5] C. Boutsidis, D. Woodruff, and P. Zhong. Optimal principal
component analysis in distributed and streaming models.
STOC, 2016.
[6] K. L. Clarkson and D. P. Woodruff. Numerical linear algebra
in the streaming model. In STOC. ACM, 2009.
[7] K. L. Clarkson and D. P. Woodruff. Low rank approximation
and regression in input sparsity time. In STOC, 2013.
[8] M. B. Cohen, C. Musco, and C. Musco. Input sparsity time
low-rank approximation via ridge leverage score sampling.
arXiv preprint arXiv:1511.07263, 2015.
[9] A. Desai, M. Ghashami, and J. M. Phillips. Improved
practical matrix sketching with guarantees. IEEE
Transactions on Knowledge and Data Engineering,
28(7):1678–1690, 2016.
[10] P. Drineas, R. Kannan, and M. W. Mahoney. Fast monte
carlo algorithms for matrices i: Approximating matrix
multiplication. SIAM Journal on Computing, 36(1):132–157,
2006.
[11] P. Drineas, R. Kannan, and M. W. Mahoney. Fast monte
carlo algorithms for matrices ii: Computing a low-rank
approximation to a matrix. SIAM Journal on Computing,
36(1):158–183, 2006.
[12] P. Drineas, M. W. Mahoney, S. Muthukrishnan, and
T. Sarlós. Faster least squares approximation. Numerische
Mathematik, 117(2):219–249, 2011.
[13] D. P. Dubhashi and A. Panconesi. Concentration of measure
for the analysis of randomized algorithms. Cambridge
University Press, 2009.
[14] D. Feldman, M. Schmidt, and C. Sohler. Turning big data
into tiny data: Constant-size coresets for k-means, pca and
projective clustering. In SODA. SIAM, 2013.
[15] M. Ghashami, E. Liberty, and J. M. Phillips. Efficient
frequent directions algorithm for sparse matrices. KDD,
2016.
[16] M. Ghashami and J. M. Phillips. Relative errors for
deterministic low-rank matrix approximations. In SODA,
pages 707–717. SIAM, 2014.
[17] M. Ghashami, J. M. Phillips, and F. Li. Continuous matrix
approximation on distributed data. Proceedings of the VLDB
Endowment, 7(10):809–820, 2014.
[18] P. B. Gibbons and S. Tirthapura. Estimating simple functions
on the union of data streams. In SPAA. ACM, 2001.
[19] P. B. Gibbons and S. Tirthapura. Distributed streams
algorithms for sliding windows. In SPAA. ACM, 2002.
[20] H. Huang and S. P. Kasiviswanathan. Streaming anomaly
detection using randomized matrix sketching. Proceedings of
the VLDB Endowment, 2015.
[21] Z. Huang and K. Yi. The communication complexity of
distributed epsilon-approximations. In FOCS, 2014.
[22] R. Kannan, S. Vempala, and D. P. Woodruff. Principal
component analysis and higher correlations for distributed
data. In COLT, 2014.
[23] Z. Karnin and E. Liberty. Online pca with spectral bounds. In
Proceedings of the 28th Annual Conference on
Computational Learning Theory (COLT), 2015.
[24] E. Kushilevitz and N. Nisan. Communication Complexity.
Cambridge University Press, 1997.
[25] Y. Liang, M.-F. F. Balcan, V. Kanchanapally, and
D. Woodruff. Improved distributed principal component
analysis. In NIPS, 2014.
[26] Y. Liang, B. Xie, D. Woodruff, L. Song, and M.-F. Balcan.
Communication efficient distributed kernel principal
component analysis.
[27] E. Liberty. Simple and deterministic matrix sketching. In
KDD, pages 581–588. ACM, 2013.
[28] J. Misra and D. Gries. Finding repeated elements. Science of
computer programming, 2(2):143–152, 1982.
[29] J. Nelson and H. L. Nguyên. Osnap: Faster numerical linear
algebra algorithms via sparser subspace embeddings. In
FOCS. IEEE, 2013.
[30] R. I. Oliveira. Sums of random hermitian matrices and an
inequality by rudelson. Electron. Commun. Probab,
15(203-212):26, 2010.
[31] T. Sarlos. Improved approximation algorithms for large
matrices via random projections. In FOCS, 2006.
[32] J. A. Tropp. User-friendly tail bounds for sums of random
matrices. Foundations of Computational Mathematics,
12(4):389–434, 2012.
[33] D. Van Gucht, R. Williams, D. P. Woodruff, and Q. Zhang.
The communication complexity of distributed set-joins with
applications to matrix multiplication. In PODS. ACM, 2015.
[34] Z. Wei, X. Liu, F. Li, S. Shang, X. Du, and J.-R. Wen. Matrix
sketching over sliding windows. SIGMOD, 2016.
[35] D. Woodruff. Low rank approximation lower bounds in
row-update streams. In NIPS, 2014.
[36] S. Yoo, H. Huang, and S. P. Kasiviswanathan. Streaming
spectral clustering. ICDE, 2016.
[37] Y. Zhang, M. Wainwright, and M. Jordan. Distributed
estimation of generalized matrix rank: Efficient algorithms
and lower bounds. In ICML, 2015.
