[1] Privacy by the numbers: A new approach to safeguard-

ing data. Scientiﬁc American, 2012.

[2] Apple tries to peek at user habits without violating

privacy. The Wall Street Journal, 2016.

[3] A. Agarwal, M. J. Wainwright, P. L. Bartlett, and P. K.
Ravikumar. Information-theoretic lower bounds on the
In NIPS,
oracle complexity of convex optimization.
pages 1–9, 2009.

[4] S. Agrawal, J. R. Haritsa, and B. A. Prakash. Frapp: a
framework for high-accuracy privacy-preserving mining.
Data Mining and Knowledge Discovery, 18(1):101–139,
2009.

[5] K. Ball. An elementary introduction to modern convex

geometry. Flavors of geometry, 31:1–58, 1997.

[6] R. Bassily and A. Smith.

Local, private, efﬁcient
protocols for succinct histograms. In STOC, pages 127–
135. ACM, 2015.

[7] R. Bassily, A. Smith, and A. Thakurta. Private empirical
risk minimization: Efﬁcient algorithms and tight error
bounds. In FOCS, pages 464–473. IEEE, 2014.

[8] A. Beimel, K. Nissim, and E. Omri. Distributed private
data analysis: Simultaneously solving how and what. In
CRYPTO, pages 451–468. Springer, 2008.

[9] D. Bertsimas and S. Vempala. Solving convex programs

by random walks. JACM, 51(4):540–556, 2004.

[10] S. Bubeck. Convex optimization: Algorithms and com-
plexity. Foundations and Trends in Machine Learning,
8(3-4):231–357, 2015.

[11] P. B¨urgisser and F. Cucker. Condition: The geometry of
numerical algorithms, volume 349. Springer Science &
Business Media, 2013.

[12] T.-H. H. Chan, E. Shi, and D. Song.

Private and
continual release of statistics. ACM Trans. Inf. Syst.
Secur., 14(3):26, 2011.

[13] K. Chaudhuri, C. Monteleoni, and A. D. Sarwate. Dif-
ferentially private empirical risk minimization. JMLR,
12(Mar):1069–1109, 2011.

[14] J. C. Duchi, M. I. Jordan, and M. J. Wainwright. Local
privacy and statistical minimax rates. In FOCS, pages
429–438. IEEE, 2013.

[15] C. Dwork and A. Roth. The algorithmic foundations
Foundations and Trends in

of differential privacy.
Theoretical Computer Science, 9(3-4):211–407, 2014.

[16] C. Dwork, K. Kenthapadi, F. McSherry, I. Mironov, and
M. Naor. Our data, ourselves: Privacy via distributed
noise generation. In EUROCRYPT, 2006.

[17] C. Dwork, F. McSherry, K. Nissim, and A. Smith.
Calibrating noise to sensitivity in private data analysis.
In TCC, pages 265–284. Springer, 2006.

[18] C. Dwork, M. Naor, T. Pitassi, and G. N. Rothblum.
In

Differential privacy under continual observation.
STOC, pages 715-724, ACM, 2010.
´U. Erlingsson, V. Pihur, and A. Korolova. Rappor:
Randomized aggregatable privacy-preserving ordinal re-
sponse. In CCS, pages 1054–1067. ACM, 2014.

[20] A. Evﬁmievski, J. Gehrke, and R. Srikant. Limiting
privacy breaches in privacy preserving data mining. In
PODS, pages 211–222. ACM, 2003.

[21] V. Feldman, C. Guzman, and S. Vempala. Statistical
query algorithms for stochastic convex optimization.
arXiv:1512.09170, 2015.

[22] M. Hay, V. Rastogi, G. Miklau, and D. Suciu. Boost-
ing the Accuracy of Differentially Private Histograms
Through Consistency. PVLDB, 3(1):1021–1032, 2010.
[23] J. Hsu, S. Khanna, and A. Roth. Distributed private
heavy hitters. In ICALP, pages 461–472. Springer, 2012.
[24] P. Jain, P. Kothari, and A. Thakurta. Differentially

[19]

private online learning. In COLT, pages 24–1, 2012.

[25] S. P. Kasiviswanathan and A. Smith. On the’semantics’
of differential privacy: A bayesian formulation. Journal
of Privacy and Conﬁdentiality, 6(1):1, 2014.

[26] S. P. Kasiviswanathan, H. K. Lee, K. Nissim,
S. Raskhodnikova, and A. Smith. What can we learn
privately? SIAM Journal on Computing, 40(3):793–826,
2011.

[27] M. Kearns. Efﬁcient noise-tolerant learning from statis-

tical queries. JACM, 45(6):983–1006, 1998.

[28] D. Kifer, A. Smith, and A. Thakurta. Private convex
empirical risk minimization and high-dimensional re-
gression. JMLR, 1:41, 2012.

[29] G. Lan. An optimal method for stochastic composite
optimization. Mathematical Programming, 133(1-2):
365–397, 2012.

[30] A. Y. Levin. On an algorithm for the minimization

of convex functions.
volume 160, pages 1244–1247, 1965.

In Soviet Mathematics Doklady,

[31] F. J. MacWilliams and N. J. A. Sloane. The theory of

error correcting codes. Elsevier, 1977.

[32] N. Mishra and M. Sandler. Privacy via pseudorandom

sketches. In SIGMOD, pages 143–152. ACM, 2006.

[33] A. Nemirovski, D.-B. Yudin, and E.-R. Dawson. Prob-
lem complexity and method efﬁciency in optimization.
1982.

[34] Y. Nesterov. Introductory lectures on convex optimiza-
tion: A basic course, volume 87. Springer Science &
Business Media, 2013.

[35] D. J. Newman. Location of the maximum on unimodal

surfaces. JACM, 12(3):395–398, 1965.

[36] Z. Qin, Y. Yang, T. Yu, I. Khalil, X. Xiao, and K. Ren.
Heavy hitter estimation over set-valued data with local
In CCS, pages 192–203. ACM,
differential privacy.
2016.

[37] M. Raginsky and A. Rakhlin. Information-based com-
plexity, feedback and dynamics in convex program-
IEEE Transactions on Information Theory, 57
ming.
(10):7036–7056, 2011.

[38] M. Rudelson and R. Vershynin. The smallest singular
value of a random rectangular matrix. Communications
on Pure and Applied Mathematics, pages 1707 – 1739,
2009.

[39] S. Shalev-Shwartz, O. Shamir, N. Srebro, and K. Srid-
haran. Stochastic Convex Optimization. In COLT, 2009.
[40] O. Shamir and T. Zhang. Stochastic gradient descent
for non-smooth optimization: Convergence results and
optimal averaging schemes. In ICML (1), pages 71–79,
2013.

[41] A. Smith and A. Thakurta. Differentially private model
selection via stability arguments and the robustness of
the lasso. J Mach Learn Res Proc Track, 30:819–850,
2013.

[42] S. Song, K. Chaudhuri, and A. D. Sarwate. Stochastic
gradient descent with differentially private updates. In
GlobalSIP, pages 245–248. IEEE, 2013.

[43] K. Talwar, A. Thakurta, and L. Zhang. Nearly optimal

private lasso. In NIPS, 2015.

[44] A. G. Thakurta and A. Smith.

(nearly) optimal algo-
rithms for private online learning in full-information and
bandit settings. In NIPS, pages 2733–2741, 2013.

[45] R. Vershynin. Introduction to the non-asymptotic anal-

ysis of random matrices. arXiv:1011.3027, 2010.

[46] S. L. Warner. Randomized response: A survey technique
Journal of the
for eliminating evasive answer bias.
American Statistical Association, 60(309):63–69, 1965.
[47] O. Williams and F. McSherry. Probabilistic inference
In NIPS, pages 2451–2459,

and differential privacy.
2010.

[48] Y. Yang and A. Barron.

Information-theoretic deter-
mination of minimax rates of convergence. Annals of
Statistics, pages 1564–1599, 1999.

