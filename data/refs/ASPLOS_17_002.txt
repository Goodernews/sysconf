[1] Nvidia Multi-Process Service. https://docs.nvidia.
com/deploy/pdf/CUDA_Multi_Process_Service_
Overview .pdf.

[2] Profiler User’s Guide. http://docs .nvidia.com/cuda/
profiler-users-guide.

[3] J. Adriaens, K. Compton, N. S. Kim, and M. Schulte. The
Case for GPGPU Spatial Multitasking. In the 18th Interna-
tional Symposium on High Performance Computer Architec-
ture (HPCA), pages 1-12. IEEE, 2012.

[4] P. Aguilera, K. Morrow, and N. S. Kim. QoS-aware Dynamic
Resource Allocation for Spatial-Multitasking GPUs. In the
19th Asia and South Pacific Design Automation Conference
(ASP-DAC), pages 726-731. IEEE, 2014.

[5] J. Anantpur and R. Govindarajan. PRO: Progress Aware GPU
Warp Scheduling Algorithm. In International Parallel and
Distributed Processing Symposium (IPDPS), pages 979-988.
TEEE, 2015.

[6] R. Ausavarungnirun, S. Ghose, O. Kayiran, G. H. Loh, C. R.
Das, M. T. Kandemir, and O. Mutlu. Exploiting Inter-Warp
Heterogeneity to Improve GPGPU Performance. In the 24th
International Conference on Parallel Architectures and Com-
pilation Techniques (PACT), pages 25-38. ACM, 2015.

[7] L. A. Barroso and U. Hélzle. The Case for Energy-
proportional Computing. Computer, (12):33-37, 2007.

[8] L. A. Barroso, J. Dean, and U. Hélzle. Web Search for a
Planet: The Google Cluster Architecture. Micro, 23(2):22-28,
2003.

[9] T. Beisel, T. Wiersema, C. Plessl, and A. Brinkmann. Co-
operative Multitasking for Heterogeneous Accelerators in the
Linux Completely Fair Scheduler. In IEEE International Con-
ference on Application-Specific Systems, Architectures and
Processors (ASAP), pages 223-226. IEEE, 2011.

[10] R. Bittner, E. Ruf, and A. Forin. Direct GPU/FPGA Commu-
nication via PCI Express. Cluster Computing, 17(2):339-348,
2014.

[11] J. Cabezas, L. Vilanova, I. Gelado, T. B. Jablin, N. Navarro,
and W.-m. Hwu. Automatic Execution of Single-GPU Com-
putations across Multiple GPUs. In Proceedings of the 23rd
international conference on Parallel architectures and compi-
lation, pages 467-468. ACM, 2014.

[12] S. Che, M. Boyer, J. Meng, D. Tarjan, J. W. Sheaffer, S.-H.
Lee, and K. Skadron. Rodinia: A Benchmark Suite for Het-
erogeneous Computing. In International Symposium on Work-
load Characterization (HISWC), pages 44-54. IEEE, 2009.

[13] Q. Chen, H. Yang, J. Mars, and L. Tang. Baymax: QoS Aware-
ness and Increased Utilization of Non-Preemptive Accelera-
tors in Warehouse Scale Computers. In Proceedings of the
21th International Conference on Architectural Support for
Programming Languages and Operating Systems (ASPLOS),
pages 681-696, New York, NY, USA, 2016. ACM.

[14] C. Delimitrou and C. Kozyrakis. iBench: Quantifying Inter-
ference for Datacenter Applications. In International Sym-
posium on Workload Characterization (IISWC), pages 23-33.
TEEE, 2013.

30

[15] C. Delimitrou and C. Kozyrakis. Paragon: QoS-aware
Scheduling for Heterogeneous Datacenters. ACM SIGARCH
Computer Architecture News, 41(1):77-88, 2013.

[16] C. Delimitrou and C. Kozyrakis. Quasar: Resource-efficient
and QoS-aware Cluster Management. In Proceedings of the
19th International Conference on Architectural Support for
Programming Languages and Operating Systems (ASPLOS),
pages 127-144, New York, NY, USA, 2014. ACM.

[17] G. Elliott, B. C. Ward, J. H. Anderson, et al. GPUSync: A
Framework for Real-time GPU Management. In the 34th
Real-Time Systems Symposium (RTSS), pages 33-44. IEEE,
2013.

[18] G. A. Elliott and J. H. Anderson. Globally Scheduled Real-
time Multiprocessor Systems with GPUs. Real-Time Systems,
48(1):34-74, 2012.

[19] J. Hauswald, Y. Kang, M. A. Laurenzano, Q. Chen, C. Li,
R. Dreslinski, T. Mudge, J. Mars, and L. Tang. DjiNN and
Tonic: DNN as a Service and Its Implications for Future Ware-
house Scale Computers. In Proceedings of the 42nd Annual
International Symposium on Computer Architecture (ISCA),
pages 27-40, New York, NY, USA, 2015. ACM.

[20] J. Hauswald, M. A. Laurenzano, Y. Zhang, C. Li, A. Rovinski,
A. Khurana, R. Dreslinski, T. Mudge, V. Petrucci, L. Tang,
and J. Mars. Sirius: An Open End-to-End Voice and Vision
Personal Assistant and Its Implications for Future Warehouse
Scale Computers. In Proceedings of the 20th International
Conference on Architectural Support for Programming Lan-
guages and Operating Systems (ASPLOS), pages 223-238,
New York, NY, USA, 2015. ACM.

[21] S. Hong and H. Kim. An Analytical Model for a GPU Ar-
chitecture with Memory-level and Thread-level Parallelism
Awareness. In Proceedings of the 36th Annual International
Symposium on Computer Architecture (ISCA), pages 152-
163, New York, NY, USA, 2009. ACM.

[22] S. Hong and H. Kim. An Integrated GPU Power and Per-
formance Model. In Proceedings of the 37th Annual Inter-
national Symposium on Computer Architecture (ISCA), pages
280-289, New York, NY, USA, 2010. ACM.

[23] N. Jones. The Learning Machines, 2014.

[24] W. Joo and D. Shin. Resource-Constrained Spatial Multi-
tasking for Embedded GPU. In International Conference on
Consumer Electronics (ICCE), pages 339-340. IEEE, 2014.

[25] H. Kasture and D. Sanchez. Ubik: Efficient Cache Sharing
with Strict QoS for Latency-critical Workloads. In Proceed-
ings of the 19th International Conference on Architectural
Support for Programming Languages and Operating Systems
(ASPLOS), pages 729-742, New York, NY, USA, 2014. ACM.

[26] S. Kato, K. Lakshmanan, R. Rajkumar, and Y. Ishikawa.
TimeGraph: GPU Scheduling for Real-time Multi-tasking En-
vironments. In USENIX Annual Technical Conference (ATC),
pages 17-30, 2011.

[27] D. Kirk et al. NVIDIA CUDA Software and GPU Parallel
Computing Architecture. In ISMM, volume 7, pages 103-104,
2007.

[28] M. A. Laurenzano, Y. Zhang, L. Tang, and J. Mars. Protean
code: Achieving Near-free Online Code Transformations for
Warehouse Scale Computers. In Proceedings of the 47th An-
nual IEEE/ACM International Symposium on Microarchitec-
ture (MICRO), pages 558-570. IEEE, 2014.

[29] H. Lee, A. Faruque, and M. Abdullah. GPU-EvR: Run-time
Event-based Real-time Scheduling Framework on GPGPU
Platform. In Design, Automation and Test in Europe Con-
ference and Exhibition (DATE), pages 1-6. IEEE, 2014.

[30] S.-Y. Lee, A. Arunkumar, and C.-J. Wu. CAWA: Coordinated
Warp Scheduling and Cache Prioritization for Critical Warp
Acceleration of GPGPU Workloads. In Proceedings of the
42nd Annual International Symposium on Computer Archi-
tecture (ISCA), pages 515-527. ACM, 2015.

[31] J. Leverich and C. Kozyrakis. Reconciling High Server Uti-
lization and Sub-millisecond Quality-of-Service. In Proceed-
ings of the 9th European Conference on Computer Systems,
page 4. ACM, 2014.

[32] D. Lo, L. Cheng, R. Govindaraju, P. Ranganathan, and
C. Kozyrakis. Heracles: Improving Resource Efficiency at
Scale. In Proceedings of the 42nd Annual International Sym-
posium on Computer Architecture (ISCA), pages 450-462.
ACM, 2015.

[33] J. Mars, L. Tang, R. Hundt, K. Skadron, and M. L. Soffa.
Bubble-Up: Increasing Utilization in Modern Warehouse
Scale Computers via Sensible Co-locations. In Proceedings
of the 44th Annual IEEE/ACM International Symposium on
Microarchitecture (MICRO), pages 248-259, New York, NY,
USA, 2011. ACM.

[34] D. Meisner, B. T. Gold, and T. F. Wenisch. PowerNap: Elim-
inating Server Idle Power. In Proceedings of the 14th Inter-
national Conference on Architectural Support for Program-
ming Languages and Operating Systems, pages 205-216, New
York, NY, USA, 2009. ACM.

[35] K. J. Nesbit, N. Aggarwal, J. Laudon, and J. E. Smith. Fair
Queuing Memory Systems. In the 39th Annual IEEE/ACM In-
ternational Symposium on Microarchitecture (MICRO), pages
208-222. TEEE, 2006.

[36] C. Nvidia. Compute Unified Device Architecture Program-
ming Guide. 2007.

[37] C. NVIDIA. GPU Occupancy Calculator. CUDA SDK, 2010.

[38] S. Pai, M. J. Thazhuthaveetil, and R. Govindarajan. Improving
GPGPU Concurrency with Elastic Kernels. In Proceedings of
the 18th International Conference on Architectural Support
for Programming Languages and Operating Systems (ASP-
LOS), pages 407-418, New York, NY, USA, 2013. ACM.

[39] J. J. K. Park, Y. Park, and S. Mahlke. Chimera: Collaborative
Preemption for Multitasking on a Shared GPU. In Proceed-
ings of the 20th International Conference on Architectural
Support for Programming Languages and Operating Systems
(ASPLOS), pages 593-606. ACM, 2015.

[40] V. Petrucci, M. Laurenzano, J. Doherty, Y. Zhang, D. Mosse,
J. Mars, L. Tang, et al. Octopus-Man: QoS-Driven Task Man-
agement for Heterogeneous Multicores in Warehouse-Scale
Computers. In the 21st International Symposium on High
Performance Computer Architecture (HPCA), pages 246-258.
TEEE, 2015.

[41] R. Phull, C.-H. Li, K. Rao, H. Cadambi, and §. Chakrad-
har. Interference-Driven Resource Management for GPU-
based Heterogeneous Clusters. In Proceedings of the 21st

31

international symposium on High-Performance Parallel and
Distributed Computing (HPDC), pages 109-120. ACM, 2012.

[42] B. Pichai, L. Hsu, and A. Bhattacharjee. Address Translation
for Throughput-Oriented Accelerators. Micro, IEEE, 35(3):
102-113, May 2015.

[43] A. Putnam, A. M. Caulfield, E. S. Chung, D. Chiou, K. Con-
stantinides, J. Demme, H. Esmaeilzadeh, J. Fowers, G. P.
Gopal, J. Gray, et al. A Reconfigurable Fabric for Accelerat-
ing Large-scale Datacenter Services. In the 41st International
Symposium on Computer Architecture (ISCA), pages 13-24.
TEEE, 2014.

[44] T. G. Rogers, M. O’Connor, and T. M. Aamodt. Divergence-
Aware Warp Scheduling. In Proceedings of the 46th An-
nual IEEE/ACM International Symposium on Microarchitec-
ture (MICRO), pages 99-110. ACM, 2013.

[45] K. Sajjapongse, X. Wang, and M. Becchi. A Preemption-
based Runtime to Efficiently Schedule Multi-process Applica-
tions on Heterogeneous Clusters with GPUs. In Proceedings
of the 22nd international symposium on High-performance
Parallel and Distributed Computing (HPDC), pages 179-190.
ACM, 2013.

[46] L. Tang, J. Mars, W. Wang, T. Dey, and M. L. Soffa. Re-
QoS: Reactive Static/Dynamic Compilation for QoS in Ware-
house Scale Computers. In Proceedings of the 18th Interna-
tional Conference on Architectural Support for Programming
Languages and Operating Systems (ASPLOS), pages 89-100,
New York, NY, USA, 2013. ACM.

[47] N. Vijaykumar, G. Pekhimenko, A. Jog, A. Bhowmick,
R. Ausavarungnirun, C. Das, M. Kandemir, T. C. Mowry, and.
O. Mutlu. A Case for Core-assisted Bottleneck Accelera-
tion in GPUs: Enabling Flexible Data Compression with As-
sist Warps. In Proceedings of the 42nd Annual International
Symposium on Computer Architecture (ISCA), pages 41-53.
ACM, 2015.

[48] Z. Wang, J. Yang, R. Melhem, B. Childers, Y. Zhang, and
M. Guo. Simultaneous Multikernel GPU: Multi-tasking
Throughput Processors via Fine-Grained Sharing. In the 22th
International Symposium on High Performance Computer Ar-
chitecture (HIPCA), pages 358-369. IEEE, 2016.

[49] G. Wu, J. L. Greathouse, A. Lyashevsky, N. Jayasena, and
D. Chiou. GPGPU Performance and Power Estimation Us-
ing Machine Learning. In the 21st International Symposium
on High Performance Computer Architecture (HPCA), pages
564-576. IEEE, 2015.

[50] H. Yang, A. Breslow, J. Mars, and L. Tang. Bubble-Flux:
Precise Online QoS Management for Increased Utilization
in Warehouse Scale Computers. In Proceedings of the 40th
Annual International Symposium on Computer Architecture
(ISCA), pages 607-618, New York, NY, USA, 2013. ACM.

[51] G. L. Yuan, A. Bakhoda, and T. M. Aamodt. Complex-
ity Effective Memory Access Scheduling for Many-core Ac-
celerator Architectures. In Proceedings of the 42nd Annual
IEEE/ACM International Symposium on Microarchitecture,
pages 34-44. ACM, 2009.

[52] Y. Zhang and J. D. Owens. A Quantitative Performance Anal-
ysis Model for GPU Architectures. In Proceedings of the 17th
International Symposium on High Performance Computer Ar-
chitecture (HIPCA), pages 382-393. IEEE, 2011.

[53] Y. Zhang, M. Laurenzano, J. Mars, and L. Tang. SMiTe: Pre-
cise QoS Prediction on Real System SMT Processors to Im-
prove Utilization in Warehouse Scale Computers. In Proceed-
ings of the 47th Annual International Symposium on Microar-
chitecture (MICRO), pages 406-418, New York, NY, USA,
2014. ACM.

[54] J. Zhong and B. He. Kernelet: High-throughput GPU Ker-
nel Executions with Dynamic Slicing and Scheduling. IEEE

Transactions on Parallel and Distributed Systems, 25(6):
1522-1532, 2014.