[1] K. Alex, I. Sutskever, and Geoffrey E. Hinton, “Imagenet classiﬁca-
tion with deep convolutional neural networks,” in Proc. In Advances
in neural information processing systems, 2012, pp. 1097–1105.

[2] C. Zhang, P. Li, G. Sun, Y. Guan, B. Xiao, and J. Cong,
“Optimizing FPGA-based accelerator design for deep convolutional
neural networks,” in Proceedings of
the 2015 ACM/SIGDA
International Symposium on Field-Programmable Gate Arrays, ser.
FPGA ’15. New York, NY, USA: ACM, 2015, pp. 161–170.
[Online]. Available: http://doi.acm.org/10.1145/2684746.2689060

[3] V. Gokhale, J. Jin, A. Dundar, B. Martini, and E. Culurciello, “A
240 g-ops/s mobile coprocessor for deep neural networks,” in IEEE
Conference on Computer Vision and Pattern Recognition Workshops
(CVPRW),, June 2014, pp. 696–701.

[4] C. Farabet, C. Poulet, J. Han, and Y. LeCun, “CNP: An FPGA-
based processor for convolutional networks,” in Proc. International
Conference on Field Programmable Logic and Applications (FPL),
Aug 2009, pp. 32–37.

[5] M. D. Zeiler, “Hierarchical convolutional deep learning in computer

vision,” Ph.D. dissertation, New York University, 2014.

[6] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. Girshick,
S. Guadarrama, and T. Darrell, “Caffe: Convolutional architecture
for fast feature embedding,” arXiv preprint arXiv:1408.5093, 2014.
[7] A. Krizhevsky, “Cuda-convnet,” 2012. [Online]. Available: http:

//code.google.com/p/cuda-convnet/

[8] T. Chen, Z. Du, N. Sun, J. Wang, C. Wu, Y. Chen, and
O. Temam, “DianNao: A small-footprint high-throughput accelerator
for ubiquitous machine-learning,” in Proc. 19th International
Conference on Architectural Support for Programming Languages
and Operating Systems, ser. ASPLOS ’14. New York, NY,
USA: ACM, 2014, pp. 269–284.
[Online]. Available: http:
//doi.acm.org/10.1145/2541940.2541967

[9] W. Qadeer, R. Hameed, O. Shacham, P. Venkatesan, C. Kozyrakis,
and M. A. Horowitz, “Convolution engine: Balancing efﬁciency
; ﬂexibility in specialized computing,” in Proc. 40th Annual
International Symposium on Computer Architecture, ser. ISCA ’13.
New York, NY, USA: ACM, 2013, pp. 24–35. [Online]. Available:
http://doi.acm.org/10.1145/2485922.2485925
[10] O. Temam, “A defect-tolerant accelerator

for emerging high-
performance applications,” in Proceedings of
the 39th Annual
ISCA
International Symposium on Computer Architecture, ser.
’12. Washington, DC, USA:
IEEE Computer Society, 2012,
pp. 356–367. [Online]. Available: http://dl.acm.org/citation.cfm?id=
2337159.2337200

[11] Z. Du, R. Fasthuber, T. Chen, P. Ienne, L. Li, T. Luo, X. Feng,
Y. Chen, and O. Temam, “Shidiannao: Shifting vision processing
closer to the sensor,” in 2015 ACM/IEEE 42nd Annual International
Symposium on Computer Architecture (ISCA), June 2015, pp. 92–
104.

[12] H. Song, L. Xingyu, M. Huizi, P. Jing, P. Ardavan, A. H. Mark,
and J. D. William, “Eie: Efﬁcient inference engine on compressed
deep neural network,” in ACM/IEEE 43rd Annual International
Symposium on Computer Architecture (ISCA), June 2016.

[13] Y. Chen, J. Emer, and V. Sze, “Eyeriss: A spatial architecture
for energy-efﬁcient dataﬂow for convolutional neural networks,” in
2016 ACM/IEEE 43rd Annual International Symposium on Computer
Architecture (ISCA), June 2016.

[14] R. Shi, Z. Xu, Z. Sun, M. Peemen, A. Li, H. Corporaal, and D. Wu,
“A locality aware convolutional neural networks accelerator,” in
Proc. Euromicro Conference on Digital System Design (DSD),, Aug
2015, pp. 591–598.

[15] C. Szegedy, W. Liu, Y. Jia, P. Sermanet, S. Reed, D. Anguelov,
D. Erhan, V. Vanhoucke, and A. Rabinovich, “Going deeper with
convolutions,” CoRR, vol. abs/1409.4842, 2014. [Online]. Available:
http://arxiv.org/abs/1409.4842

[16] R. B. Girshick, J. Donahue, T. Darrell, and J. Malik, “Rich
feature hierarchies for accurate object detection and semantic
segmentation,” CoRR, vol. abs/1311.2524, 2013. [Online]. Available:
http://arxiv.org/abs/1311.2524

[17] L. Yang, R. P. Dick, H. Lekatsas, and S. Chakradhar, “Online
memory compression for embedded systems,” ACM Trans. Embed.
Comput. Syst., vol. 9, no. 3, pp. 27:1–27:30, Mar. 2010. [Online].
Available: http://doi.acm.org/10.1145/1698772.1698785

[18] G. Pekhimenko, V. Seshadri, O. Mutlu, M. A. Kozuch, P. B. Gibbons,
and T. C. Mowry, “Base-delta-immediate compression: Practical data
compression for on-chip caches,” in Proc. International Conference
on Parallel Computing Technologies (PACT), 2012.

[19] S. M. Jafri, A. Tajammul, M. Daneshtalab, A. Hemani, K. Paul,
P. Ellervee, J. Plosila, and H. Tenhunen, “Customizable compression
architecture for efﬁcient conﬁguration in CGRAs,” in IEEE 22nd
Annual International Symposium on Field-Programmable Custom
Computing Machines (FCCM), 2014, May 2014, pp. 31–31.

[20] S. Jafri, A. Hemani, K. Paul, J. Plosila, and H. Tenhunen, “Compact
generic intermediate representation (CGIR) to enable late binding in
coarse grained reconﬁgurable architectures,” in Proc. International
Conference on Field-Programmable Technology (FPT),, Dec. 2011,
pp. 1 –6.

[21] M. Peemen, B. Mesman, and H. Corporaal, “Efﬁciency optimization
for a consumer platform,” in

trainable feature extractors

of

in Computer Science,

Advanced Concepts for Intelligent Vision Systems, ser. Lecture
Notes
J. Blanc-Talon, R. Kleihorst,
W. Philips, D. Popescu, and P. Scheunders, Eds. Springer Berlin
Heidelberg, 2011, vol. 6915, pp. 293–304. [Online]. Available:
http://dx.doi.org/10.1007/978-3-642-23687-7 27

[22] M. A. Tajammul, S. M. A. H. Jafri, A. Hemani, J. Plosila,
and H. Tenhunen, “Private conﬁguration environments for efﬁcient
conﬁguration in CGRAs,” in Proc. Application Speciﬁc Systems
Architectures and Processors (ASAP), Washington, D.C., USA, 5–7
June 2013.

[23] M. A. Shami and A. Hemani, “Morphable dpu: Smart and efﬁcient
data path for signal processing applications,” in 2009 IEEE Workshop
on Signal Processing Systems, Oct 2009, pp. 167–172.

[24] M. A. Shami and A. Hemani, “Classiﬁcation of massively parallel
computer architectures,” in 2012 IEEE 26th International Parallel
and Distributed Processing Symposium Workshops PhD Forum, May
2012, pp. 344–351.

[25] M. Millberg, E. Nilsson, R. Thid, and A. Jantsch, “Guaranteed
bandwidth using looped containers in temporally disjoint networks
within the nostrum network on chip,” in Proc. Design, Automation
and Test in Europe Conference and Exhibition, 2004., vol. 2.
IEEE,
2004, pp. 890–895.

[26] S. M. A. H. Jafri, M. Daneshtalab, N. Abbas, G. S. Leon, and
A. Hemani, “Transmap: Transformation based remapping and par-
allelism for high utilization and energy efﬁciency in cgras,” IEEE
Transactions on Computers, vol. PP, no. 99, pp. 1–1, 2016.

[27] M. A. Shami and A. Hemani, “Partially reconﬁgurable interconnec-
tion network for dynamically reprogrammable resource array,” in
2009 IEEE 8th International Conference on ASIC, Oct 2009, pp.
122–125.

[28] N. Farahini, S. Li, M. A. Tajammul, M. A. Shami, G. Chen, A. He-
mani, and W. Ye, “39.9 gops/watt multi-mode cgra accelerator for a
multi-standard basestation,” in 2013 IEEE International Symposium
on Circuits and Systems (ISCAS2013), May 2013, pp. 1448–1451.
[29] S. Jafri, S. Piestrak, K. Paul, A. Hemani, J. Plosila, and H. Tenhunen,
“Energy-aware fault-tolerant cgras addressing application with dif-
ferent reliability needs,” in Digital System Design (DSD), 2013
Euromicro Conference on, Sept 2013, pp. 525–534.

[30] S. M. Jafri, S. J. Piestrak, O. Sentieys, and S. Pillement, “Design
of the coarse-grained reconﬁgurable architecture dart with on-line
error detection,” Microprocessors and Microsystems, vol. 38, no. 2,
pp. 124–136, 2014.

[31] Y. Lecun, L. Bottou, Y. Bengio, and P. Haffner, “Gradient-based
learning applied to document recognition,” Proceedings of the IEEE,
vol. 86, no. 11, pp. 2278–2324, Nov 1998.

[32] M. Peemen, B. Mesman, and C. Corporaal, “Speed sign detection
and recognition by convolutional neural networks,” Proceedings of
the 8th International Automotive Congress, pp. 162–170, 2011.

[33] C. Garcia and M. Delakis, “Convolutional face ﬁnder: a neural
architecture for fast and robust face detection,” IEEE Transactions
on Pattern Analysis and Machine Intelligence,, vol. 26, no. 11, pp.
1408–1423, Nov 2004.

[34] H. Esmaeilzadeh, E. Blem, R. St. Amant, K. Sankaralingam,
end of multicore
and D. Burger,
scaling,”
International
Symposium on Computer Architecture, ser.
ISCA ’11. New
York, NY, USA: ACM, 2011, pp. 365–376. [Online]. Available:
http://doi.acm.org/10.1145/2000064.2000108

“Dark silicon and the

in Proceedings of

the 38th Annual

[35] H. Esmaeilzadeh, A. Sampson, L. Ceze, and D. Burger, “Neural
acceleration for general-purpose approximate programs,” in Interna-
tional Symposium on Microarchitecture (MICRO), 2012 45th Annual
IEEE/ACM, Dec 2012, pp. 449–460.

[36] A. Hemani, N. Farahini, S. M. A. H. Jafri, H. Sohoﬁ, S. Li, and
K. Paul, The SiLago Solution: Architecture and Design Methods for
a Heterogeneous Dark Silicon Aware Coarse Grain Reconﬁgurable
Fabric. Cham: Springer International Publishing, 2017, pp. 47–94.
[Online]. Available: http://dx.doi.org/10.1007/978-3-319-31596-6 3
[37] S. Jafri, M. A. Tajammul, A. Hemani, K. Paul, J. Plosila, and
H. Tenhunen, “Energy-aware-task-parallelism for efﬁcient dynamic
voltage, and frequency scaling, in cgras,” in Embedded Computer
Systems: Architectures, Modeling, and Simulation (SAMOS XIII),
2013 International Conference on, 2013, pp. 104–112.

[38] S. M. A. H. Jafri, O. Ozbak, A. Hemani, N. Farahini, K. Paul,
J. Plosila, and H. Tenhunen, “Energy-aware CGRAs using dynam-
ically reconﬁgurable isolation cells.” in Proc. International sympo-
sium for quality and design (ISQED), 2013, pp. 104–111.


