[1] “Message Passing Interface Forum, http://www.mpi-forum.org/, last accessed 2017/06/20.”
[2] T. Hoefler, R. Rabenseifner, H. Ritzdorf, B. R. de Supinski, R. Thakur,
and J. L. Träff, “The scalable process topology interface of MPI 2.2,”
Concurrency and Computation: Practice and Experience, vol. 23, no. 4,
pp. 293–310, 2011.

[3] T. Hoefler and J. L. Traff, “Sparse collective operations for MPI,” in
Proc. International Symposium on Parallel & Distributed Processing
(IPDPS), 2009, pp. 1–8.
[4] “Nek5000, https://nek5000.mcs.anl.gov/, last accessed 2017/06/20.”
[5] F. Gygi, “Large-scale first-principles molecular dynamics: moving from
terascale to petascale computing,” Journal of Physics: Conference Series,
vol. 46, no. 1, pp. 268–277, 2006.
[6] “MPICH: High-performance and widely portable MPI implementation,
http://http://www.mpich.org/, last accessed 2017/06/20.”
[7] “MVAPICH: MPI over InfiniBand, 10GigE/iWARP and RoCE,
http://mvapich.cse.ohio-state.edu/, last accessed 2017/06/20.”
[8] “Open MPI: Open source high performance computing,
http://www.open-mpi.org/, last accessed 2017/06/20.”
[9] S. H. Mirsadeghi, J. L. Träff, P. Balaji, and A. Afsahi, “Exploiting
common neighborhoods to optimize MPI neighborhood collectives,”
ECE0630. Technical Report, ECE Dept., Queen’s University, Kingston,
ON, Canada, June 2017.
[10] A. Ovcharenko, D. Ibanez, F. Delalondre, O. Sahni, K. E. Jansen,
C. D. Carothers, and M. S. Shephard, “Neighborhood communication
paradigm to increase scalability in large-scale dynamic scientific applications,” Parallel Computing, vol. 38, no. 3, pp. 140–156, 2012.
[11] K. Kandalla, A. Buluç, H. Subramoni, K. Tomko, J. Vienne, L. Oliker,
and D. K. Panda, “Can network-offload based non-blocking neighborhood MPI collectives improve communication overheads of irregular
graph algorithms?” in Proc. International Conference on Cluster Computing Workshops, 2012, pp. 222–230.
[12] A. Buluç and J. R. Gilbert, “The combinatorial BLAS: Design, implementation, and applications,” The International Journal of High
Performance Computing Applications, vol. 25, no. 4, pp. 496–509, 2011.
[13] S. Kumar, P. Heidelberger, D. Chen, and M. Hines, “Optimization of
applications with non-blocking neighborhood collectives via multisends
on the Blue Gene/P supercomputer,” in Proc. International Symposium
on Parallel & Distributed Processing (IPDPS), 2010, pp. 1–11.
[14] S. Kumar, G. Dozsa, G. Almasi, P. Heidelberger, D. Chen, M. E. Giampapa, M. Blocksome, A. Faraj, J. Parker, J. Ratterman, B. Smith, and
C. J. Archer, “The Deep Computing Messaging Framework: Generalized
scalable message passing on the Blue Gene/P supercomputer,” in Proc.
International Conference on Supercomputing (ICS), 2008, pp. 94–103.
[15] T. Hoefler and T. Schneider, “Optimization principles for collective
neighborhood communications,” in Proc. International Conference on
High Performance Computing, Networking, Storage and Analysis (SC),
2012, pp. 98:1–98:10.
[16] J. L. Träff, F. D. Lübbe, A. Rougier, and S. Hunold, “Isomorphic, sparse
MPI-like collective communication operations for parallel stencil computations,” in Proc. European MPI Users’ Group Meeting (EuroMPI),
2015, pp. 10:1–10:10.
[17] J. L. Träff, A. Carpen-Amarie, S. Hunold, and A. Rougier, “Messagecombining algorithms for isomorphic, sparse collective communication,”
arXiv:1606.07676, 2016.
[18] E. Chan, M. Heimlich, A. Purkayastha, and R. V. D. Geijn, “Collective
communication: theory, practice, and experience,” Concurrency and
Computation: Practice and Experience, vol. 19, no. 13, pp. 1749–1783,
2007.
[19] M. Wattenhofer and R. Wattenhofer, “Distributed weighted matching,”
in Proc. International Symposium on Distributed Computing, 2004, pp.
335–348.
[20] J.-H. Hoepman, “Simple distributed weighted matchings,” arXiv preprint
cs/0410047, 2004.
[21] Z. Lotker, B. Patt-Shamir, and S. Pettie, “Improved distributed approximate matching,” J. ACM, vol. 62, no. 5, pp. 38:1–38:17, 2015.
[22] C. Koufogiannakis and N. E. Young, “Distributed algorithms for covering, packing and maximum weighted matching,” Distributed Computing,
vol. 24, no. 1, pp. 45–63, 2011.
[23] C. U. Ileri and O. Dagdeviren, “Performance evaluation of distributed
maximum weighted matching algorithms,” in Proc. International Conference on Digital Information and Communication Technology and its
Applications (DICTAP), 2016, pp. 103–108.
[24] C. L. et al., “Scinet: Lessons learned from building a power-efficient
top-20 system and data centre,” Journal of Physics: Conference Series,
vol. 256, no. 1, 2010.