[1] Dell DVD Store Database Test Suite.

http:/ /linux.dell.com/dvdstore/. Online; accessed 21

February 2017.

[2] Logging control in w3c httpd.

https: //www.w3.org/Daemon/User/Config/

Logging. htmlcommon-logfile-format. Online; accessed

25 September 2016.

[3] Microsoft System Center: Monitors and Rules.

https: //technet.microsoft.com/en
us/library /hh457603(v=sc.12).aspx. Online; accessed

23 February 2017.

[4] Microsoft System Center Operations Manager.

https: //technet.microsoft.com/library /hh205987.aspx.

Online; accessed 21 February 2017.

[5] Nagios - The Industry Standard In IT Infrastructure

Monitoring. https://www.nagios.org/. Online;

accessed 21 February 2017.

[6] Oracle Enterprise Manager 12c.

http:/ /www.oracle.com/technetwork/oem/enterprise
manager /overview /index.html. Online; accessed 21

February 2017.

[7] F. M. Bereznay. Did something change? using

statistical techniques to interpret service and resource

metrics. In Int. CMG Conference, 2006.

[8] J. P. Buzen and A. W. Shum. Masf - multivariate
adaptive statistical filtering. In Int. CMG Conference,
pages 1-10. Computer Measurement Group, 1995.

[9] L. Cherkasova, K. Ozonat, N. Mi, J. Symons, and
E. Smirni. Anomaly? application change? or workload
change? towards automated detection of application
performance anomaly and change. In 2008 IEEE
International Conference on Dependable Systems and
Networks With FTCS and DCC (DSN), pages
452-461, June 2008.

[10] W. A. Florac and A. D. Carleton. Measuring the
Software Process: Statistical Process Control for
Software Process Improvement. Addison-Wesley
Longman Publishing Co., Inc., Boston, MA, USA,
1999.

[11] K. C. Foo, Z. M. Jiang, B. Adams, A. E. Hassan,
Y. Zou, and P. Flora. Mining performance regression
testing repositories for automated performance
analysis. In 2010 10th International Conference on
Quality Software, pages 32-41, July 2010.

[12] M. Harchol-Balter. Performance Modeling and Design
of Computer Systems: Queueing Theory in Action.
Cambridge University Press, New York, NY, USA, Ist
edition, 2013.

[13] S. Iwata and K. Kono. Narrowing down possible
causes of performance anomaly in web applications. In
2010 European Dependable Computing Conference,
pages 185-190, April 2010.

[14] J. D. C. Little. A proof for the queuing formula: L =
Aw. Oper. Res., 9(3):383-387, June 1961.

[15] J. P. Magalhaes and L. M. Silva. Detection of
performance anomalies in web-based applications. In
2010 Ninth IEEE International Symposium on
Network Computing and Applications, pages 60-67,
July 2010.

[16] H. Malik, B. Adams, and A. E. Hassan. Pinpointing
the subsystems responsible for the performance
deviations in a load test. In 2010 IEEE 21st
International Symposium on Software Reliability
Engineering, pages 201-210, Nov 2010.

[17] H. Malik, B. Adams, A. E. Hassan, P. Flora, and

G. Hamann. Using load tests to automatically
compare the subsystems of a large enterprise system.
In 2010 IEEE 34th Annual Computer Software and
Applications Conference, pages 117-126, July 2010.
[18] H. Malik, H. Hemmati, and A. E. Hassan. Automatic
detection of performance deviations in the load testing
of large scale systems. In 2013 35th International
Conference on Software Engineering (ICSE), pages
1012-1021, May 2013.

[19] H. Malik, Z. M. Jiang, B. Adams, A. E. Hassan,

P. Flora, and G. Hamann. Automatic comparison of
lead tests to support the performance analysis of large
enterprise systems. In 2010 14th European Conference
on Software Maintenance and Reengineering, pages
222-231, March 2010.

[20] R. K. Mansharamani, A. Khanapurkar, B. Mathew,
and R. Subramanyan. Performance testing: Far from
steady state. In COMPSAC Workshops, pages
341-346. IEEE Computer Society, 2010.

[21] T. H. Nguyen, B. Adams, Z. M. Jiang, A. E. Hassan,
M. Nasser, and P. Flora. Automated detection of
performance regressions using statistical process
control techniques. In Proceedings of the 3rd
ACM/SPEC International Conference on
Performance Engineering, ICPE °12, pages 299-310,
New York, NY, USA, 2012. ACM.

[22] B. Schroeder, A. Wierman, and M. Harchol-Balter.
Open versus closed: A cautionary tale. In Proceedings
of the 38rd Conference on Networked Systems Design &
Implementation - Volume 3, NSDI’06, pages 18-18,
Berkeley, CA, USA, 2006. USENIX Association.

[23] L. Tang, T. Li, L. Shwartz, F. Pinel, and G. Y.
Grabarnik. An integrated framework for optimizing
automatic monitoring systems in large it
infrastructures. In Proceedings of the 19th ACM
SIGKDD International Conference on Knowledge
Discovery and Data Mining, KDD ’13, pages
1249-1257, New York, NY, USA, 2013. ACM.

[24] I. Trubin. Review of IT Control Chart. Journal of
Emerging Trends in Computing and Information
Sciences, 4(11):857-868, Dec. 2013.

[25] I. Trubin and V. C. Scmg. Capturing workload
pathology by statistical exception detection system. In
Proceedings of the Computer Measurement Group,
2005.

[26] I. A. Trubin. Global and Application Level Exception
Detection System, Based on MASF Technique. In 28th
International Computer Measurement Group
Conference, December 8-13, 2002, Reno, Nevada,
USA, Proceedings, pages 557-566, 2002.

[27] I. A. Trubin and L. Merritt. "Mainframe Global and
Workload Level Statistical Exception Detection
System, Based on MASF”. In 30th International
Computer Measurement Group Conference, December
5-10, 2004, Las Vegas, Nevada, USA, Proceedings,
pages 671-678, 2004.

[28] T. Wilson. What were they thinking: Modeling think
times for performance testing. 2011.