[1] C. L. Abad. Big Data Storage Workload Characterization, Modeling and Synthetic Generation. PhD thesis, University of Illinois at
Urbana-Champaign, 2014.

[2] M. Abd-El-Malek, W. V. Courtright, II, C. Cranor, G. R. Ganger,
J. Hendricks, A. J. Klosterman, M. Mesnier, M. Prasad, B. Salmon,
R. R. Sambasivan, S. Sinnamohideen, J. D. Strunk, E. Thereska,
M. Wachs, and J. J. Wylie. Ursa Minor: Versatile Cluster-based
Storage. In Proceedings of the 4th Conference on USENIX Conference on File and Storage Technologies - Volume 4, FAST’05,
pages 5–5, Berkeley, CA, USA, 2005. USENIX Association.
[3] A. Adya, W. J. Bolosky, M. Castro, G. Cermak, R. Chaiken,
J. R. Douceur, J. Howell, J. R. Lorch, M. Theimer, and R. P.
Wattenhofer. Farsite: Federated, Available, and Reliable Storage
for an Incompletely Trusted Environment. SIGOPS Oper. Syst.
Rev., 36(SI):1–14, Dec. 2002.
[4] R. Agrawal, M. J. Carey, and M. Livny. Concurrency control
performance modeling: Alternatives and implications. ACM Trans.
Database Syst., 12(4):609–654, Nov. 1987.
[5] A. Alexandrov, R. Bergmann, S. Ewen, J.-C. Freytag, F. Hueske,
A. Heise, O. Kao, M. Leich, U. Leser, V. Markl, F. Naumann,
M. Peters, A. Rheinländer, M. J. Sax, S. Schelter, M. Höger,
K. Tzoumas, and D. Warneke. The Stratosphere Platform for Big
Data Analytics. The VLDB Journal, 23(6):939–964, Dec. 2014.
[6] J. Baker, C. Bond, J. C. Corbett, J. Furman, A. Khorlin, J. Larson,
J.-M. Leon, Y. Li, A. Lloyd, and V. Yushprakh. Megastore: Providing scalable, highly available storage for interactive services.
In Proceedings of the Conference on Innovative Data system Research (CIDR), pages 223–234, 2011.
[7] H. Berenson, P. Bernstein, J. Gray, J. Melton, E. O’Neil, and
P. O’Neil. A critique of ansi sql isolation levels. SIGMOD Rec.,
24(2):1–10, May 1995.
[8] Cassandra File System Design. http://www.datastax.com/
dev/blog/cassandra-file-system-design.
[Online; accessed 1-January-2016].
[9] F. Chang, J. Dean, S. Ghemawat, W. C. Hsieh, D. A. Wallach,
M. Burrows, T. Chandra, A. Fikes, and R. E. Gruber. Bigtable:
A Distributed Storage System for Structured Data. ACM Trans.
Comput. Syst., 26(2), 2008.
[10] J. C. Corbett, J. Dean, M. Epstein, A. Fikes, C. Frost, J. J. Furman,
S. Ghemawat, A. Gubarev, C. Heiser, P. Hochschild, W. Hsieh,
S. Kanthak, E. Kogan, H. Li, A. Lloyd, S. Melnik, D. Mwaura,
D. Nagle, S. Quinlan, R. Rao, L. Rolig, Y. Saito, M. Szymaniak, C. Taylor, R. Wang, and D. Woodford. Spanner: Google’s
Globally-distributed Database. In Proceedings of the 10th USENIX
Conference on Operating Systems Design and Implementation,
OSDI’12, pages 251–264, Berkeley, CA, USA, 2012. USENIX
Association.
[11] P. Corbett, D. Feitelson, J.-P. Prost, and S. Baylor. Parallel access
to ﬁles in the Vesta ﬁlesystem. In Supercomputing ’93. Proceedings, pages 472–481, Nov 1993.
[12] E. Corporation. HADOOP IN THE LIFE SCIENCES:An Introduction. https://www.emc.com/collateral/software/
white-papers/h10574-wp-isilon-hadoop-inlifesci.pdf, 2012. [Online; accessed 30-Aug-2015].
[13] Dean, Jeffrey and Ghemawat, Sanjay. Mapreduce: Simpliﬁed data
processing on large clusters. Commun. ACM, 51(1):107–113, Jan.
2008.
[14] J. R. Douceur and J. Howell. Distributed Directory Service in
the Farsite File System. In Proceedings of the 7th Symposium on
Operating Systems Design and Implementation, OSDI ’06, pages
321–334, Berkeley, CA, USA, 2006. USENIX Association.
https://www.elastic.co/products/
[15] Elasticsearch.
elasticsearch. [Online; accessed 1-January-2016].
[16] L. George. HBase: The Deﬁnitive Guide. Deﬁnitive Guide Series.
O’Reilly Media, Incorporated, 2011.
[17] S. Ghemawat, H. Gobioff, and S.-T. Leung. The Google File
System. SIGOPS Oper. Syst. Rev., 37(5):29–43, Oct. 2003.
[18] GiraffaFS. https://github.com/giraffafs/giraffa.
[Online; accessed 1-January-2016].
[19] J. Gray, R. Lorie, G. Putzolu, and I. Traiger. Granularity of
Locks and Degrees of Consistency in a Shared Database. In IFIP
Working Conference on Modelling in Data Base Management
Systems, pages 365–394. IFIP, 1976.
[20] H. S. Gunawi, A. Rajimwale, A. C. Arpaci-Dusseau, and R. H.
Arpaci-Dusseau. SQCK: A Declarative File System Checker. In
Proc. of OSDI’08, pages 131–146. USENIX Association, 2008.
[21] Hammer-Bench: Distributed Metadata Benchmark to HDFS.
https://github.com/smkniazi/hammer-bench. [Online; accessed 1-January-2016].
[22] Hadoop JIRA: Add thread which detects JVM pauses. https:
//issues.apache.org/jira/browse/HADOOP-9618.
[Online; accessed 1-January-2016].
[23] M. P. Herlihy and J. M. Wing. Linearizability: A correctness
condition for concurrent objects. ACM Trans. Program. Lang.
Syst., 12(3):463–492, July 1990.
[24] Hadoop Open Platform-as-a-Service (Hops) is a new distribution of Apache Hadoop with scalable, highly available, customizable metadata. https://github.com/smkniazi/
hammer-bench. [Online; accessed 1-January-2016].
[25] P. Hunt, M. Konar, F. P. Junqueira, and B. Reed. ZooKeeper:
Wait-free Coordination for Internet-scale Systems. In Proceedings
of the 2010 USENIX Conference on USENIX Annual Technical
Conference, USENIXATC’10, pages 11–11, 2010.
[26] F. Hupfeld, T. Cortes, B. Kolbeck, J. Stender, E. Focht, M. Hess,
J. Malo, J. Marti, and E. Cesario. The XtreemFS architecture—a
case for object-based ﬁle systems in Grids. Concurrency and
computation: Practice and experience, 20(17):2049–2060, 2008.
[27] M. Isard, M. Budiu, Y. Yu, A. Birrell, and D. Fetterly. Dryad: Distributed data-parallel programs from sequential building blocks.
In Proceedings of the 2Nd ACM SIGOPS/EuroSys European Conference on Computer Systems 2007, EuroSys ’07, pages 59–72,
New York, NY, USA, 2007. ACM.
[28] C. Johnson, K. Keeton, C. B. Morrey, C. A. N. Soules, A. Veitch,
S. Bacon, O. Batuner, M. Condotta, H. Coutinho, P. J. Doyle,
R. Eichelberger, H. Kiehl, G. Magalhaes, J. McEvoy, P. Nagarajan,
P. Osborne, J. Souza, A. Sparkes, M. Spitzer, S. Tandel, L. Thomas,
and S. Zangaro. From research to practice: Experiences engineering a production metadata database for a scale out ﬁle system. In
Proceedings of the 12th USENIX Conference on File and Storage Technologies, FAST’14, pages 191–198, Berkeley, CA, USA,
2014. USENIX Association.
[29] A. Lakshman and P. Malik. Cassandra: A Decentralized Structured
Storage System. SIGOPS Oper. Syst. Rev., 44(2):35–40, Apr. 2010.
[30] B. W. Lampson. Hints for computer system design. SIGOPS Oper.
Syst. Rev., 17(5):33–48, Oct. 1983.
[31] R. Latham, N. Miller, R. B. Ross, and P. H. Carns. A NextGeneration Parallel File System for Linux Clusters. LinuxWorld
Magazine, January 2004.
[32] LevelDB. http://leveldb.org/. [Online; accessed 1-
January-2016].
[33] E. Levy and A. Silberschatz. Distributed file systems: Concepts
and examples. ACM Computing Surveys, 22:321–374, 1990.
[34] MemSQL, The World’s Fastest Database, In Memory Database,
Column Store Database. http://www.memsql.com/. [Online;
accessed 30-June-2015].
[35] E. L. Miller and R. Katz. RAMA: An Easy-To-Use, HighPerformance Parallel File System. Parallel Computing, 23(4):419–
446, July 1997.
[36] J. H. Morris, M. Satyanarayanan, M. H. Conner, J. H. Howard,
D. S. Rosenthal, and F. D. Smith. Andrew: A Distributed Personal
Computing Environment. Commun. ACM, 29(3):184–201, Mar.
1986.
[37] MySQL Cluster: High Availability. https:
//www.mysql.com/products/cluster/
availability.html. [Online; accessed 23-May-2016].
[38] MySQL Cluster CGE. http://www.mysql.com/
products/cluster/. [Online; accessed 30-June-2015].
[39] M. A. Olson and M. A. The Design and Implementation of the
Inversion File System, 1993.
[40] J. K. Ousterhout, A. R. Cherenson, F. Douglis, M. N. Nelson,
and B. B. Welch. The sprite network operating system. IEEE
Computer, 21:23–36, 1988.
[41] M. Ovsiannikov, S. Rus, D. Reeves, P. Sutter, S. Rao, and J. Kelly.
The Quantcast File System. Proc. VLDB Endow., 6(11):1092–
1101, Aug. 2013.
[42] F. Özcan, N. Tatbul, D. J. Abadi, M. Kornacker, C. Mohan, K. Ramasamy, and J. Wiener. Are We Experiencing a Big Data Bubble?
In Proceedings of the 2014 ACM SIGMOD International Conference on Management of Data, pages 1407–1408, 2014.
[43] S. V. Patil, G. A. Gibson, S. Lang, and M. Polte. GIGA+: Scalable Directories for Shared File Systems. In Proceedings of the
2Nd International Workshop on Petascale Data Storage: Held in
Conjunction with Supercomputing ’07, PDSW ’07, pages 26–29,
New York, NY, USA, 2007. ACM.
[44] B. Pawlowski, C. Juszczak, P. Staubach, C. Smith, D. Lebel, and
D. Hitz. NFS Version 3 - Design and Implementation. In In
Proceedings of the Summer USENIX Conference, pages 137–152,
1994.
[45] D. Peng and F. Dabek. Large-scale incremental processing using distributed transactions and notifications. In Proceedings of
the 9th USENIX Symposium on Operating Systems Design and
Implementation, 2010.
[46] Peter Braam Braam and Michael Callahan. The InterMezzo File
System. In In Proceedings of the 3rd of the Perl Conference,
O’Reilly Open Source Convention, Monterey, CA, USA, 1999.
[47] A. J. Peters and L. Janyst. Exabyte Scale Storage at CERN. Journal of Physics: Conference Series, 331(5):052015, 2011.
[48] I. Polato, R. Ré, A. Goldman, and F. Kon. A comprehensive view
of Hadoop research – A systematic literature review. Journal of
Network and Computer Applications, 46:1–25, 2014.
[49] G. Popek and B. J. Walker. The LOCUS distributed system architecture. MIT Press, 1985.
[50] K. W. Preslan, A. Barry, J. Brassow, R. Cattelan, A. Manthei,
E. Nygaard, S. V. Oort, D. Teigland, M. Tilstra, and et al. Implementing Journaling in a Linux Shared Disk File System, 2000.
[51] K. Ren, Y. Kwon, M. Balazinska, and B. Howe. Hadoop’s adolescence: an analysis of hadoop usage in scientific workloads.
Proceedings of the VLDB Endowment, 6(10):853–864, 2013.
[52] K. Ren, Q. Zheng, S. Patil, and G. Gibson. IndexFS: Scaling File
System Metadata Performance with Stateless Caching and Bulk
Insertion. In Proceedings of the International Conference for High
Performance Computing, Networking, Storage and Analysis, SC
’14, pages 237–248, Piscataway, NJ, USA, 2014. IEEE Press.
[53] O. Rodeh and A. Teperman. zFS - a scalable distributed file system
using object disks. In Mass Storage Systems and Technologies,
2003. (MSST 2003). Proceedings. 20th IEEE/11th NASA Goddard
Conference on, pages 207–218, April 2003.
[54] M. Ronström and J. Oreland. Recovery Principles of MySQL
Cluster 5.1. In Proc. of VLDB’05, pages 1108–1115. VLDB
Endowment, 2005.
[55] RPC Congestion Control with FairCallQueue. https:
//issues.apache.org/jira/browse/HADOOP-9640.
[Online; accessed 1-January-2016].
[56] G. B. Salman Niazi, Mahmoud Ismail and J. Dowling. Leader
Election using NewSQL Systems. In Proc. of DAIS 2015, pages
158 –172. Springer, 2015.
[57] M. Satyanarayanan, J. J. Kistler, P. Kumar, M. E. Okasaki, E. H.
Siegel, David, and C. Steere. Coda: A Highly available File
System for a Distributed Workstation Environment. IEEE Transactions on Computers, 39:447–459, 1990.
[58] Schmuck, Frank and Haskin, Roger. GPFS: A Shared-Disk File
System for Large Computing Clusters. In Proceedings of the 1st
USENIX Conference on File and Storage Technologies, FAST ’02,
Berkeley, CA, USA, 2002. USENIX Association.
[59] M. Seltzer and N. Murphy. Hierarchical File Systems Are Dead.
In Proceedings of the 12th Conference on Hot Topics in Operating Systems, HotOS’09, pages 1–1, Berkeley, CA, USA, 2009.
USENIX Association.
[60] K. Shvachko. Name-node memory size estimates and optimization
proposal. https://issues.apache.org/jira/browse/
HADOOP-1687, August 2007. [Online; accessed 11-Nov-2014].
[61] K. Shvachko, H. Kuang, S. Radia, and R. Chansler. The hadoop
distributed file system. In Proceedings of the 2010 IEEE 26th Symposium on Mass Storage Systems and Technologies (MSST), MSST
’10, pages 1–10, Washington, DC, USA, 2010. IEEE Computer
Society.
[62] K. V. Shvachko. HDFS Scalability: The Limits to Growth. login:
The Magazine of USENIX, 35(2):6–16, Apr. 2010.
[63] HOPS, Software-As-A-Service from SICS’S new datacenter. https://www.swedishict.se/hops-softwareas-a-service-from-sicss-new-datacenter. [Online; accessed 23-May-2016].
[64] M. Srivas, P. Ravindra, U. Saradhi, A. Pande, C. Sanapala, L. Renu,
S. Kavacheri, A. Hadke, and V. Vellanki. Map-Reduce Ready
Distributed File System, 2011. US Patent App. 13/162,439.
[65] The Curse of the Singletons! The Vertical Scalability of Hadoop
NameNode. http://hadoopblog.blogspot.se/2010/
04/curse-of-singletons-vertical.html. [Online;
accessed 30-Aug-2015].
[66] The Lustre Storage Architecture. http://
wiki.lustre.org/manual/LustreManual20_HTML/
UnderstandingLustre.html. [Online; accessed 30-Aug2015].
[67] C. A. Thekkath, T. Mann, and E. K. Lee. Frangipani: A Scalable
Distributed File System. In Proceedings of the Sixteenth ACM
Symposium on Operating Systems Principles, SOSP ’97, pages
224–237, New York, NY, USA, 1997. ACM.
[68] A. Thomson and D. J. Abadi. CalvinFS: Consistent WAN Replication and Scalable Metadata Management for Distributed File
Systems. In 13th USENIX Conference on File and Storage Technologies (FAST 15), pages 1–14, Santa Clara, CA, Feb. 2015.
USENIX Association.
[69] A. Thomson, T. Diamond, S.-C. Weng, K. Ren, P. Shao, and
D. J. Abadi. Calvin: Fast Distributed Transactions for Partitioned
Database Systems. In Proceedings of the 2012 ACM SIGMOD
International Conference on Management of Data, SIGMOD ’12,
pages 1–12, New York, NY, USA, 2012. ACM.
[70] VoltDB Documentation. http://docs.voltdb.com/
ReleaseNotes/. [Online; accessed 30-June-2015].
[71] S. A. Weil, S. A. Brandt, E. L. Miller, D. D. E. Long, and
C. Maltzahn. Ceph: A Scalable, High-performance Distributed
File System. In Proceedings of the 7th Symposium on Operating
Systems Design and Implementation, OSDI ’06, pages 307–320,
Berkeley, CA, USA, 2006. USENIX Association.
[72] S. A. Weil, K. T. Pollack, S. A. Brandt, and E. L. Miller. Dynamic
Metadata Management for Petabyte-Scale File Systems. In Proceedings of the 2004 ACM/IEEE Conference on Supercomputing,
SC ’04, pages 4–, Washington, DC, USA, 2004. IEEE Computer
Society.
[73] Welch, Brent and Unangst, Marc and Abbasi, Zainul and Gibson,
Garth and Mueller, Brian and Small, Jason and Zelenka, Jim and
Zhou, Bin. Scalable Performance of the Panasas Parallel File
System. In Proceedings of the 6th USENIX Conference on File
and Storage Technologies, FAST’08, Berkeley, CA, USA, 2008.
USENIX Association.
[74] WinFS: Windows Future Storage. https://
en.wikipedia.org/wiki/WinFS. [Online; accessed
30-June-2015].
[75] L. Xiao, K. Ren, Q. Zheng, and G. A. Gibson. ShardFS vs.
IndexFS: Replication vs. Caching Strategies for Distributed Metadata Management in Cloud Storage Systems. In Proceedings of
the Sixth ACM Symposium on Cloud Computing, SoCC ’15, pages
236–249, New York, NY, USA, 2015. ACM.
[76] S. Yang, W. B. Ligon III, and E. C. Quarles. Scalable distributed
directory implementation on orange file system. Proc. IEEE Intl.
Wrkshp. Storage Network Architecture and Parallel I/Os (SNAPI),
2011.
[77] M. Zaharia, M. Chowdhury, M. J. Franklin, S. Shenker, and I. Stoica. Spark: Cluster computing with working sets. In Proceedings
of the 2Nd USENIX Conference on Hot Topics in Cloud Computing, HotCloud’10, pages 10–10, Berkeley, CA, USA, 2010.
USENIX Association.
[78] M. Zait and B. Dageville. Method and mechanism for database
partitioning, Aug. 16 2005. US Patent 6,931,390.
