[1] W.-m. W. Hwu, Heterogeneous System Architecture: A New Compute
Platform Infrastructure. Morgan Kaufman, 2015.
[2] Khronos group, “The OpenCL specification,” Version 2.0, 2015.
[3] NVIDIA, “CUDA C programming guide v. 8.0,” September 2016.
[4] J. A. Stratton, C. Rodrigues, I.-J. Sung, N. Obeid, L.-W. Chang,
N. Anssari, G. D. Liu, and W.-m. W. Hwu, “Parboil: A revised
benchmark suite for scientific and commercial throughput computing,”
IMPACT Technical Report, 2012.
[5] S. Che, M. Boyer, J. Meng, D. Tarjan, J. Sheaffer, S.-H. Lee, and
K. Skadron, “Rodinia: A benchmark suite for heterogeneous computing,” in Workload Characterization, IEEE International Symposium on,
pp. 44–54, 2009.
[6] A. Danalis, G. Marin, C. McCurdy, J. S. Meredith, P. C. Roth, K. Spafford, V. Tipparaju, and J. S. Vetter, “The scalable heterogeneous computing (SHOC) benchmark suite,” in Proceedings of the 3rd Workshop on
General-Purpose Computation on Graphics Processing Units, pp. 63–
74, 2010.
[7] Y. Ukidave, F. N. Paravecino, L. Yu, C. Kalra, A. Momeni, Z. Chen,
N. Materise, B. Daley, P. Mistry, and D. Kaeli, “NUPAR: A benchmark suite for modern GPU architectures,” in Proceedings of the
6th ACM/SPEC International Conference on Performance Engineering,
2015.
[8] M. Burtscher, R. Nasre, and K. Pingali, “A quantitative study of irregular
programs on GPUs,” in Workload Characterization, IEEE International
Symposium on, pp. 141–151, 2012.
[9] P. Mistry, Y. Ukidave, D. Schaa, and D. Kaeli, “Valar: A benchmark
suite to study the dynamic behavior of heterogeneous systems,” in
Proceedings of the 6th Workshop on General Purpose Processor Using
Graphics Processing Units, pp. 54–65, 2013.
[10] Y. Sun, X. Gong, A. K. Ziabari, L. Yu, X. Li, S. Mukherjee, C. McCardwell, A. Villegas, and D. Kaeli, “Hetero-Mark, a benchmark suite
for CPU-GPU collaborative computing,” in Workload Characterization,
IEEE International Symposium on, 2016.
[11] S. Mukherjee, X. Gong, L. Yu, C. McCardwell, Y. Ukidave, T. Dao, F. N.
Paravecino, and D. Kaeli, “Exploring the features of OpenCL 2.0,” in
Proceedings of the 3rd International Workshop on OpenCL, pp. 5:1–5:5,
2015.
[12] S. Mukherjee, Y. Sun, P. Blinzer, A. K. Ziabari, and D. Kaeli, “A
comprehensive performance analysis of HSA and OpenCL 2.0,” in
Performance Analysis of Systems and Software, IEEE International
Symposium on, pp. 183–193, 2016.
[13] M. Gupta, D. Das, P. Raghavendra, T. Tye, L. Lobachev, A. Agarwal,
and R. Hegde, “Implementing cross-device atomics in heterogeneous
processors,” in Parallel and Distributed Processing Symposium Workshop, IEEE International, pp. 659–668, 2015.
[14] J. Canny, “A computational approach to edge detection,” Pattern Analysis and Machine Intelligence, IEEE Transactions on, no. 6, pp. 679–698,
1986.
[15] J. Gómez Luna, L.-W. Chang, I.-J. Sung, W.-M. Hwu, and N. Guil, “Inplace data sliding algorithms for many-core architectures,” in Parallel
Processing, 44th International Conference on, pp. 210–219, 2015.
[16] M. A. Fischler and R. C. Bolles, “Random sample consensus: a paradigm
for model fitting with applications to image analysis and automated
cartography,” Communications of the ACM, vol. 24, pp. 381–395, June
1981.
[17] I.-J. Sung, G. Liu, and W.-M. Hwu, “DL: A data layout transformation
system for heterogeneous computing,” in Innovative Parallel Computing,
pp. 1 –11, 2012.
[18] L. Chen, O. Villa, S. Krishnamoorthy, and G. Gao, “Dynamic load
balancing on single- and multi-GPU systems,” in Parallel Distributed
Processing, IEEE International Symposium on, pp. 1–12, 2010.

[19] L. Luo, M. Wong, and W.-m. Hwu, “An effective GPU implementation
of breadth-first search,” in Proceedings of the 47th Design Automation
Conference, pp. 52–55, 2010.
[20] J. Power, J. Hestness, M. Orr, M. Hill, and D. Wood, “gem5-gpu:
A heterogeneous CPU-GPU simulator,” Computer Architecture Letters,
vol. 13, Jan 2014.
[21] RadeonOpenCompute, “ROCm: Platform for GPU enabled HPC and
ultrascale computing.” https://github.com/RadeonOpenCompute/ROCm,
2016.
[22] AMD, “App profiler settings.” http://developer.amd.com/tools-and-sdks/
archive/compute/amd-app-profiler/user-guide/app-profiler-settings/.
[23] S. Kelley. https://github.com/smskelley/canny-opencl.
[24] AMD, “Memory system on Fusion APUs. The benefits of zero copy.”
http://developer.amd.com/wordpress/media/2013/06/1004 final.pdf,
June 2011.
[25] bshaozi, “Compile problem.” https://github.com/RadeonOpenCompute/
hcc/issues/124, September 2016.
[26] B. Reagen, R. Adolf, Y. S. Shao, G. Y. Wei, and D. Brooks, “MachSuite:
Benchmarks for accelerator design and customized architectures,” in
Workload Characterization, IEEE International Symposium on, pp. 110–
119, 2014.
[27] K. L. Spafford, J. S. Meredith, S. Lee, D. Li, P. C. Roth, and J. S. Vetter,
“The tradeoffs of fused memory hierarchies in heterogeneous computing
architectures,” in Proceedings of the 9th conference on Computing
Frontiers, pp. 103–112, 2012.
[28] K. Lee, H. Lin, and W.-c. Feng, “Performance characterization of dataintensive kernels on AMD fusion architectures,” Computer ScienceResearch and Development, vol. 28, no. 2-3, pp. 175–184, 2013.
[29] Q. Zhu, B. Wu, X. Shen, K. Shen, L. Shen, and Z. Wang, “Understanding
co-run performance on CPU-GPU integrated processors: observations,
insights, directions,” Frontiers of Computer Science, pp. 1–17, 2016.
[30] N. Farooqui, I. Roy, Y. Chen, V. Talwar, and K. Schwan, “Accelerating
graph applications on integrated GPU platforms via instrumentationdriven optimizations,” in Proceedings of the ACM International Conference on Computing Frontiers, pp. 19–28, 2016.
[31] V. Garcia-Flores, J. Gómez-Luna, T. Grass, A. Rico, E. Ayguade,
and A. J. Pena, “Evaluating the effect of last-level cache sharing
on integrated GPU-CPU systems with heterogeneous applications,” in
Workload Characterization, IEEE International Symposium on, pp. 1–
10, 2016.
[32] C. Erb, M. Collins, and J. L. Greathouse, “Dynamic buffer overflow detection for gpgpus,” in Proceedings of the 2017 International Symposium
on Code Generation and Optimization, pp. 61–73, 2017.
[33] G. Chen and X. Shen, “Free launch: optimizing GPU dynamic kernel
launches through thread reuse,” in Proceedings of the 48th International
Symposium on Microarchitecture, pp. 407–419, 2015.
[34] J. Wang, N. Rubin, A. Sidelnik, and S. Yalamanchili, “Dynamic thread
block launch: A lightweight execution mechanism to support irregular
applications on GPUs,” in ACM SIGARCH Computer Architecture News,
vol. 43, pp. 528–540, 2015.
[35] H. Wu, D. Li, and M. Becchi, “Compiler-assisted workload consolidation
for efficient dynamic parallelism on GPU,” in Parallel and Distributed
Processing Symposium, 2016 IEEE International, pp. 534–543, 2016.
[36] I. El Hajj, J. Gómez-Luna, C. Li, L.-W. Chang, D. Milojicic, and W.-m.
Hwu, “KLAP: Kernel launch aggregation and promotion for optimizing
dynamic parallelism,” in Microarchitecture (MICRO), 2016 49th Annual
IEEE/ACM International Symposium on, pp. 1–12, IEEE, 2016.
[37] X. Tang, A. Pattnaik, H. Jiang, O. Kayiran, A. Jog, M. I. Sreepathi Pai,
M. T. Kandemir, and C. R. Das, “Controlled kernel launch for dynamic
parallelism in GPUs,”
