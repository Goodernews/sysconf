[1] Diamantino Caseiro and Isabel Trancoso. 2001. On Integrating the Lexicon with
the Language Model. (2001).
[2] D. Caseiro and I. Trancoso. 2001. Transducer composition for "on-the-�y" lexicon
and language model integration. In Automatic Speech Recognition and Understanding, 2001. ASRU ’01. IEEE Workshop on. 393–396. https://doi.org/10.1109/
ASRU.2001.1034667
[3] J. Choi, K. You, and W. Sung. 2010. An FPGA implementation of speech recognition with weighted �nite state transducers. In 2010 IEEE International Conference
on Acoustics, Speech and Signal Processing. 1602–1605. https://doi.org/10.1109/
ICASSP.2010.5495538
[4] Jike Chong, Ekaterina Gonina, and Kurt Keutzer. 2011. E�cient automatic speech
recognition on the gpu. Chapter in GPU Computing Gems Emerald Edition, Morgan
Kaufmann 1 (2011).
[5] VoxForge Speech Corpus. 2009. http://www.voxforge.org.
[6] H. J. G. A. Dol�ng and I. L. Hetherington. 2001. Incremental language models for
speech recognition using �nite-state transducers. In Automatic Speech Recognition
and Understanding, 2001. ASRU ’01. IEEE Workshop on. 194–197. https://doi.org/
10.1109/ASRU.2001.1034620
[7] Z. Du, R. Fasthuber, T. Chen, P. Ienne, L. Li, T. Luo, X. Feng, Y. Chen, and O.
Temam. 2015. ShiDianNao: Shifting vision processing closer to the sensor. In
2015 ACM/IEEE 42nd Annual International Symposium on Computer Architecture
(ISCA). 92–104. https://doi.org/10.1145/2749469.2750389
[8] M. Friesen. 2016. Linux Power Management Optimization on the Nvidia Jetson
Platform. Technical Report. "https://www.socallinuxexpo.org/sites/default/�les/
presentations/scale14x_r27_�nal.pdf"
[9] Alex Graves and Navdeep Jaitly. 2014. Towards End-To-End Speech Recognition with Recurrent Neural Networks. In Proceedings of the 31st International
Conference on Machine Learning (Proceedings of Machine Learning Research),
Eric P. Xing and Tony Jebara (Eds.), Vol. 32. PMLR, Bejing, China, 1764–1772.
http://proceedings.mlr.press/v32/graves14.html
[10] A. Graves, A. r. Mohamed, and G. Hinton. 2013. Speech recognition with deep
recurrent neural networks. In 2013 IEEE International Conference on Acoustics,
Speech and Signal Processing. 6645–6649. https://doi.org/10.1109/ICASSP.2013.
6638947
[11] S. Han, J. Kang, H. Mao, Y. Hu, X. Li, Y. Li, D. Xie, H. Luo, S. Yao, Y. Wang, H.
Yang, and W. J. Dally. 2016. ESE: E�cient Speech Recognition Engine with Sparse
LSTM on FPGA. ArXiv e-prints (Dec. 2016). arXiv:cs.CL/1612.00694
[12] Song Han, Je� Pool, John Tran, and William Dally. 2015. Learning both Weights
and Connections for E�cient Neural Network. In Advances in Neural Information
Processing Systems 28, C. Cortes, N. D. Lawrence, D. D. Lee, M. Sugiyama, and
R. Garnett (Eds.). Curran Associates, Inc., 1135–1143. http://papers.nips.cc/paper/
5784-learning-both-weights-and-connections-for-e�cient-neural-network.
pdf
[13] T. Hori, C. Hori, Y. Minami, and A. Nakamura. 2007. E�cient WFST-Based
One-Pass Decoding With On-The-Fly Hypothesis Rescoring in Extremely Large
Vocabulary Continuous Speech Recognition. IEEE Transactions on Audio, Speech,
and Language Processing 15, 4 (May 2007), 1352–1365. https://doi.org/10.1109/
TASL.2006.889790
[14] K. Hwang and W. Sung. 2014. Fixed-point feedforward deep neural network
design using weights +1, 0, and -1. In 2014 IEEE Workshop on Signal Processing
Systems (SiPS). 1–6. https://doi.org/10.1109/SiPS.2014.6986082
[15] J. R. Johnston and R. A. Rutenbar. 2012. A High-Rate, Low-Power, ASIC Speech
Decoder Using Finite State Transducers. In 2012 IEEE 23rd International Conference
on Application-Speci�c Systems, Architectures and Processors. 77–85. https://doi.
org/10.1109/ASAP.2012.25
[16] S. Li, J. H. Ahn, R. D. Strong, J. B. Brockman, D. M. Tullsen, and N. P. Jouppi. 2009.
McPAT: An integrated power, area, and timing modeling framework for multicore and manycore architectures. In 2009 42nd Annual IEEE/ACM International
Symposium on Microarchitecture (MICRO). 469–480.
[17] Andrej Ljolje, Fernando Pereira, and Michael Riley. 1999. E�cient general lattice
generation and rescoring. In EUROSPEECH.
[18] Y. Miao, M. Gowayyed, and F. Metze. 2015. EESEN: End-to-end speech recognition
using deep RNN models and WFST-based decoding. In 2015 IEEE Workshop
on Automatic Speech Recognition and Understanding (ASRU). 167–174. https:
//doi.org/10.1109/ASRU.2015.7404790
[19] Mehryar Mohri, Fernando Pereira, and Michael Riley. 2002. Weighted �nite-state
transducers in speech recognition. Computer Speech and Language 16, 1 (2002),
69 – 88. https://doi.org/10.1006/csla.2001.0184
[20] V. Panayotov, G. Chen, D. Povey, and S. Khudanpur. 2015. Librispeech: An ASR
corpus based on public domain audio books. In Acoustics, Speech and Signal
Processing (ICASSP), 2015 IEEE International Conference on. 5206–5210. https:
//doi.org/10.1109/ICASSP.2015.7178964
[21] Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej Glembek,
Nagendra Goel, Mirko Hannemann, Petr Motlicek, Yanmin Qian, Petr Schwarz,
Jan Silovsky, Georg Stemmer, and Karel Vesely. 2011. The Kaldi Speech Recognition Toolkit. In IEEE 2011 Workshop on Automatic Speech Recognition and Understanding. IEEE Signal Processing Society. IEEE Catalog No.: CFP11SRW-USB.
[22] Michael Price. 2016. Energy-scalable speech recognition circuits (Doctoral dissertation). In Massachusetts Institute of Technology. http://hdl.handle.net/1721.1/
106090
[23] Michael Price, Anantha Chandrakasan, and James R. Glass. 2016. MemoryE�cient Modeling and Search Techniques for Hardware ASR Decoders. In INTERSPEECH. 1893–1897.
[24] M. Price, J. Glass, and A. P. Chandrakasan. 2015. A 6 mW, 5,000-Word Real-Time
Speech Recognizer Using WFST Models. IEEE Journal of Solid-State Circuits 50, 1
(Jan 2015), 102–112. https://doi.org/10.1109/JSSC.2014.2367818
[25] L. R. Rabiner. 1989. A tutorial on hidden Markov models and selected applications
in speech recognition. Proc. IEEE 77, 2 (Feb 1989), 257–286. https://doi.org/10.
1109/5.18626
[26] Anthony Rousseau, Paul DelÃľglise, and Yannick EstÃĺve. 2014. Enhancing the
TED-LIUM corpus with selected data for language modeling and more TED talks.
In In Proc. LREC. 26–31.
[27] Hamid Tabani, Jose-Maria Arnau, Jordi Tubella, and Antonio Gonzalez. 2017.
Performance Analysis and Optimization of Automatic Speech Recognition. MultiScale Computing Systems, IEEE Transactions on (2017). https://doi.org/10.1109/
TMSCS.2017.2739158
[28] Hamid Tabani, Jose-Maria Arnau, Jordi Tubella, and Antonio Gonzalez. 2017. An
Ultra Low-power Hardware Accelerator for Acoustic Scoring in Speech Recognition. In Parallel Architecture and Compilation Techniques (PACT), 26th International
Conference on. IEEE.
[29] TN-41-01. 2007. Calculating Memory System Power for DDR3, Micron Technology,
Tech. Rep. Technical Report.
[30] TN-53-01. 2016. LPDDR4 Power Calculator, Micron Technology, Tech. Rep. Technical
Report.
[31] Willie Walker, Paul Lamere, Philip Kwok, Bhiksha Raj, Rita Singh, Evandro
Gouvea, Peter Wolf, and Joe Woelfel. 2004. Sphinx-4: A Flexible Open Source
Framework for Speech Recognition. Technical Report. Mountain View, CA, USA.
[32] D. Willett and S. Katagiri. 2002. Recent advances in e�cient decoding combining
on-line transducer composition and smoothed language model incorporation.
In 2002 IEEE International Conference on Acoustics, Speech, and Signal Processing,
Vol. 1. I–713–I–716. https://doi.org/10.1109/ICASSP.2002.5743817
[33] Wayne Xiong, Jasha Droppo, Xuedong Huang, Frank Seide, Mike Seltzer, Andreas Stolcke, Dong Yu, and Geo�rey Zweig. 2016. Achieving Human Parity in Conversational Speech Recognition. CoRR abs/1610.05256 (2016). http:
//arxiv.org/abs/1610.05256
[34] Reza Yazdani, Albert Segura, Jose-Maria Arnau, and Antonio Gonzalez. 2016. An
ultra low-power hardware accelerator for automatic speech recognition. In 2016
49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO).
1–12. https://doi.org/10.1109/MICRO.2016.7783750
[35] Reza Yazdani, Albert Segura, Jose-Maria Arnau, and Antonio Gonzalez. 2017.
Low-Power Automatic Speech Recognition Through a Mobile GPU and a Viterbi
Accelerator. IEEE Micro 37, 1 (Jan 2017), 22–29. https://doi.org/10.1109/MM.2017.
15
[36] K. You, J. Chong, Y. Yi, E. Gonina, C. J. Hughes, Y. K. Chen, W. Sung, and K. Keutzer.
2009. Parallel scalability in speech recognition. IEEE Signal Processing Magazine
26, 6 (November 2009), 124–135. https://doi.org/10.1109/MSP.2009.934124
[37] X. Zhang, J. Trmal, D. Povey, and S. Khudanpur. 2014. Improving deep neural
network acoustic models using generalized maxout networks. In 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP). 215–219.
https://doi.org/10.1109/ICASSP.2014.6853589