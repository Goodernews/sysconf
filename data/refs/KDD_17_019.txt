[1] S. Athey and G. W. Imbens. Machine learning methods for
estimating heterogeneous causal effects. stat, 1050:5, 2015.
[2] S. Athey, G. W. Imbens, and S. Wager. Approximate residual
balancing: De-biased inference of average treatment effects in
high dimensions. arXiv preprint arXiv:1604.07125, 2016.

[3] P. C. Austin. An introduction to propensity score methods
for reducing the effects of confounding in observational studies.
Multivariate behavioral research, 46(3):399–424, 2011.
[4] H. Bang and J. M. Robins. Doubly robust estimation in missing
data and causal inference models. Biometrics, 61(4), 2005.
[5] L. Bottou, J. Peters, J. Q. Candela, D. X. Charles, M. Chickering,
E. Portugaly, D. Ray, P. Y. Simard, and E. Snelson. Counterfactual reasoning and learning systems: the example of computational
advertising. Journal of Machine Learning Research, 14(1):3207–
3260, 2013.
[6] D. Chan, R. Ge, O. Gershony, T. Hesterberg, and D. Lambert.
Evaluating online ad campaigns in a pipeline: causal models at
scale. In Proceedings of the 16th ACM SIGKDD international
conference on Knowledge discovery and data mining, pages 7–16.
ACM, 2010.
[7] K. C. G. Chan, S. C. P. Yam, and Z. Zhang. Globally efficient
non-parametric inference of average treatment effects by empirical
balancing calibration weighting. Journal of the Royal Statistical
Society: Series B (Statistical Methodology), 2015.
[8] V. Chernozhukov, D. Chetverikov, M. Demirer, E. Duflo,
C. Hansen, et al. Double machine learning for treatment and
causal parameters. arXiv preprint arXiv:1608.00060, 2016.
[9] A. Diamond and J. S. Sekhon. Genetic matching for estimating causal effects: A general multivariate matching method for
achieving balance in observational studies. Review of Economics
and Statistics, 95(3):932–945, 2013.
[10] M. H. Farrell. Robust inference on average treatment effects
with possibly more covariates than observations. Journal of
Econometrics, 189(1):1–23, 2015.
[11] J. Hainmueller. Entropy balancing for causal effects: A multivariate reweighting method to produce balanced samples in
observational studies. Political Analysis, 20(1):25–46, 2012.
[12] K. Imai and M. Ratkovic. Covariate balancing propensity score.
Journal of the Royal Statistical Society: Series B (Statistical
Methodology), 76(1):243–263, 2014.
[13] G. W. Imbens and D. B. Rubin. Causal inference in statistics,
social, and biomedical sciences. Cambridge University Press,
2015.
[14] R. Kohavi and R. Longbotham. Unexpected results in online
controlled experiments. ACM SIGKDD Explorations Newsletter,
12(2):31–35, 2011.
[15] K. Kuang, P. Cui, B. Li, M. Jiang, S. Yang, and F. Wang. Treatment effect estimation with data-driven variable decomposition.
In Proceedings of the 31st AAAI Conference on Artificial Intelligence. AAAI, 2017.
[16] K. Kuang, M. Jiang, P. Cui, and S. Yang. Steering social media
promotions with effective strategies. In Data Mining (ICDM),
2016 IEEE 16th International Conference on. IEEE, 2016.
[17] R. J. LaLonde. Evaluating the econometric evaluations of training
programs with experimental data. The American economic
review, pages 604–620, 1986.
[18] D. F. McCaffrey, G. Ridgeway, and A. R. Morral. Propensity
score estimation with boosted regression for evaluating causal
effects in observational studies. Psychological methods, 9(4):403,
2004.
[19] N. Parikh, S. P. Boyd, et al. Proximal algorithms. Foundations
and Trends in optimization, 1(3):127–239, 2014.
[20] H. Peng, F. Long, and C. Ding. Feature selection based on
mutual information criteria of max-dependency, max-relevance,
and min-redundancy. IEEE Transactions on pattern analysis
and machine intelligence, 27(8):1226–1238, 2005.
[21] C. A. Rolling and Y. Yang. Model selection for estimating treatment effects. Journal of the Royal Statistical Society: Series B
(Statistical Methodology), 76(4):749–769, 2014.
[22] P. R. Rosenbaum and D. B. Rubin. The central role of the propensity score in observational studies for causal effects. Biometrika,
70(1):41–55, 1983.
[23] R. M. Shiffrin. Drawing causal inference from big data, 2016.
[24] K. Torkkola. Feature extraction by non-parametric mutual information maximization. Journal of machine learning research,
3(Mar):1415–1438, 2003.
[25] D. Westreich, J. Lessler, and M. J. Funk. Propensity score estimation: neural networks, support vector machines, decision trees
(cart), and meta-classifiers as alternatives to logistic regression.
Journal of clinical epidemiology, 63(8):826–833, 2010.
[26] J. R. Zubizarreta. Stable weights that balance covariates for estimation with incomplete outcome data. Journal of the American
Statistical Association, 110(511):910–922, 2015.

