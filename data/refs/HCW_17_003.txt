[1] J. Dean and S. Ghemawat, “Mapreduce: simplified data
processing on large clusters,” Communications of the ACM,
vol. 51, no. 1, pp. 107–113, 2008.
[2] A. Acharya and S. Setia, “Availability and utility of idle
memory in workstation clusters,” in ACM SIGMETRICS
Performance Evaluation Review, vol. 27, no. 1. ACM, 1999,
pp. 35–46.
[3] R. Birke, L. Y. Chen, and E. Smirni, “Usage patterns in multitenant data centers: A temporal perspective,” in Proceedings
of the 9th International Conference on Autonomic Computing,
ser. ICAC ’12. ACM, 2012.

[4] H. Li, A. Ghodsi, M. Zaharia, S. Shenker, and I. Stoica,
“Tachyon: Reliable, memory speed storage for cluster computing frameworks,” in Proceedings of the ACM Symposium
on Cloud Computing. ACM, 2014, pp. 1–15.

[5] T. Newhall, E. R. Lehman-Borer, and B. Marks, “Nswap2l:
Transparently managing heterogeneous cluster storage resources for fast swapping,” in Proceedings of the Second
International Symposium on Memory Systems, ser. MEMSYS
’16, 2016.

[6] T. E. Anderson, D. E. Culler, and D. A. Patterson, “A case
for now (networks of workstations),” Micro, IEEE, vol. 15,
no. 1, pp. 54–64, 1995.

[7] A. Acharya, G. Edjlali, and J. Saltz, “The utility of exploiting
idle workstations for parallel computation,” in ACM SIGMETRICS Performance Evaluation Review, vol. 25, no. 1. ACM,
1997, pp. 225–234.

[8] D. Nevarez, V. Patwari, J. J. Rosales, and M. J. Rosas,
“Distributed computing utilizing virtual memory having a
shared paging space,” Oct. 18 2011, US Patent 8,041,877.

[9] M. Serrano, J. Sahuquillo, S. Petit, H. Hassan, and J. Duato,
“A cost-effective heuristic to schedule local and remote memory in cluster computers,” The Journal of Supercomputing,
vol. 59, no. 3, pp. 1533–1551, 2012.

[10] H. Sharifian and M. Sharifi, “Network ram based process
migration for hpc clusters,” Journal of Information Systems
and Telecommunication, vol. 1, no. 1, pp. 47–53, 2013.

[11] H.-H. Choi, K. Kim, and S.-J. Bae, “A remote memory system
for high performance data processing,” International Journal
of Future Computer and Communication, vol. 4, no. 1, p. 50,
2015.
[12] T. Newhall, S. Finney, K. Ganchev, and M. Spiegel, “Nswap:
A network swapping module for linux clusters,” in Euro-Par
2003 Parallel Processing. Springer, 2003, pp. 1160–1169.
[13] A. Samih, R. Wang, C. Maciocco, T.-Y. C. Tai, and Y. Solihin,
“A Collaborative Memory System for High-Performance and
Cost-Effective Clustered Architectures,” in Proceedings of the
1st Workshop on Architectures and Systems for Big Data.
ACM, 2011, pp. 4–12.
[14] P. Werstein, X. Jia, and Z. Huang, “A Remote Memory
Swapping System for Cluster Computers,” in International
Conference on Parallel and Distributed Computing, Applications and Technologies PDCAT. IEEE, 2007, pp. 75–81.
[15] M. D. Dahlin, R. Y. Wang, T. E. Anderson, and D. A.
Patterson, “Cooperative caching: Using remote client memory
to improve file system performance,” in Proceedings of the
1st USENIX conference on Operating Systems Design and
Implementation. USENIX Association, 1994, p. 19.
[16] R. Nishtala, H. Fugal, S. Grimm, M. Kwiatkowski, H. Lee,
H. C. Li, R. McElroy, M. Paleczny, D. Peek, P. Saab et al.,
“Scaling memcache at facebook,” in Presented as part of the
10th USENIX Symposium on Networked Systems Design and
Implementation (NSDI 13), 2013, pp. 385–398.
[17] M. J. Feeley, W. E. Morgan, E. Pighin, A. R. Karlin, H. M.
Levy, and C. A. Thekkath, Implementing global memory
management in a workstation cluster. ACM, 1995, vol. 29,
no. 5.
[18] M. Serrano, J. Sahuquillo, S. Petit, H. ne Hassan, and J. Duato, “A cost-effective heuristic to schedule local and remote
memory in cluster computers,” Journal of Supercomputing,
vol. 59, no. 3, 2013.
[19] G. Graefe, “The five-minute rule twenty years later, and
how flash memory changes the rules,” in Proceedings of the
3rd international workshop on Data management on new
hardware. ACM, 2007, p. 6.
[20] B. Fitzpatrick, “Distributed caching with memcached,” Linux
journal, vol. 2004, no. 124, p. 5, 2004.
[21] J. Zhang, G. Wu, X. Hu, and X. Wu, “A distributed cache for
hadoop distributed file system in real-time cloud services,” in
Grid Computing (GRID), 2012 ACM/IEEE 13th International
Conference on. IEEE, 2012, pp. 12–21.
[22] Y. Luo, S. Luo, J. Guan, and S. Zhou, “A ramcloud storage
system based on hdfs: Architecture, implementation and evaluation,” Journal of Systems and Software, vol. 86, no. 3, pp.
744–750, 2013.
[23] J. Ousterhout, A. Gopalan, A. Gupta, A. Kejriwal, C. Lee,
B. Montazeri, D. Ongaro, S. J. Park, H. Qin, M. Rosenblum,
S. Rumble, R. Stutsman, and S. Yang, “The ramcloud storage
system,” ACM Trans. Comput. Syst., vol. 33, no. 3, Aug. 2015.
[24] J. Xu and S. Swanson, “Nova: A log-structured file system for
hybrid volatile/non-volatile main memories,” in Proceedings
of the 14th Usenix Conference on File and Storage
Technologies, ser. FAST’16. Berkeley, CA, USA: USENIX
Association, 2016, pp. 323–338. [Online]. Available:
http://dl.acm.org/citation.cfm?id=2930583.2930608
[25] N. S. Islam, X. Lu, M. Wasi-ur Rahman, D. Shankar, and
D. K. Panda, “Triple-h: A hybrid approach to accelerate hdfs
on hpc clusters with heterogeneous storage architecture,” in
Cluster, Cloud and Grid Computing (CCGrid), 2015 15th
IEEE/ACM International Symposium on. IEEE, 2015, pp.
101–110.
[26] S. Robbins, “Ram is the new disk. . . ,” InfoQ News, June 2008.
[27] A. Uta, A. Sandu, S. Costache, and T. Kielmann, “Memefs:
an elastic in-memory runtime file system for escience applications,” in e-Science (e-Science), 2015 IEEE 11th International
Conference on. IEEE, 2015, pp. 465–474.
[28] “Device mapper, red hat inc.” http://sources.redhat.com/dm.
[29] R. Dementiev, L. Kettner, and P. Sanders, “Stxxl: standard
template library for xxl data sets,” Softw., Pract. Exper.,
vol. 38, no. 6, pp. 589–637, 2008.
[30] R. McDougall, “Filebench,” URL: http://www. nfsv4bat.
org/Documents/nasconf/2004/filebench, p. 56, 2005.