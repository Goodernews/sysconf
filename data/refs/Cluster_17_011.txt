[1] S. H. K. Narayanan, B. Norris, and P. D. Hovland, “Generating performance bounds from source code,” in Parallel
Processing Workshops (ICPPW), 2010 39th International
Conference on. JYEEE, 2010, pp. 197-206.

[2] S. Williams, A. Waterman, and D. Patterson, “Roofline: An
insightful visual performance model for multicore architectures,” Communications of the ACM, vol. 52, no. 4, pp. 65—76,
2009.

[3] D. Quinlan, “ROSE web page,” http://rosecompiler.org.

[4] L.-N. Pouchet, U. Bondhugula, C. Bastoul, A. Cohen, J. Ramanujam, P. Sadayappan, and N. Vasilache, “Loop transformations: Convexity, pruning and optimization,” in 38th ACM
SIGACT-SIGPLAN Symposium on Principles of Programming
Languages (POPL’11). Austin, TX: ACM Press, Jan. 2011,
pp. 549-562.

[5] C. Bastoul, “Code generation in the polyhedral model is easier
than you think,” in PACT’13 IEEE International Conference
on Parallel Architecture and Compilation Techniques, Juanles-Pins, France, September 2004, pp. 7-16.

[6] M. Griebl, “Automatic parallelization of loop programs for
distributed memory architectures,” Ph.D. dissertation, University of Passau, 2004.

[7] U. Bondhugula, A. Hartono, J. Ramanujam, and P. Sadayappan, “A practical automatic polyhedral parallelizer and
locality optimizer,” in ACM SIGPLAN Notices, vol. 43, no. 6.
ACM, 2008, pp. 101-113.

[8] T. Grosser, A. Groesslinger, and C. Lengauer, “Pollyperforming polyhedral optimizations on a low-level intermediate
representation,” Parallel Processing Letters, vol. 22, no. 04,
p. 1250010, 2012.

[9] P. J. Mucci, S. Browne, C. Deane, and G. Ho, “PAPI:
A portable interface to hardware performance counters,” in
Proceedings of the department of defense HPCMP users
group conference, 1999, pp. 7-10.

[10] S. S. Shende and A. D. Malony, “The TAU parallel performance system,” International Journal of High Performance
Computing Applications, vol. 20, no. 2, pp. 287-311, 2006.

[11] L. Adhianto, S. Banerjee, M. Fagan, M. Krentel, G. Marin,
J. Mellor-Crummey, and N. R. Tallent, “HPCToolkit: Tools
for performance analysis of optimized parallel programs,”
Concurrency and Computation: Practice and Experience,
vol. 22, no. 6, pp. 685-701, 2010.

[12] M. Geimer, F. Wolf, B. J. Wylie, E. Abrahém, D. Becker, and
B. Mohr, “The Scalasca performance toolset architecture,”
Concurrency and Computation: Practice and Experience,
vol. 22, no. 6, pp. 702-719, 2010.

[13] G. Marin, J. Dongarra, and D. Terpstra, “MIAMI: A framework for application performance diagnosis,” in Performance
Analysis of Systems and Software (ISPASS), 2014 IEEE
International Symposium on. TYEEE, 2014, pp. 158-168.

[14] S. L. Graham, P. B. Kessler, and M. K. Mckusick, “Gprof:
A call graph execution profiler,’ in ACM Sigplan Notices,
vol. 17, no. 6. ACM, 1982, pp. 120-126.

[15] S. Pakin and P. McCormick, “Hardware-independent application characterization,” in Workload Characterization (IISWC),
2013 IEEE International Symposium on. JEEE, 2013, pp.
111-112.

[16] C. Bastoul, A. Cohen, S. Girbal, S. Sharma, and O. Temam,
“Putting polyhedral loop transformations to work,” in International Workshop on Languages and Compilers for Parallel
Computing. Springer, 2003, pp. 209-225.

[17] M. A. Heroux, D. W. DoerjDFyer, P. S. Crozier, J. M.
Willenbring, H. C. Edwards, A. Williams, M. Rajan, E. R.
Keiter, H. K. Thornquist, and R. W. Numrich, “Improving
performance via mini-applications,” Sandia National Laboratories, Tech. Rep. SAND2009-5574, Sept. 2009.

[18] J. D. McCalpin, “A survey of memory bandwidth and machine
balance in current high performance computers,” IEEE TCCA
Newsletter, vol. 19, p. 25, 1995.

[19] P. R. Luszczek, D. H. Bailey, J. J. Dongarra, J. Kepner,
R. F. Lucas, R. Rabenseifner, and D. Takahashi, ““The HPC
challenge CHPCC) benchmark suite,” in Proceedings of the
2006 ACM/IEEE conference on Supercomputing. Citeseer,
2006, p. 213.

[20] J. Hammer, G. Hager, J. Eitzinger, and G. Wellein, “Automatic loop kernel analysis and performance modeling with
Kerncraft,” in Proceedings of the 6th International Workshop
on Performance Modeling, Benchmarking, and Simulation of
High Performance Computing Systems. ACM, 2015, p. 4.

[21] J. Hofmann, J. Eitzinger, and D. Fey, “Execution-cachememory performance model: Introduction and validation,”
arXiv preprint arXiv:1509.03118, 2015.

[22] Intel, “Intel architecture code analyzer homepage,”
https://software .intel.com/en-us/articles/intel-architecturecode-analyzer.

[23] K. A. Lindlan, J. Cuny, A. D. Malony, S. Shende, F. Juelich,
R. Rivenburgh, C. Rasmussen, and B. Mohr, “A tool framework for static and dynamic analysis of object-oriented software with templates,” in Proceedings of the 2000 ACM/IEEE
Conference on Supercomputing. _TEEE Computer Society,
2000.

[24] L. Djoudi and D. Barthou, “Maqao: Modular assembler
quality analyzer and optimizer for Itanium 2,” Workshop on
EPIC architectures and compiler technology, 2005.

[25] A. R. Bernat and B. P. Miller, “Anywhere, any-time binary
instrumentation,” in Proc. of the 10th ACM SIGPLANSIGSOFT Workshop on Program Analysis for Software
Tools, ser. PASTE ’11. ACM, 2011, pp. 9-16. [Online].
Available: http://doi.acm.org/10.1145/2024569.2024572

[26] D. Beckingsale, O. Pearce, I. Laguna, and T. Gamblin,
“Apollo: Reusable models for fast, dynamic tuning of inputdependent code,” in The 31th IEEE International Parallel and
Distributed Processing Symposium, 2017.

[27] A. Rodrigues, K. S. Hemmert, B. W. Barrett, C. Kersey,
R. Oldfield, M. Weston, R. Riesen, J. Cook, P. Rosenfeld,
E. Cooper-Balis, and B. Jacob, “The structural simulation
toolkit,” SIGMETRICS Perform. Eval. Rev. vol. 38, no. 4,
pp. 37-42, March 2011.