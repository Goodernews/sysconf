[1] Anthony Agelastos, Benjamin Allan, Jim Brandt, Paul Cassella, Jeremy Enos,
Joshi Fullop, Ann Gentile, Steve Monk, Nichamon Naksinehaboon, Jeff Ogden,
and others. 2014. The lightweight distributed metric service: a scalable infrastructure for continuous monitoring of large scale computing systems and
applications. In High Performance Computing, Networking, Storage and Analysis,
SC14: International Conference for. IEEE, 154–165.
[2] Wolfgang Barth. 2008. Nagios: System and network monitoring. No Starch Press.
[3] Arthur S Bland, Jack C Wells, Otis E Messer, Oscar R Hernandez, and James H
Rogers. 2012. Titan: Early experience with the cray xk6 at oak ridge national
laboratory. In Proceedings of cray user group conference (CUG 2012). 3–4.
[4] Jim Brandt, Ann Gentile, Jackson Mayo, Philippe Pebay, Diana Roe, David Thompson, and Matthew Wong. 2009. Resource monitoring and management with
OVIS to enable HPC in cloud computing environments. In Parallel & Distributed
Processing, 2009. IPDPS 2009. IEEE International Symposium on. IEEE, 1–8.
[5] Leo Breiman. 2001. Random Forests. Machine Learning 45, 1 (2001), 5–32. DOI:
https://doi.org/10.1023/A:1010933404324
[6] Michael J Brim, Luiz DeRose, Barton P Miller, Ramya Olichandran, and Philip C
Roth. 2010. MRNet: A scalable infrastructure for the development of parallel
tools and applications. Cray User Group (2010).
[7] Philip H. Carns, Robert Latham, Robert B. Ross, Kamil Iskra, Samuel Lang, and
Katherine Riley. 2009. 24/7 Characterization of petascale I/O workloads. In
CLUSTER. IEEE Computer Society, 1–10. http://dblp.uni-trier.de/db/conf/cluster/
cluster2009.html#CarnsLRILR09
[8] Elastic. 2017. ELK Stack. (2017). https://www.elastic.co/products
[9] Nagios Enterprises. 2017. Nagios. (2017). https://www.nagios.org/
[10] Gupta et al. 2015. Understanding and Exploiting Spatial Properties of System
Failures on Extreme-Scale HPC Systems. International Conference on Dependable
Systems and Networks (DSN) (2015).
[11] Tiwari et al. 2014. Lazy checkpointing: Exploiting temporal locality in failures
to mitigate checkpointing overheads on extreme-scale systems. In Dependable
Systems and Networks (DSN), 2014 44th Annual IEEE/IFIP International Conference
on. IEEE, 25–36.
[12] Tiwari et al. 2015. Reliability Lessons Learned From GPU Experience With The
Titan Supercomputer at Oak Ridge Leadership Computing Facility. Proceedings
of SC15: International Conference for High Performance Computing, Networking,
Storage and Analysis (2015).
[13] Tiwari et al. 2015. Understanding GPU errors on large-scale HPC systems and
the implications for system design and operation. In High Performance Computer
Architecture (HPCA), 2015 IEEE 21st International Symposium on. IEEE, 331–342.
[14] Matt Ezell. 2013. Understanding the impact of interconnect failures on system
operation. In Proceedings of Cray User Group Conference (CUG 2013).
[15] Thomas R Furlani, Matthew D Jones, Steven M Gallo, Andrew E Bruno, CharngDa Lu, Amin Ghadersohi, Ryan J Gentner, Abani Patra, Robert L DeLeon, Gregor
Laszewski, and others. 2013. Performance metrics and auditing framework using
application kernels for high-performance computer systems. Concurrency and
Computation: Practice and Experience 25, 7 (2013), 918–931.
[16] Raghul Gunasekaran, Sarp Oral, Jason Hill, Ross Miller, Feiyi Wang, and Dustin
Leverman. 2015. Comparative I/O Workload Characterization of Two Leadership
Class Storage Clusters. In Proceedings of the 10th Parallel Data Storage Workshop
(PDSW ’15).
[17] J Hammond. 2011. TACC_stats: I/O performance monitoring for the intransigent.
In 2011 Workshop for Interfaces and Architectures for Scientific Data Storage (IASDS
2011).
[18] InfluxData. 2017. InfluxDB. (2017). https://www.influxdata.com/
[19] Grafana Labs. 2017. Grafana. (2017). https://grafana.com/
[20] Ross Miller, Jason Hill, David A. Dillow, Raghul Gunasekaran, Galen M. Shipman,
and Don Maxwell. 2010. Monitoring Tools For Large Scale Systems. In Proceedings
of Cray User Group Conference (CUG 2010).
[21] Bin Nie, Devesh Tiwari, Saurabh Gupta, Evgenia Smirni, and James H Rogers.
2016. A large-scale study of soft-errors on gpus in the field. In High Performance
Computer Architecture (HPCA), 2016 IEEE International Symposium on. IEEE,
519–530.
[22] Sarp Oral, David A Dillow, Douglas Fuller, Jason Hill, Dustin Leverman, Sudharshan S Vazhkudai, Feiyi Wang, Youngjae Kim, James Rogers, James Simmons, and
others. 2013. OLCF’s 1 TB/s, next-generation lustre file system. In Proceedings of
Cray User Group Conference (CUG 2013).
[23] Ganglia Project. 2017. Ganglia Monitoring System. (2017). http://ganglia.
sourceforge.net/
[24] Philip C Roth, Dorian C Arnold, and Barton P Miller. 2003. MRNet: A softwarebased multicast/reduction network for scalable tools. In Supercomputing, 2003
ACM/IEEE Conference. IEEE, 21–21.
[25] Splunk. 2017. Splunk Enterprise. (2017). https://www.splunk.com/
[26] Vladimir N. Vapnik. 1995. The Nature of Statistical Learning Theory. SpringerVerlag New York, Inc., New York, NY, USA.
[27] Feiyi Wang, Sarp Oral, Galen Shipman, Oleg Drokin, Tom Wang, and Isaac Huang.
2009. Understanding lustre filesystem internals. Oak Ridge National Laboratory,
National Center for Computational Sciences, Tech. Rep (2009).
[28] Richard W Watson and Robert A Coyne. 1995. The parallel I/O architecture of the
high-performance storage system (HPSS). In Mass Storage Systems, 1995.’StorageAt the Forefront of Information Infrastructures’, Proceedings of the Fourteenth IEEE
Symposium on. IEEE, 27–44.
[29] Christopher Zimmer, Saurabh Gupta, Scott Atchley, Sudharshan S. Vazhkudai,
and Carl Albing. 2016. A Multi-faceted Approach to Job Placement for Improved
Performance on Extreme-Scale Systems. In SC16: International Conference for
High Performance Computing, Networking, Storage and Analysis. 1015–1025. DOI:
https://doi.org/10.1109/SC.2016.86
[30] Christopher Zimmer, Saurabh Gupta, and Veronica G. Vergara Larrea. 2013.
Finally, A Way to Measure Frontend I/O Performance. In Proceedings of Cray
User Group Conference (CUG 2016).
