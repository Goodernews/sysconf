[1] J. R. Allen and K. Kennedy, “PFC: A program to convert fortran to parallel form,” Department of Mathematical Sciences,
Rice University, Tech. Rep., 1982.
[2] J. R. Allen and K. Kennedy, “Automatic translation of Fortran programs to vector form,” Tranactions on Programming
Languages and Systems (TOPLAS), 1987.
[3] ARM Ltd, “ARM NEON,” http://www.arm.com/products/
processors/technologies/neon.php, 2014.
[4] O. Bachmann, P. S. Wang, and E. V. Zima, “Chains of recurrences: A method to expedite the evaluation of closed-form
functions,” in Proceedings of the International Symposium on
Symbolic and Algebraic Computation (ISSAC), 1994.
[5] S. S. Baghsorkhi, N. Vasudevan, and Y. Wu, “Flexvec:
auto-vectorization for irregular loops,” in Proceedings of the
37th ACM SIGPLAN Conference on Programming Language
Design and Implementation (PLDI), 2016.
[6] R. Barik, J. Zhao, and V. Sarkar, “Efficient selection of vector
instructions using dynamic programming,” in Proceedings of
the International Symposium on Microarchitecture (MICRO),
2010.
[7] J. L. Birch, “Using the chains of recurrences algebra for data
dependence testing and induction variable substitution,” Master’s thesis, Department of Computer Science, The Florida
State University, 2002.
[8] J. Davies, C. Huson, T. Macke, B. Leasure, and M. Wolfe,
“The KAP/S-1- an advanced source-to-source vectorizer for
the S-1 Mark IIa supercomputer,” in Proceedings of the
International Conference on Parallel Processing, 1986.
[9] A. E. Eichenberger, P. Wu, and K. O’Brien, “Vectorization for
SIMD architectures with alignment constraints,” in Proceedings of the Conference on Programming Language Design
and Implementation (PLDI), 2004.
[10] Free Software Foundation, “GCC: GNU compiler collection,”
http://gcc.gnu.org, 2015.
[11] K. Gray, Microsoft DirectX 9 programmable graphics
pipeline. Microsoft Press, 2003.
[12] IBM PowerPC Microprocessor Family, “Vector/SIMD Multimedia Extension Technology Programming Environments
Manual,” 2005.
[13] Intel Corporation, “IA-32 Architectures Optimization Reference Manual,” 2007.
[14] Intel Corporation, “The Compute Architecture of Intel Processor Graphics Gen9,” 2015.
[15] C. E. Kozyrakis, S. Perissakis, D. Patterson, T. Anderson,
K. Asanovic, N. Cardwell, R. Fromm, J. Golbus, B. Gribstad,
K. Keeton, R. Thomas, N. Treuhaft, and K. Yelick, “Scalable
processors in the billion-transistor era: IRAM,” Computer,
1997.
[16] D. J. Kuck, R. H. Kuhn, D. A. Padua, B. Leasure, and
M. Wolfe, “Dependence graphs and compiler optimizations,”
in Proceedings of the Symposium on Principles of Programming Languages (POPL), 1981.
[17] S. Larsen and S. Amarasinghe, “Exploiting superword level
parallelism with multimedia instruction sets,” in Proceedings
of the Conference on Programming Language Design and
Implementation (PLDI), 2000.
[18] C. Lattner and V. Adve, “LLVM: A compilation framework
for lifelong program analysis transformation,” in Proceedings
of the International Symposium on Code Generation and
Optimization (CGO), 2004.
[19] E. Lindholm, J. Nickolls, S. Oberman, and J. Montrym,
“NVIDIA Tesla: A unified graphics and computing architecture,” IEEE Micro, 2008.
[20] J. Liu, Y. Zhang, O. Jang, W. Ding, and M. Kandemir, “A
compiler framework for extracting superword level parallelism,” in Proceedings of the Conference on Programming
Language Design and Implementation (PLDI), 2012.
[21] S. Maleki, Y. Gao, M. J. Garzar´an, T. Wong, and D. A. Padua,
“An evaluation of vectorizing compilers,” in Proceedings of
the International Conference on Parallel Architectures and
Compilation Techniques (PACT), 2011.
[22] A. Munshi, “The OpenCL specification,” in 2009 IEEE Hot
Chips 21 Symposium (HCS). IEEE, 2009, pp. 1–314.
[23] D. Nuzman, I. Rosen, and A. Zaks, “Auto-vectorization of
interleaved data for SIMD,” in Proceedings of the Conference on Programming Language Design and Implementation
(PLDI), 2006.
[24] D. Nuzman and A. Zaks, “Outer-loop vectorization: revisited
for short SIMD architectures,” in Proceedings of the International Conference on Parallel Architectures and Compilation
Techniques (PACT), 2008.
[25] Nvidia Corporation, “The CUDA specification.”
[26] S. Oberman, G. Favor, and F. Weber, “AMD 3DNow! technology: Architecture and implementations,” IEEE Micro, 1999.
[27] W. Oed, “Cray Y-MP C90: System features and early benchmark results,” Parallel Computing, 1992.
[28] Y. Park, S. Seo, H. Park, H. Cho, and S. Mahlke, “SIMD
defragmenter: Efficient ILP realization on data-parallel architectures,” in Proceedings of the International Conference
on Architectural Support for Programming Languages and
Operating Systems (ASPLOS), 2012.
[29] V. Porpodas and T. M. Jones, “Throttling automatic vectorization: When less is more,” in 2015 International Conference
on Parallel Architecture and Compilation (PACT), 2015.
[30] V. Porpodas, A. Magni, and T. M. Jones, “PSLP: Padded SLP
automatic vectorization,” in Proceedings of the International
Symposium on Code Generation and Optimization (CGO),
2015.
[31] G. Ren, P. Wu, and D. Padua, “Optimizing data permutations
for SIMD devices,” in Proceedings of the Conference on
Programming Language Design and Implementation (PLDI),
2006.
[32] I. Rosen, D. Nuzman, and A. Zaks, “Loop-aware SLP in
GCC,” in GCC Developers Summit, 2007.
[33] R. M. Russell, “The CRAY-1 computer system,” Communications of the ACM, 1978.
[34] J. Shin, M. Hall, and J. Chame, “Superword-level parallelism
in the presence of control flow,” in Proceedings of the International Symposium on Code Generation and Optimization
(CGO), 2005.
[35] D. Shreiner, OpenGL reference manual: The official reference
document to OpenGL, version 1.2. Addison-Wesley Longman Publishing Co., Inc., 1999.
[36] SPEC, “Standard Performance Evaluation Corp Benchmarks,”
http://www.spec.org, 2014.
[37] R. van Engelen, “Symbolic evaluation of chains of recurrences for loop optimization,” Department of Computer Science, Florida State University, Tech. Rep. TR-000102, 2000.
[38] M. Wolfe, “Vector optimization vs. vectorization,” in Supercomputing. Springer, 1988.
[39] M. J. Wolfe, High Performance Compilers for Parallel Computing. Addison-Wesley, 1995.
[40] P. Wu, A. Eichenberger, and A. Wang, “Efficient SIMD code
generation for runtime alignment and length conversion,”
in Proceedings of the International Symposium on Code
Generation and Optimization (CGO), 2005.
[41] H. Zhou and J. Xue, “A compiler approach for exploiting
partial SIMD parallelism,” ACM Transactions on Architecture
and Code Optimization (TACO), 2016.
[42] H. Zhou and J. Xue, “Exploiting mixed SIMD parallelism
by reducing data reorganization overhead,” in Proceedings of
the 2016 International Symposium on Code Generation and
Optimization (CGO), 2016.
