[1] T. Arnold. Sparse density representations for simultaneous inference on large
spatial datasets. arXiv preprint arXiv:1510.00755, 2015.
[2] S. Balakrishnan, B. T. Fasy, F. Lecci, A. Rinaldo, A. Singh, and L. Wasserman.
Statistical inference for persistent homology. Annals of Statistics, 2014.
[3] R. Blundell and A. Duncan. Kernel regression in empirical microeconomics.
Journal of Human Resources, pages 62–87, 1998.
[4] C. Boutsidis, P. Drineas, and M. Magdon-Ismail. Near-optimal coresets for leastsquares regression. IEEE Trans. Information Theory, 59(10), 2013.
[5] J. D. Brutlag. Aberrant behavior detection in time series for network monitoring.
In System Administration Conference (LISA). USENIX, 2000.
[6] S. Chan, I. Diakonikolas, R. A. Servedio, and X. Sun. Efficient density estimation
via piecewise polynomial approximation. In STOC, 2014.
[7] A. Dasgupta, P. Drineas, B. Harb, R. Kumar, and M. W. Mahoney. Sampling
algorithms and coresets for ℓp regression. SICOMP, 38:2060–2078, 2009.
[8] T. F. Gonzalez. Clustering to minimize the maximum intercluster distance. Theoretical Computer Science, 38:293–306, 1985.
[9] A. Gretton, K. M. Borgwardt, M. J. Rasch, B. Schölkopf, and A. Smola. A kernel
two-sample test. JMLR, 13:723–773, 2012.
[10] S. Har-Peled. Geometric approximation algorithms. AMS, 2011.
[11] J. Horel, M. Splitt, L. Dunn, J. Pechmann, B. White, C. Ciliberti, S. Lazarus,
J. Slemmer, D. Zaff, and J. Burks. Mesowest: Cooperative mesonets in the western
united states. Bulletin of the American Meteorological Society, 83(2):211–225, 2002.
[12] S. Joshi, R. V. Kommaraju, J. M. Phillips, and S. Venkatasubramanian. Comparing
distributions and shapes using the kernel distance. SoCG, 2011.
[13] Y. Li, P. M. Long, and A. Srinivasan. Improved bounds on the samples complexity
of learning. J. Comp. and Sys. Sci., 62:516–527, 2001.
[14] E. A. Nadaraya. On estimating regression. Theory of Probability and its Applications, 9:141–142, 1964.
[15] R. K. Pace and R. Barry. Sparse spatial autoregressions. Statistics & Probability
Letters, 33(3):291–297, 1997.
[16] J. M. Phillips. eps-samples for kernels. SODA, 2013.
[17] J. M. Phillips. Coresets and sketches. In Handbook on Discrete and Computational
Geometry, chapter 47. CRC Press, 3rd edition, 2016.
[18] J. M. Phillips and Y. Zheng. L_infty error and bandwith selection for kernel
density estimates of large data. In KDD, 2015.
[19] C. E. Rasmussen and C. K. I. Williams. Gaussian Processes for Machine Learning.
MIT Press, 2006.
[20] R. Ricci, E. Eide, and The CloudLab Team. Introducing CloudLab: Scientific
infrastructure for advancing cloud architectures and applications. USENIX ;login:,
39(6), Dec. 2014.
[21] N. Sharma, P. Sharma, D. Irwin, and P. Shenoy. Predicting solar generation from
weather forecasts using machine learning. In SmartGridComm, 2011.
[22] H. Takeda, S. Farsiu, and P. Milanfar. Kernel regression for image processing and
reconstruction. IEEE Trans Image Processing, 16:349–366, 2007.
[23] F. Tom. Mining the quantified self: Personal knowledge discovery as a challenge
for data science. Big Data, 3:249–266, 2016.
[24] V. Vapnik and A. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. Th. of Prob. Applic., 16:264–280, 1971.
[25] G. S. Watson. Smooth regression analysis. Indian Journal of Statistics, Series A,
26:359–372, 1964.
[26] X. Wei and Y. Li. Theoretical analysis of a rigid coreset minimum enclosing ball
algorithm for kernel regression estimation. In International Symposium on Neural
Networks, pages 741–752, 2008.
[27] J. R. Wolberg. Expert Trading Systems: Modeling Financial Markets with Kernel
Regression. Wiley, 2000.
[28] C. Yang, R. Duraiswami, N. Gumerov, and L. Davis. Improved fast Gauss transform
and efficient kernel density estimation. In ICCV, 2003.
[29] Y. Zheng, J. Jestes, J. M. Phillips, and F. Li. Quality and efficiency in kernel density
estimates for large data. In SIGMOD, 2012.
