[1] B. Awerbuch and Y. Shiloach. New connectivity and MSF algorithms for shuffleexchange network and PRAM. JEEE Trans. on Comp., 36(10):1258-1263, 1987.

[2] D. A. Bader and G. Cong. Fast shared-memory algorithms for computing the
minimum spanning forest of sparse graphs. In Par. and Dist. Proc. Symp. (IPDPS),
page 39. IEEE, 2004.

[3] D. A. Bader et al. Approximating betweenness centrality. In Algorithms and
Models for the Web-Graph, pages 124-137. Springer, 2007.

[4] S. Beamer, K. Asanovié, and D. Patterson. Direction-optimizing breadth-first
search. Scientific Programming, 21(3-4):137- 148, 2013.

[5] S. Beamer, K. Asanovié, and D. Patterson. GAIL: the graph algorithm iron law.
In Workshop on Ir. App.: Arch, and Alg., page 13, 2015.

[6] E.G. Boman et al. A scalable parallel graph coloring algorithm for distributed
memory computers. In Euro-Par, pages 241-251. 2005.

[7] M. Borokhovich et al. Tight bounds for algebraic gossip on graphs. In Inf. Theory
Proc. (ISIT), IEEE IntL Symp. on, pages 1758-1762, 2010.

[8] ©. Boruvka. O jistém problému minimalnim. 1926.

[9] U. Brandes. A faster algorithm for betweenness centrality. J. of Math. Sociology,
25(2):163-177, 2001.

[10] S. Brin and L. Page. The anatomy of a large-scale hypertextual Web search
engine. In Proc. of Intl. Conf. on World Wide Web, WWWW7, pages 107-117, 1998.

[11] U. Catalyurek and C. Aykanat. A Fine-Grain Hypergraph Model for 2D Decomposition of Sparse Matrices. In Proc. of the Intl. Par. Amp; Dist. Proc. Symp.,
IPDPS 01, pages 118-, 2001.

[12] V. T. Chakaravarthy et al. Scalable single source shortest path algorithms for
massively parallel systems. In Par. and Dist. Proc. Symp., IEEE Intl, pages 889-901,
2014.

[13] T. H.Cormen, C. Stein, R. L. Rivest, and C. E. Leiserson. Introduction to Algorithms.
McGraw-Hill Higher Education, 2nd edition, 2001.

[14] G. Csardi and T. Nepusz. The igraph software package for complex network
research. Interjournal, Complex Systems, 1695(5):1—9, 2006.

[15] N. Doekemeijer and A. L. Varbanescu. A survey of parallel graph processing
frameworks. Delft University of Technology, 2014.

[16] P. Erdés and A. Rényi. On the evolution of random graphs. Selected Papers of
Alfréd Rényi, 2:482-525, 1976.

[17] S. Fortune and J. Wyllie. Parallelism in random access machines. In Proc. of
ACM Symp. on Theory of Comp., pages 114-118, 1978.

[18] H. Gazit et al. An improved parallel algorithm that computes the BFS numbering
of a directed graph. Inf. Proc. Let., 28(2):61-65, 1988.

[19] H. Gazit et al. Optimal tree contraction in the EREW model. In Concurrent
Computations, pages 139-156. Springer, 1988.

[20] R. Gerstenberger, M. Besta, and T. Hoefler. Enabling Highly-scalable Remote
Memory Access Programming with MPI-3 One Sided. In Proc. of the ACM/IEEE
Supercomputing, SC °13, pages 53:1-53:12, 2013.

[21] A. Goel and K. Munagala. Complexity measures for map-reduce, and comparison
to parallel computing. arXiv preprint arXiv:1211.6526, 2012.

[22] J. E. Gonzalez et al. PowerGraph: Distributed Graph-Parallel Computation on
Natural Graphs. In OSDI, volume 12, page 2, 2012.

[23] ©. Green et al. Branch-Avoiding Graph Algorithms. arXiv:1411. 1460, 2014.

[24] D. Gregor and A. Lumsdaine. The parallel BGL: A generic library for distributed
graph computations. Par. Obj.-Or. Scientific Comp. (POOSC), page 2, 2005.

[25] T. J. Harris. A survey of PRAM simulation techniques. ACM Comp. Surv. (CSUR),
26(2):187-206, 1994,

[26] Intel, Inc. 64 and 1A-32 Architectures Software Developer’s Manual, 2015.

[27] J. Kepner and J. Gilbert. Graph algorithms in the language of linear algebra,
volume 22. SIAM, 2011.

[28] J. Kim et al. Technology-Driven, Highly-Scalable Dragonfly Topology. In Ann.
Intl. Symp. on Comp. Arch., SCA 08, pages 77-88, 2008.

[29] M. Kulkarni et al. Optimistic parallelism requires abstractions. In ACM SIGPLAN
Conf. on Prog. Lang. Des. and Impl, PLD1’07, pages 211-222, 2007.

[30] C. E. Leiserson and T. B. Schardl. A work-efficient parallel breadth-first search
algorithm (or how to cope with the nondeterminism of reducers). In Proc. of
ACM Symp. on Par. in Alg, and Arch., pages 303-314, 2010.

[31] J. Leskovec et al. Kronecker graphs: An approach to modeling networks. J. of
Machine Learning Research, 11(Feb):985-1042, 2010.

[32] Y. Low et al. Graphlab: A new framework for parallel machine learning. preprint
arXiv:1006.4990, 2010.

[33] A. Lumsdaine, D. Gregor, B. Hendrickson, and J. W. Berry. Challenges in Parallel
Graph Processing. Par. Proc. Let., 17(1):5—20, 2007.

[34] K. Madduri et al. A faster parallel algorithm and efficient multithreaded implementations for evaluating betweenness centrality on massive datasets. In Par. &
Dist. Proc. (IPDPS), IEEE Intl. Symp. on, pages 1-8, 2009.

[35] G. Malewicz et al. Pregel: a system for large-scale graph processing. In ACM
SIGMOD Intl. Conf. on Manag. of Data, SIGMOD ’10, pages 135-146, 2010.

[36] T. Mattson et al. Standards for graph algorithm primitives. arXiv preprint
arXiv:1408.0393, 2014.

[37] U. Meyer and P. Sanders. A-stepping: a parallelizable shortest path algorithm.
Journal of Algorithms, 49(1):114-152, 2003.

[38] MPI Forum. MPI: A Message-Passing Interface Standard. Version 3, 2012.

[39] R. C. Murphy et al. Introducing the graph 500. Cray User’s Group (CUG), 2010.

[40] V. Prabhakaran et al. Managing large graphs on multi-cores with graph awareness. In USENIX Annual Technical Conference, volume 12, 2012.

[41] D. Prountzos and K. Pingali. Betweenness centrality: algorithms and implementations. In ACM SIGPLAN Notices, volume 48, pages 35-46. ACM, 2013.

[42] S. Salihoglu and J. Widom. Optimizing graph algorithms on Pregel-like systems.
Proceedings of the VLDB Endowment, 7(7):577-588, 2014.

[43] N. Satish et al. Navigating the maze of graph analytics frameworks using massive
graph datasets. In ACM SIGMOD Inil. Conf. on Man. Data, pages 979-990, 2014.

[44] T. Schank. Algorithmic aspects of triangle-based network analysis. PhD thesis,
University Karlsruhe, 2007.

[45] S. Seo et al. HAMA: An Efficient Matrix Computation with the MapReduce
Framework. In Intl. Conf. on Cloud Comp. Tech. and Science, CLOUDCOM’10,
pages 721-726, 2010.

[46] J. Shun and G. E. Blelloch. Ligra: a lightweight graph processing framework for
shared memory. In ACM SIGPLAN Notices, volume 48, pages 135-146, 2013.

[47] J. Shun and K. Tangwongsan. Multicore triangle computations without tuning.
In 2015 IEEE 31st Intl. Conf. on Data Engineering, pages 149-160, April 2015.

[48] T. Suzumura et al. Performance characteristics of Graph500 on large-scale
distributed environment. In Workload Char. (HSWC), IEEE Intl. Symp. on, pages
149-158, 2011.

[49] V.N. Swamy et al. An Asymptotically Optimal Push—Pull Method for Multicasting Over a Random Network. Inf. Theory, IEEE Tran. on, 59(8):5075-5087,
2013.

[50] M. Voss. Understanding the internals of tbb:graph : Balancing Push and Pull.

[51] Z. Wang et al. Hybrid Pulling/Pushing for 1/O-Efficient Distributed and Iterative
Graph Computing. In ACM Intl. Conf: on Man. of Data, pages 479-494, 2016.

[52] J.J. Whang et al. Scalable Data-Driven PageRank: Algorithms, System Issues,
and Lessons Learned. In Euro-Par: Par. Proc., pages 438-450. 2015.

[53] J. Yang and J. Leskovec. Defining and evaluating network communities based
on ground-truth. Knowledge and Information Systems, 42(1):181-213, 2015.

[54] M. Zaharia et al. Resilient Distributed Datasets: A Fault-tolerant Abstraction for
In-memory Cluster Computing. In Proc. of the USENIX Conf. on Net. Sys. Design
and ImpL, NSDI’12, pages 2-2, 2012.

[55] M. Zhang et al. Exploring the hidden dimension in graph processing. In USENIX
Symp. on Op. Sys. Des. and Impl. (OSDI 16), 2016.

[56] Y. Zhao. A model of computation with push and pull processing. PhD thesis,
Citeseer, 2003.

[57] X. Zhu et al. Gemini: A computation-centric distributed graph processing system.
In USENIX Symp. on Op. Sys. Des. and Impl (OSDI 16), 2016.