[1] ASCAC Subcommittee, “Top ten exascale research challenges,” Ofﬁce of Science, U.S. Department of Energy, Washington, D.C., Tech. Rep. SAND2015-1027, 2014.
[2] M. Al-Fares et al., “A scalable, commodity data center
network architecture,” SIGCOMM Comput. Commun. Rev.,
vol. 38, no. 4, pp. 63–74, Aug. 2008.
[3] T. Hoeﬂer, “Software and hardware techniques for powerefﬁcient HPC networking,” Computing in Science Engineering, vol. 12, no. 6, pp. 30–37, Nov 2010.
[4] S. Rumley et al., “End-to-End Modeling and Optimization
of Power Consumption in HPC Interconnects,” in ICPPW:
International Conference on Parallel Processing Workshops,
2016.
[5] A. Bhatele and T. Gamblin, “OS/Runtime challenges for
dynamic topology aware mapping,” ser. ExaOSR, 2012.
[6] E. A. León et al., “Characterizing parallel scientiﬁc applications on commodity clusters: An empirical study of a tapered
fat-tree,” in Supercomputing, 2016.
[7] J. Paudel et al., “Hybrid parallel task placement in X10,” ser.
X10 ’13, 2013, pp. 31–38.
[8] E. Jeannot et al., “Process placement in multicore clusters:algorithmic issues and practical techniques,” Parallel and
Distributed Systems, IEEE Transactions on, vol. 25, no. 4, pp.
993–1002, April 2014.
[9] S.-Y. Lee and J. Aggarwal, “A mapping strategy for parallel
processing,” Computers, IEEE Transactions on, vol. C-36,
no. 4, pp. 433–442, April 1987.
[10] A. Rosenberg, “Issues in the study of graph embeddings,”
ser. Lecture Notes in Computer Science, H. Noltemeier, Ed.
Springer Berlin Heidelberg, 1981, vol. 100, pp. 150–176.
[11] C. Gotsman and M. Lindenbaum, “On the metric properties
of discrete space-ﬁlling curves,” ser. IAPR, Oct 1994.
[12] A. Bhatele and L. V. Kalé, “Beneﬁts of topology aware
mapping for mesh interconnects,” Parallel Processing Letters,
vol. 18, no. 4, pp. 549–566, 2008.
[13] A. Bhatelé et al., “Dynamic topology aware load balancing
algorithms for molecular dynamics applications,” ser. ICS ’09,
2009, pp. 110–116.
[14] J. Navaridas et al., “Effects of job and task placement on
parallel scientiﬁc applications performance,” ser. PDP, Feb
2009, pp. 55–61.
[15] B. Prisacari et al., “Efﬁcient task placement and routing
of nearest neighbor exchanges in dragonﬂy networks,” ser.
HPDC ’14, 2014, pp. 129–140.
[16] J. Kim et al., “Technology-driven, highly-scalable dragonﬂy
topology,” ser. ISCA, 2008, pp. 77–88.
[17] J. H. Ahn et al., “HyperX: Topology, routing, and packaging
of efﬁcient large-scale networks,” ser. SC ’09, 2009.
[18] J. Traff, “Implementing the MPI process topology mechanism,” ser. SC ’02, Nov 2002, pp. 28–28.
[19] C. Leiserson, “Fat-trees: Universal networks for hardwareefﬁcient supercomputing,” Computers, IEEE Transactions on,
vol. C-34, no. 10, pp. 892–901, Oct 1985.
[20] A. H. Abdel-Gawad et al., “RAHTM: Routing algorithm
aware hierarchical task mapping,” ser. SC ’14, pp. 325–335.
[21] B. Hendrickson and R. Leland, “A multi-level algorithm for
partitioning graphs,” ser. SC ’95, 1995, pp. 28–28.
[22] G. Karypis and V. Kumar, “Multilevel k-way partitioning
scheme for irregular graphs,” J. Parallel Distrib. Comput.,
vol. 48, no. 1, pp. 96–129, Jan. 1998.
[23] H. D. Simon and S.-H. Teng, “How good is recursive bisection?” SIAM J. Sci. Comput., vol. 18, no. 5, Sep. 1997.
[24] J. Kim et al., “Flattened butterﬂy: a cost-efﬁcient topology
for high-radix networks,” ser. ISCA, 2007.
[25] A. McPherson et al., Static Approximation of MPI Communication Graphs for Optimized Process Placement, ser. LCPC,
2014.
[26] J. Hursey and J. M. Squyres, “Advancing application process
afﬁnity experimentation: Open MPI’s LAMA-based afﬁnity
interface,” ser. EuroMPI ’13, 2013, pp. 163–168.
[27] M. J. Rashti et al., “Multi-core and network aware MPI
topology functions,” ser. EuroMPI’11, 2011, pp. 50–60.
[28] T. Hoeﬂer et al., “The scalable process topology interface of
MPI 2.2,” Concurr. Comput. : Pract. Exper., vol. 23, no. 4,
pp. 293–310, Mar. 2011.
[29] G. Almasi et al., “Implementing MPI on the BlueGene/L
Supercomputer,” ser. Euro-Par, 2004, pp. 833–845.
[30] Center for Computational Sciences and Engineering,
Lawrence Berkeley National Laboratory. Boxlib. [Online].
Available: https://ccse.lbl.gov/BoxLib/
[31] T. Hoeﬂer et al., “An overview of process mapping
techniques and algorithms in high-performance computing,”
in High Performance Computing on Complex Environments.
Wiley, Jun. 2014, pp. 75–94. [Online]. Available: https:
//hal.inria.fr/hal-00921626
[32] S. Kamil et al., “Reconﬁgurable hybrid interconnection for
static and dynamic scientiﬁc applications,” ser. CF ’07, 2007.
[33] A. Bhatele et al., “Mapping applications with collectives over
sub-communicators on torus networks,” ser. SC ’12, 2012.
[34] B. Prisacari et al., “Bandwidth-optimal all-to-all exchanges
in fat tree networks,” ser. ICS ’13, 2013, pp. 139–148.
[35] R. Thakur et al., “Optimization of collective communication
operations in mpich,” International Journal of High Performance Computing Applications, vol. 19, no. 1, pp. 49–66,
2005.
[36] T. Hoeﬂer et al., “Implementation and performance analysis
of non-blocking collective operations for mpi,” ser. SC ’07.
[37] B. Alverson et al., “Cray XC Series Network,” Tech. Rep.
[38] Characterization of the DOE Mini-apps. (2014)
http://portal.nersc.gov/project/cal/designforward.htm.
[39] R. Hornung et al., “Hydrodynamics Challenge Problem,
Lawrence Livermore National Laboratory,” Tech. Rep. LLNLTR-490254.
[40] S. Ethier et al., “Petascale parallelization of the gyrokinetic
toroidal code,” ser. VECPAR 2010, 2010.
[41] Paul Fischer and Katherine Heisey. Proxy-apps for thermal
hydraulics. [Online]. Available: https://cesar.mcs.anl.gov/
content/software/thermal hydraulics
[42] H. Adalsteinsson et al., “A simulator for large-scale parallel
computer architectures,” International Journal of Distributed
Systems and Technologies, vol. 1, no. 2, pp. 57–73, Apr. 2010.
[43] H. Adelsteinson and J. Wilke. (2016) DUMPI. [Online].
Available: https://github.com/sstsimulator/sst-dumpi
[44] J. Wilke and J. Kenny. (2016) SST/macro GitHub. [Online].
Available: https://github.com/sstsimulator/sst-macro
[45] G. Karypis and V. Kumar, “METIS – unstructured graph
partitioning and sparse matrix ordering system, version 2.0,”
University of Minnesota, Tech. Rep., 1995.
[46] G. Karypis and V. Kumer, “Multilevel k-way hypergraph
partitioning,” ser. DAC ’99, 1999, pp. 343–348.
[47] J. Shalf et al., “Exascale computing technology challenges,”
ser. VECPAR, vol. 6449. Springer, 2010, pp. 1–25.
[48] G. Karypis and V. Kumar, “A fast and high quality multilevel scheme for partitioning irregular graphs,” SIAM J. Sci.
Comput., vol. 20, no. 1, pp. 359–392, Dec. 1998.
[49] T. Andrews, “Computation Time Comparison Between Matlab and C++ Using Launch Windows,” Tech. Rep., 2012.
[50] E. Jeannot and G. Mercier, “Near-optimal placement of MPI
processes on hierarchical NUMA architectures,” ser. EuroPar’10, 2010, pp. 199–210.
[51] G. Mercier and J. Clet-Ortega, “Towards an efﬁcient process
placement policy for MPI applications in multicore environments,” ser. PVM/MPI meeting, 2009, pp. 104–115.
[52] D. Barthou and E. Jeannot, “SPAGHETtI: Scheduling/placement approach for task-graphs on HETerogeneous
architecture,” 2014, pp. 174–185.
[53] M. Deveci et al., “Exploiting geometric partitioning in task
mapping for parallel computers,” ser. IPDPS ’14, 2014.
[54] A. Bhatele; et al., “Optimizing communication for Charm++
applications by reducing network contention,” Concurr. Comput. : Pract. Exper., vol. 23, no. 2, pp. 211–222, Feb. 2011.
[55] T. Agarwal et al., “Topology-aware task mapping for reducing
communication contention on large parallel machines,” ser.
IPDPS’06, 2006, pp. 145–145.
[56] A. Bhatele et al., “Analyzing network health and congestion
in dragonﬂy-based supercomputers,” in IPDPS ’16: International Parallel & Distributed Processing Symposium, 2016.
[57] T. Groves et al., “(SAI) Stalled, Active and Idle: Characterizing Power and Performance of Large-scale Dragonﬂy
Networks,” in Cluster, 2016.
[58] K. Wen et al., “Flexﬂy: Enabling a reconﬁgurable dragonﬂy
through silicon photonics,” in Supercomputing, 2016.