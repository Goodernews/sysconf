[1] 2011. CUDA C/C++ SDK code samples. NVIDIA. (2011).
[2] 2014. Hybrid Memory Cube Specification 2.1. Hybrid Memory Cube Consortium.
(2014).
[3] 2016. NVIDIA Tesla P100. (2016). NVIDIA white paper.
[4] 2017. JEDEC Solid State Technology Association. (2017). http://jedec.org.
[5] Junwhan Ahn, Sungpack Hong, Sungjoo Yoo, Onur Mutlu, and Kiyoung Choi.
2015. A Scalable Processing-in-memory Accelerator for Parallel Graph Processing. In Proceedings of the 42nd Annual International Symposium on Computer
Architecture (ISCA ’15).
[6] Junwhan Ahn, Sungjoo Yoo, Onur Mutlu, and Kiyoung Choi. 2015. PIM-enabled
Instructions: A Low-overhead, Locality-aware Processing-in-memory Architecture. In Proceedings of the 42nd Annual International Symposium on Computer
Architecture (ISCA ’15).
[7] H. Asghari-Moghaddam, Y. H. Son, J. H. Ahn, and N. S. Kim. 2016. Chameleon:
Versatile and practical near-DRAM acceleration architecture for large memory
systems. In the 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO ’16).
[8] A. Bakhoda, G. L. Yuan, W. W. L. Fung, H. Wong, and T. M. Aamodt. Analyzing
CUDA workloads using a detailed GPU simulator. In 2009 IEEE International
Symposium on Performance Analysis of Systems and Software (ISPASS ’09).
[9] Brad Benton. 2017. CCIX, GEN-Z, Open CAPI: OVERVIEW & COMPARISON.
13th Annual OpenFabrics Alliance Workshop. (Mar 2017).
[10] A. Boroumand, S. Ghose, M. Patel, H. Hassan, B. Lucia, K. Hsieh, K. T. Malladi, H.
Zheng, and O. Mutlu. 2017. LazyPIM: An Efficient Cache Coherence Mechanism
for Processing-in-Memory. IEEE Computer Architecture Letters 16, 1 (Jan 2017).
[11] Doug Burger, James R. Goodman, and Alain Kägi. 1996. Memory Bandwidth Limitations of Future Microprocessors. In Proceedings of the 23rd Annual International
Symposium on Computer Architecture (ISCA ’96).
[12] K. Chandrasekar, C. Weis, B. Akesson, N. Wehn, and K. Goossens. 2013. System
and circuit level power modeling of energy-efficient 3D-stacked wide I/O DRAMs.
In 2013 Design, Automation Test in Europe Conference Exhibition (DATE).
[13] Shuai Che, Michael Boyer, Jiayuan Meng, David Tarjan, Jeremy W. Sheaffer, SangHa Lee, and Kevin Skadron. Rodinia: A Benchmark Suite for Heterogeneous
Computing. In Proceedings of the 2009 IEEE International Symposium on Workload
Characterization (IISWC ’09).
[14] Hanjin Chu. 2013. AMD Heterogeneous Uniform Memory Access. AMD. (2013).
[15] Mohammad Dashti, Alexandra Fedorova, Justin Funston, Fabien Gaud, Renaud
Lachaize, Baptiste Lepers, Vivien Quema, and Mark Roth. 2013. Traffic Management: A Holistic Approach to Memory Placement on NUMA Systems. In
Proceedings of the Eighteenth International Conference on Architectural Support
for Programming Languages and Operating Systems (ASPLOS ’13).
[16] Jeff Draper, Jacqueline Chame, Mary Hall, Craig Steele, Tim Barrett, Jeff LaCoss,
John Granacki, Jaewook Shin, Chun Chen, Chang Woo Kang, Ihn Kim, and
Gokhan Daglikoca. 2002. The Architecture of the DIVA Processing-in-memory
Chip. In Proceedings of the 16th International Conference on Supercomputing (ICS
’02).
[17] A. Farmahini-Farahani, J. H. Ahn, K. Morrow, and N. S. Kim. NDA: Near-DRAM
acceleration architecture leveraging commodity DRAM devices and standard
memory modules. In 2015 IEEE 21st International Symposium on High Performance
Computer Architecture (HPCA ’15).
[18] Wilson W. L. Fung, Ivan Sham, George Yuan, and Tor M. Aamodt. 2007. Dynamic
Warp Formation and Scheduling for Efficient GPU Control Flow. In Proceedings of
the 40th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO
’07).
[19] Mingyu Gao, Grant Ayers, and Christos Kozyrakis. 2015. Practical Near-Data Processing for In-Memory Analytics Frameworks. In Proceedings of the International
Conference on Parallel Architecture and Compilation (PACT ’15).
[20] M. Gao and C. Kozyrakis. 2016. HRL: Efficient and flexible reconfigurable logic for
near-data processing. In the IEEE International Symposium on High Performance
Computer Architecture (HPCA ’16).
[21] M. Gokhale, B. Holmes, and K. Iobst. 1995. Processing in memory: the Terasys
massively parallel PIM array. Computer 28, 4 (Apr 1995), 23–31.
[22] S. Grauer-Gray, L. Xu, R. Searles, S. Ayalasomayajula, and J. Cavazos. 2012.
Auto-tuning a high-level language targeted to GPU codes. In Innovative Parallel
Computing (InPar).
[23] Anthony Gutierrez, Michael Cieslak, Bharan Giridhar, Ronald G. Dreslinski,
Luis Ceze, and Trevor Mudge. 2014. Integrated 3D-stacked Server Designs
for Increasing Physical Density of Key-value Stores. In Proceedings of the 19th
International Conference on Architectural Support for Programming Languages and
Operating Systems (ASPLOS ’14).
[24] Mark Harris. 2013. Unified Memory in CUDA 6. GTC On-Demand, NVIDIA.
(2013).
[25] Michael A Heroux, Douglas W Doerfler, Paul S Crozier, James M Willenbring,
H Carter Edwards, Alan Williams, Mahesh Rajan, Eric R Keiter, Heidi K Thornquist, and Robert W Numrich. 2009. Improving performance via mini-applications.
Sandia National Laboratories, Tech. Rep. SAND2009-5574 3 (2009).
[26] Kevin Hsieh, Eiman Ebrahimi, Gwangsun Kim, Niladrish Chatterjee, Mike
O’Connor, Nandita Vijaykumar, Onur Mutlu, and Stephen W. Keckler. 2016.
Transparent Offloading and Mapping (TOM): Enabling Programmer-transparent
Near-data Processing in GPU Systems. In Proceedings of the 43rd International
Symposium on Computer Architecture (ISCA ’16).
[27] S.W. Keckler, W.J. Dally, B. Khailany, M. Garland, and D. Glasco. 2011. GPUs and
the Future of Parallel Computing. Micro, IEEE 31, 5 (Sept 2011), 7–17.
[28] Farzad Khorasani, Rajiv Gupta, and Laxmi N. Bhuyan. 2015. Efficient Warp
Execution in Presence of Divergence with Collaborative Context Collection. In

Proceedings of the 48th International Symposium on Microarchitecture (MICRO’15).
[29] Gwangsun Kim, John Kim, Jung Ho Ahn, and Jaeha Kim. 2013. Memory-centric
System Interconnect Design with Hybrid Memory Cubes. In Proceedings of the
22nd International Conference on Parallel Architectures and Compilation Techniques
(PACT ’13).
[30] D. U. Lee, K. W. Kim, K. W. Kim, H. Kim, J. Y. Kim, Y. J. Park, J. H. Kim, D. S.
Kim, H. B. Park, J. W. Shin, J. H. Cho, K. H. Kwon, M. J. Kim, J. Lee, K. W. Park,
B. Chung, and S. Hong. 2014. A 1.2V 8Gb 8-channel 128GB/s high-bandwidth
memory (HBM) stacked DRAM with effective microbump I/O test methods using
29nm process and TSV. In 2014 IEEE International Solid-State Circuits Conference
Digest of Technical Papers (ISSCC ’14).
[31] Jingwen Leng, Tayler Hetherington, Ahmed ElTantawy, Syed Gilani, Nam Sung
Kim, Tor M. Aamodt, and Vijay Janapa Reddi. 2013. GPUWattch: Enabling
Energy Optimizations in GPGPUs. In Proceedings of the 40th Annual International
Symposium on Computer Architecture (ISCA ’13).
[32] Baptiste Lepers, Vivien Quéma, and Alexandra Fedorova. 2015. Thread and
Memory Placement on NUMA Systems: Asymmetry Matters. In Proceedings of
the USENIX Conference on Usenix Annual Technical Conference (USENIX ATC’15).
[33] Wen mei W. Hwu. 2012. GPU Computing GEMS Jade Edition. Morgan Kaufmann.
[34] R. Nair, S.F. Antao, C. Bertolli, P. Bose, J.R. Brunheroto, T. Chen, C. Cher, C.H.A.
Costa, J. Doi, C. Evangelinos, B.M. Fleischer, T.W. Fox, D.S. Gallo, L. Grinberg, J.A.
Gunnels, A.C. Jacob, P. Jacob, H.M. Jacobson, T. Karkhanis, C. Kim, J.H. Moreno,
J.K. O’Brien, M. Ohmacht, Y. Park, D.A. Prener, B.S. Rosenburg, K.D. Ryu, O.
Sallenave, M.J. Serrano, P.D.M. Siegl, K. Sugavanam, and Z. Sura. 2015. Active
Memory Cube: A processing-in-memory architecture for exascale systems. IBM
Journal of Research and Development (2015).
[35] Ashutosh Pattnaik, Xulong Tang, Adwait Jog, Onur Kayiran, Asit K. Mishra,
Mahmut T. Kandemir, Onur Mutlu, and Chita R. Das. 2016. Scheduling Techniques
for GPU Architectures with Processing-In-Memory Capabilities. In Proceedings of
the 2016 International Conference on Parallel Architectures and Compilation (PACT
’16).
[36] J. Poulton, R. Palmer, A. M. Fuller, T. Greer, J. Eyles, W. J. Dally, and M. Horowitz.
2007. A 14-mW 6.25-Gb/s Transceiver in 90-nm CMOS. Solid-State Circuits, IEEE
Journal of 42, 12 (2007).
[37] S. H. Pugsley, J. Jestes, H. Zhang, R. Balasubramonian, V. Srinivasan, A. Buyuktosunoglu, A. Davis, and F. Li. 2014. NDC: Analyzing the impact of 3D-stacked
memory+logic devices on MapReduce workloads. In 2014 IEEE International
Symposium on Performance Analysis of Systems and Software (ISPASS ’14).
[38] Minsoo Rhu and Mattan Erez. 2013. The Dual-path Execution Model for Efficient
GPU Control Flow. In Proceedings of the 2013 IEEE 19th International Symposium
on High Performance Computer Architecture (HPCA ’13).
[39] Minsoo Rhu, Michael Sullivan, Jingwen Leng, and Mattan Erez. 2013. A Localityaware Memory Hierarchy for Energy-efficient GPU Architectures. In Proceedings
of the 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO ’13).
[40] Timothy G. Rogers, Mike O’Connor, and Tor M. Aamodt. 2012. Cache-Conscious
Wavefront Scheduling. In Proceedings of the 2012 45th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO ’12).
[41] Timothy G. Rogers, Mike O’Connor, and Tor M. Aamodt. 2013. Divergenceaware Warp Scheduling. In Proceedings of the 46th Annual IEEE/ACM International
Symposium on Microarchitecture (MICRO ’13).
[42] Mark Shaw, Martin Goldstein, and Mark A. Shaw. 2016. Open CloudServer OCS
Blade Specification Version 2.1. Open Compute Project. (Feb 2016).
[43] Young Hoon Son, O. Seongil, Hyunggyun Yang, Daejin Jung, Jung Ho Ahn, John
Kim, Jangwoo Kim, and Jae W. Lee. 2014. Microbank: Architecting Throughsilicon Interposer-based Main Memory Systems. In Proceedings of the International
Conference for High Performance Computing, Networking, Storage and Analysis
(SC ’14).
[44] J.A. Stratton, Christopher Rodrigues, I-Jui Sung, Nady Obeid, Li-Wen Chang,
Nasser Anssari, Geng Daniel Liu, and Wen mei W. Hwu. 2012. Parboil: A Revised
Benchmark Suite for Scientific and Commercial Throughput Computing. IMPACT
Technical Report, Center for Reliable and High-Performance Computing. (2012).
[45] Thomas Vogelsang. 2010. Understanding the Energy Consumption of Dynamic
Random Access Memories. In Proceedings of the 2010 43rd Annual IEEE/ACM
International Symposium on Microarchitecture (MICRO ’10).
[46] S. Wasson. 2015. AMD Radeon R9 Fury X Graphics Card Reviewed. (2015). http://
techreport.com/review/28513/amd-radeon-r9-fury-x-graphics-card-reviewed.
[47] Joe Xie. 2016. NVIDIA RISC-V Evaluation Story. In Proceedings of the 4th RISC-V
workshop.
[48] Dongping Zhang, Nuwan Jayasena, Alexander Lyashevsky, Joseph L. Greathouse,
Lifan Xu, and Michael Ignatowski. 2014. TOP-PIM: Throughput-oriented Programmable Processing in Memory. In Proceedings of the 23rd International Symposium on High-performance Parallel and Distributed Computing (HPDC ’14).
[49] T. Zheng, D. Nellans, A. Zulfiqar, M. Stephenson, and S. W. Keckler. 2016. Towards
high performance paged memory for GPUs. In 2016 IEEE International Symposium
on High Performance Computer Architecture (HPCA ’16).
