[1] “CUDA occupancy calculator,” http://developer.download.nvidia.com/
compute/cuda/CUDA Occupancy calculator.xls, 2016.
[2] S. S. Shende and A. D. Malony, “The TAU parallel performance system,”
International Journal of High Performance Computing Applications,
vol. 20, no. 2, pp. 287–311, 2006.
[3] A. D. Malony, S. Biersdorff, S. Shende, H. Jagode, S. Tomov, G. Juckeland, R. Dietrich, D. Poole, and C. Lamb, “Parallel performance
measurement of heterogeneous parallel systems with GPUs,” in 2011
International Conference on Parallel Processing, 2011, pp. 176–185.
[4] “Allinea DDT,” http://www.allinea.com/products/ddt.
[5] “Nvidia Visual Proﬁler,” https://developer.nvidia.com/nvidia-visualproﬁler.
[6] L. Adhianto, S. Banerjee, M. Fagan, M. Krentel, G. Marin, J. MellorCrummey, and N. R. Tallent, “Hpctoolkit: Tools for performance analysis of optimized parallel programs,” Concurrency and Computation:
Practice and Experience, vol. 22, no. 6, pp. 685–701, 2010.
[7] R. Lim, B. Norris, and A. Malony, “Tuning heterogeneous computing
architectures through integrated performance tools,” in GPU Technology
Conference, 2016, p. poster.
[8] A. Hartono, B. Norris, and P. Sadayappan, “Annotation-based empirical
performance tuning using Orio,” in Parallel & Distributed Processing,
2009. IEEE International Symposium on. IEEE, 2009, pp. 1–11.
[9] N. Chaimov, B. Norris, and A. Malony, “Toward multi-target autotuning
for accelerators,” in Parallel and Distributed Systems (ICPADS), 2014
20th IEEE International Conference on, Dec 2014, pp. 534–541.
[10] A. Mametjanov, D. Lowell, C.-C. C.C. Ma, and B. Norris, “Autotuning
stencil-based computations on GPUs,” in Cluster Computing (CLUSTER), 2012 IEEE International Conference on, 2012, pp. 266–274.
[11] V. Volkov, “Better performance at lower occupancy,” 2010.
[12] “NVIDIA GeForce GTX 680 Whitepaper,” Tech. Rep., 2012, http://bit.
ly/2jzzX13.
[13] A. Monsifrot, F. Bodin, and R. Quiniou, “A machine learning approach
to automatic production of compiler heuristics,” in Artiﬁcial Intelligence:
Methodology, Systems, and Applications. Springer, 2002, pp. 41–50.
[14] M. Stephenson and S. Amarasinghe, “Predicting unroll factors using
supervised classiﬁcation,” in Code Generation and Optimization, 2005.
CGO 2005. International Symposium on. IEEE, 2005, pp. 123–134.
[15] R. Lim, D. Carrillo-Cisneros, W. Alkowaileet, and I. Scherson, “Computationally efﬁcient multiplexing of events on hardware counters,” in
Linux Symposium, 2014.
[16] R. Lim, A. Malony, B. Norris, and N. Chaimov, “Identifying optimization opportunities within kernel execution in GPU codes,” in Euro-Par
2015: Parallel Processing Workshops. Springer, 2015.
[17] B. Norris, A. Hartono, and W. Gropp, “Annotations for productivity
and performance portability,” in Petascale Computing: Algorithms
and Applications, ser. Computational Science. Chapman & Hall /
CRC Press, Taylor and Francis Group, 2007, pp. 443–462, preprint
ANL/MCS-P1392-0107. [Online]. Available: http://www.mcs.anl.gov/
uploads/cels/papers/P1392.pdf
[18] A. Nukada and S. Matsuoka, “Auto-tuning 3-D FFT library for CUDA
GPUs,” in Supercomputing Conference (SC 2009), 2015.
[19] S. Tomov, R. Nath, H. Ltaief, and J. Dongarra, “Dense linear algebra
solvers for multicore with GPU accelerators,” in International Parallel
and Distributed Processing Symposium (IPDPS 2010), Jan. 2010.
[20] “CHiLL: A Framework for Composing High-Level Loop Transformations,” USC Department of Computer Science, Tech. Rep., Jun. 2008.
[21] R. Xu, S. Chandrasekaran, X. Tian, and B. Chapman, “An analytical
model-based auto-tuning framework for locality-aware loop scheduling,”
in International Conference on High Performance Computing. Springer,
2016, pp. 3–20.
[22] NVIDIA, “CUDA Toolkit,” https://developer.nvidia.com/cuda-toolkit.
[23] R. Gupta, I. Laguna, D. Ahn, T. Gamblin, S. Bagchi, and F. Lin,
“STATuner: Efﬁcient Tuning of CUDA Kernels Parameters,” in Supercomputing Conference (SC 2015), 2015, p. poster.
[24] G. e. Fursin, “Milepost gcc: Machine learning enabled self-tuning
compiler,” International journal of parallel programming, vol. 39, no. 3,
pp. 296–327, 2011.
[25] S. Sreepathi, M. Grodowitz, R. Lim, P. Taffet, P. C. Roth, J. Meredith,
S. Lee, D. Li, and J. Vetter, “Application characterization using Oxbow
toolkit and PADS infrastructure,” in Proceedings of the 1st International
Workshop on Hardware-Software Co-Design for High Performance
Computing. IEEE Press, 2014, pp. 55–63.
[26] P. de Oliveira Castro, C. Akel, E. Petit, M. Popov, and W. Jalby,
“CERE: LLVM Based Codelet Extractor and REplayer for Piecewise
Benchmarking and Optimization,” ACM Transactions on Architecture
and Code Optimization (TACO), vol. 12, no. 1, p. 6, 2015.
