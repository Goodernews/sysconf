[1] Hybrid Memory Cube Specification 2.1.
hybridmemorycube.org, 2014.

[2] NVLink, Pascal and Stacked Memory: Feeding the Appetite for
Big Data. https://goo.gl/y6oYqD, 2014.

[3] The Road to the AMD “Fiji” GPU. https://goo.gl/ci9BvG, 2015.

[4] Data Sheet: Tesla P100. https://goo.gl/Y6gfXZ, 2016.

[5] Intel®64 and IA-32 Architectures Optimization Reference Manual. https://goo.gl/WKkFiw, 2016.

[6] NVidia Tesla V100 GPU Accelerator. https://goo.gl/5eqTg5,
2017.

[7] Acarwat, N., ET AL. Page Placement Strategies for GPUs within
Heterogeneous Memory Systems. In ASPLOS (2015).

[8] AGARWAL, N., ET AL. Unlocking Bandwidth for GPUs in CCNUMA Systems. In HPCA (2015).

[9] AHN, J., ET AL. A Scalable Processing-in-Memory Accelerator
for Parallel Graph Processing. In ISCA (2015).

[10] AHN, J., ET AL. PIM-Enabled Instructions: A Low-Overhead,
Locality-Aware Processing-in-Memory Architecture. In ISCA
(2015).

[11] Battey, L., AnD Curis, C. Configuring Huge Pages in Red Hat
Enterprise Linux 4 or 5. https://goo.gl/lqB1uf, 2014.

[12] Bovet, D. P., anD Cesati, M. Understanding the Linux kernel.
O’Reilly Media, Inc., 2005.

[13] CHANG, K., ET AL. Low-Cost Inter-Linked Subarrays (LISA):
Enabling Fast Inter-Subarray Data Movement in DRAM. In
HPCA (2016).

[14] Cuanc, K., eT AL. Understanding Latency Variation in Modern
DRAM Chips: Experimental Characterization, Analysis, and
Optimization. In SIGMETRICS (2016).

[15] Cuance, K., ET At. Understanding Reduced-Voltage Operation in Modern DRAM Devices: Experimental Characterization,
Analysis, and Mechanisms. SIGMETRICS (2017).

[16] CHATTERJEE, N., ET AL. Leveraging Heterogeneity in DRAM
Main Memories to Accelerate Critical Word Access. In MICRO
(2012).

[17] Cut, P., ET AL. PRIME: A Novel Processing-in-Memory Architecture for Neural Network Computation in ReRAM-Based
Main Memory. In ISCA (2016).

[18] Cou, C., ET AL. CAMEO: A Two-Level Memory Organization
with Capacity of Main Memory and Flexibility of HardwareManaged Cache. In MICRO (2014).

[19] Cou, C., ET AL. BATMAN: Maximizing Bandwidth Utilization
of Hybrid Memory Systems. Tech report, ECE, Georgia Institute
of Technology, 2015.

[20] Cou, C., ET AL. BEAR: Techniques for Mitigating Bandwidth
Bloat in Gigascale DRAM Caches. In ISCA (2015).

[21] Cuou, C., ET AL. CANDY: Enabling Coherent DRAM Caches
for Multi-Node Systems. In MICRO (2016).

http://www.
[22] Duman, G., ET AL. PDRAM: a Hybrid PRAM and DRAM Main
Memory System. In DAC (2009).

[23] FRANEY, S., AND LirastTI, M. Tag Tables. In HPCA (2015).

[24] Gutur, N., ET AL. Bi-Modal DRAM Cache: Improving Hit Rate,
Hit Latency and Bandwidth. In MICRO (2014).

[25] HENNING, J. L. SPEC CPU2006 Benchmark Descriptions. ACM
SIGARCH Computer Architecture News 34, 4 (2006).

[26] Huang, C.-C., ET AL. C?D: Mitigating the NUMA Bottleneck
via Coherent DRAM Caches. In MICRO (2016).

[27] Huane, C.-C., anD Nacarajan, V. ATCache: Reducing DRAM
Cache Latency via a Small SRAM Tag Cache. In PACT (2014).

[28] Jane, H., ET At. Efficient Footprint Caching for Tagless DRAM
Caches. In HPCA (2016).

[29] JEDEC. JESD235 High Bandwidth Memory (HBM) DRAM,
2013.

[30] JEFFERS, J., ET AL. Intel Xeon Phi Processor High Performance
Programming: Knights Landing Edition. Morgan Kaufmann,
2016.

[31] Jevpyic, D., ET AL. Die-Stacked DRAM Caches for Servers:
Hit Ratio, Latency, or Bandwidth? Have It All with Footprint
Cache. In ISCA (2013).

[32] Jevpyic, D., ET AL. Unison Cache: A Scalable and Effective
Die-Stacked DRAM Cache. In MICRO (2014).

[33] JIANG, X., ET AL. CHOP: Adaptive Filter-Based DRAM Caching
for CMP Server Platforms. In HPCA (2010).

[34] Kim, Y., ET aL. Ramulator: A Fast and Extensible DRAM Simulator. CAL (2016).

[35] Kumar, S., AND WILKERSON, C. Exploiting Spatial Locality in
Data Caches using Spatial Footprints. In ISCA (1998).

[36] Lez, D., ET aL. LRFU: A Spectrum of Policies that Subsumes
the Least Recently Used and Least Frequently Used Policies.
IEEE transactions on Computers (2001).

[37] Les, D., eT AL. Tiered-Latency DRAM: A Low Latency and
Low Cost DRAM Architecture. In HPCA (2013).

[38] Lez, Y., ET AL. A Fully Associative, Tagless DRAM Cache. In
ISCA (2015).

[39] Lt, Y., ET AL. Utility-Based Hybrid Memory Management. In
CLUSTER (2017).

[40] Liptay, J. Structural Aspects of the System/360 Model 85, I:
The cache. IBM Systems Journal (1968).

[41] Lou, G. H., anp Hitt, M. D. Efficiently Enabling Conventional
Block Sizes for Very Large Die-Stacked DRAM Caches. In
MICRO (2011).

[42] Lu, S.-L., ET aL. Improving DRAM Latency with Dynamic
Asymmetric Subarray. In MICRO (2015).

14

[43] Luo, Y., ET aL. Characterizing Application Memory Error
Vulnerability to Optimize Datacenter Cost via HeterogeneousReliability Memory. In DSN (2014).

[44] Mreswanl, M., ET AL. Heterogeneous Memory Architectures:
A HW/SW Approach for Mixing Die-stacked and Off-package
Memories. In HPCA (2015).

[45] Meza, J., ET AL. Enabling Efficient and Scalable Hybrid Memories Using Fine-Granularity DRAM Cache Management. CAL
(2012).

[46] O’Connor, M. Highlights of the High-Bandwidth Memory

(HBM) Standard.
[47] PHADKE, S., AND NARAYANASAMY, S. MLP Aware Heteroge
neous Memory System. In DATE (2011).

[48] QureEsut, M., ET AL. A Case for MLP-Aware Cache Replacement. ISCA (2006).

[49] Quresu, M., ET AL. Adaptive Insertion Policies for High
Performance Caching. In ISCA (2007).

[50] QuresHI, M., AND Lou, G. Fundamental Latency Trade-off
in Architecting DRAM Caches: Outperforming Impractical
DRAM-Tags with a Simple and Practical Design. In MICRO
(2012).

[51] RoBInson, J., AND DEVARAKONDA, M. Data cache management
using frequency-based replacement. In SIGMETRICS (1990).

[52] ROTHMAN, J., AND SMITH, A. Sector Cache Design and Performance. In MASCOTS (2000).

[53] SANCHEZ, D., AND Kozyrakis, C. ZSim: Fast and Accurate
Microarchitectural Simulation of Thousand-Core Systems. In
ISCA (2013).

[54] Si, J., ET AL. Transparent Hardware Management of Stacked
DRAM as Part of Memory. In MICRO (2014).

[55] Sopant, A. Intel®Xeon Phi™ Processor “Knights Landing”
Architectural Overview. https://goo.gl/dp1dVm, 2015.

[56] Sopani, A., ET AL. Knights Landing: Second-Generation Intel
Xeon Phi Product. IEEE Micro 36, 2 (2016), 34-46.

[57] STALLINGS, W., ET AL. Operating Systems: Internals and Design
Principles, vol. 148. Prentice Hall Upper Saddle River, NJ, 1998.

[58] VitLavigyA, C., ET AL. DiDi: Mitigating The Performance
Impact of TLB. Shootdowns Using A Shared TLB Directory. In
PACT (2011).

[59] Yoon, H., ET At. Row Buffer Locality Aware Caching Policies
for Hybrid Memories. In ICCD (2012).

[60] Yu, X., ET AL. IMP: Indirect Memory Prefetcher. In MICRO
(2015).

[61] Yu, X., ET at. Banshee: Bandwidth-Efficient DRAM Caching
Via Software/Hardware Cooperation. arXiv:1704.02677 (2017).