[1] N. Agarwal, D. Nellans, M. O’Connor, S. W. Keckler, and T. F. Wenisch, “Unlocking bandwidth for GPUs in CC-NUMA systems,” in Proc. HPCA-21, 2015.
[2] D. H. Albonesi, “Selective cache ways: On-demand cache resource allocation,” in
Proc. MICRO-32, 1999.
[3] M. Awasthi, K. Sudan, R. Balasubramonian, and J. Carter, “Dynamic hardwareassisted software-controlled page placement to manage capacity allocation and
sharing within large caches,” in Proc. HPCA-15, 2009.
[4] R. Balasubramonian, D. H. Albonesi, A. Buyuktosunoglu, and S. Dwarkadas, “A
dynamically tunable memory hierarchy,” IEEE TOC, vol. 52, no. 10, 2003.
[5] B. M. Beckmann, M. R. Marty, and D. A. Wood, “ASR: Adaptive selective
replication for CMP caches,” in Proc. MICRO-39, 2006.
[6] B. M. Beckmann and D. A. Wood, “Managing wire delay in large chipmultiprocessor caches,” in Proc. ASPLOS-XI, 2004.
[7] N. Beckmann and D. Sanchez, “Jigsaw: Scalable software-defined caches,” in
Proc. PACT-22, 2013.
[8] N. Beckmann, P.-A. Tsai, and D. Sanchez, “Scaling distributed cache hierarchies
through computation and data co-scheduling,” in Proc. HPCA-21, 2015.
[9] J. Chang and G. S. Sohi, “Cooperative caching for chip multiprocessors,” in Proc.
ISCA-33, 2006.
[10] K. Chen, S. Li, N. Muralimanohar, J. H. Ahn, J. B. Brockman, and N. P. Jouppi,
“CACTI-3DD: Architecture-level modeling for 3D die-stacked DRAM main memory,” in Proc. DATE, 2012.
[11] Z. Chishti, M. D. Powell, and T. Vijaykumar, “Optimizing replication, communication, and capacity allocation in CMPs,” in Proc. ISCA-32, 2005.
[12] S. Cho and L. Jin, “Managing distributed, shared L2 caches through OS-level
page allocation,” in Proc. MICRO-39, 2006.
[13] C. Chou, A. Jaleel, and M. K. Qureshi, “BEAR: techniques for mitigating bandwidth bloat in gigascale DRAM caches,” in Proc. ISCA-42, 2015.
[14] B. A. Cuesta, A. Ros, M. E. Gómez, A. Robles, and J. F. Duato, “Increasing the
effectiveness of directory caches by deactivating coherence for private memory
blocks,” in Proc. ISCA-38, 2011.
[15] W. J. Dally, “GPU Computing: To Exascale and Beyond,” in Proc. SC10, 2010.
[16] A. Das, M. Schuchhardt, N. Hardavellas, G. Memik, and A. Choudhary, “Dynamic
directories: A mechanism for reducing on-chip interconnect power in multicores,”
in Proc. DATE, 2012.
[17] X. Dong, Y. Xie, N. Muralimanohar, and N. P. Jouppi, “Simple but effective
heterogeneous main memory with on-chip memory controller support,” in Proc.
SC10, 2010.
[18] N. Duong, D. Zhao, T. Kim, R. Cammarota, M. Valero, and A. V. Veidenbaum,
“Improving cache management policies using dynamic reuse distances,” in Proc.
MICRO-45, 2012.
[19] H. Dybdahl and P. Stenstrom, “An adaptive shared/private nuca cache partitioning
scheme for chip multiprocessors,” in Proc. HPCA-13, 2007.
[20] S. Franey and M. Lipasti, “Tag tables,” in Proc. HPCA-21, 2015.
[21] M. Frigo and S. G. Johnson, “The design and implementation of FFTW3,” Proc.
of the IEEE, vol. 93, no. 2, 2005.
[22] M. Frigo, C. E. Leiserson, H. Prokop, and S. Ramachandran, “Cache-oblivious
algorithms,” in Proc. FOCS-40, 1999.
[23] D. Gross, Fundamentals of queueing theory. John Wiley & Sons, 2008.
[24] P. Hammarlund, A. J. Martinez, A. A. Bajwa, D. L. Hill, E. Hallnor, H. Jiang,
M. Dixon, M. Derr, M. Hunsaker, R. Kumar, R. B. Osborne, R. Rajwar, R. Singhal, R. D’Sa, R. Chappell, S. Kaushik, S. Chennupaty, S. Jourdan, S. Gunther,
T. Piazza, and T. Burton, “Haswell: The Fourth-Generation Intel Core Processor,”
IEEE Micro, vol. 34, no. 2, 2014.
[25] N. Hardavellas, M. Ferdman, B. Falsafi, and A. Ailamaki, “Reactive NUCA: nearoptimal block placement and replication in distributed caches,” in Proc. ISCA-36,
2009.
[26] N. Hardavellas, I. Pandis, R. Johnson, N. Mancheril, A. Ailamaki, and B. Falsafi,
“Database servers on chip multiprocessors: Limitations and opportunities,” in Proc.
CIDR, 2007.
[27] J. L. Hennessy and D. A. Patterson, Computer Architecture: A Quantitative
Approach (5th ed.). Morgan Kaufmann, 2011.
[28] E. Herrero, J. González, and R. Canal, “Elastic cooperative caching: an autonomous dynamically adaptive memory hierarchy for chip multiprocessors,”
in Proc. ISCA-37, 2010.
[29] A. Hilton, N. Eswaran, and A. Roth, “FIESTA: A sample-balanced multi-program
workload methodology,” Proc. MoBS, 2009.
[30] J.-H. Huang, “Leaps in visual computing,” in Proc. GTC, 2015.
[31] Intel, “Knights Landing: Next Generation Intel Xeon Phi,” in Proc. SC13, 2013.
[32] J. Jaehyuk Huh, C. Changkyu Kim, H. Shafi, L. Lixin Zhang, D. Burger, and
S. Keckler, “A NUCA substrate for flexible CMP cache sharing,” IEEE TPDS,
vol. 18, no. 8, 2007.
[33] A. Jaleel, K. Theobald, S. C. Steely, and J. Emer, “High performance vache
replacement using re-reference interval prediction (RRIP),” in Proc. ISCA-37,
2010.
[34] D. Jevdjic, S. Volos, and B. Falsafi, “Die-stacked DRAM caches for servers: Hit
ratio, latency, or bandwidth? Have it all with footprint cache,” in Proc. ISCA-40,
2013.
[35] X. Jiang, N. Madan, L. Zhao, M. Upton, R. Iyer, S. Makineni, D. Newell, D. Solihin, and R. Balasubramonian, “CHOP: Adaptive filter-based DRAM caching for
CMP server platforms,” in Proc. HPCA-16, 2010.
[36] A. Kannan, N. E. Jerger, and G. H. Loh, “Enabling interposer-based disintegration
of multi-core processors,” in Proc. MICRO-48, 2015.
[37] D. Kanter, “Silvermont, Intel’s low power architecture,” 2013.
[38] H. Kasture and D. Sanchez, “Ubik: Efficient cache sharing with strict QoS for
latency-critical workloads,” in Proc. ASPLOS-XIX, 2014.
[39] S. W. Keckler, W. J. Dally, B. Khailany, M. Garland, and D. Glasco, “GPUs and
the future of parallel computing,” IEEE Micro, vol. 31, no. 5, 2011.
[40] S. M. Khan, Y. Tian, and D. A. Jimenez, “Sampling dead block prediction for
last-level caches,” in Proc. MICRO-43, 2010.
[41] C. Kim, D. Burger, and S. Keckler, “An adaptive, non-uniform cache structure for
wire-delay dominated on-chip caches,” in Proc. ASPLOS-X, 2002.
[42] H. Lee, S. Cho, and B. R. Childers, “CloudCache: Expanding and shrinking
private caches,” in Proc. HPCA-17, 2011.
[43] S. Li, J. H. Ahn, R. D. Strong, J. B. Brockman, D. M. Tullsen, and N. P. Jouppi,
“McPAT: An integrated power, area, and timing modeling framework for multicore
and manycore architectures,” in Proc. MICRO-42, 2009.
[44] G. H. Loh, “3D-stacked memory architectures for multi-core processors,” in Proc.
ISCA-35, 2008.
[45] G. H. Loh and M. D. Hill, “Efficiently enabling conventional block sizes for very
large die-stacked DRAM caches,” in Proc. MICRO-44, 2011.
[46] J. Macri, “AMD’s next generation GPU and high bandwidth memory architecture:
Fury,” in HotChips-27, 2015.
[47] N. Madan, L. Zhao, N. Muralimanohar, A. Udipi, R. Balasubramonian, R. Iyer,
S. Makineni, and D. Newell, “Optimizing communication and capacity in a 3D
stacked reconfigurable cache hierarchy,” in Proc. HPCA-15, 2009.
[48] M. R. Marty and M. D. Hill, “Virtual hierarchies to support server consolidation,”
in Proc. ISCA-34, 2007.
[49] J. Merino, V. Puente, and J. Gregorio, “ESP-NUCA: A low-cost adaptive nonuniform cache architecture,” in Proc. HPCA-16, 2010.
[50] Micron, “1.35V DDR3L power calculator (4Gb x16 chips),” 2013.
[51] A. Mukkara, N. Beckmann, and D. Sanchez, “Whirlpool: Improving dynamic
cache management with static data classification,” in Proc. ASPLOS-XXI, 2016.
[52] N. Muralimanohar, R. Balasubramonian, and N. Jouppi, “Optimizing NUCA
organizations and wiring alternatives for large caches with CACTI 6.0,” in Proc.
MICRO-40, 2007.
[53] M. Qureshi and G. Loh, “Fundamental latency trade-offs in architecting DRAM
caches,” in Proc. MICRO-45, 2012.
[54] M. K. Qureshi, “Adaptive spill-receive for robust high-performance caching in
CMPs,” in Proc. HPCA-15, 2009.
[55] M. K. Qureshi, A. Jaleel, Y. N. Patt, S. C. Steely, and J. Emer, “Adaptive insertion
policies for high performance caching,” in Proc. ISCA-34, 2007.
[56] M. K. Qureshi and Y. N. Patt, “Utility-based cache partitioning: A low-overhead,
high-performance, runtime mechanism to partition shared caches,” in Proc.
MICRO-39, 2006.
[57] D. Sanchez and C. Kozyrakis, “The ZCache: Decoupling ways and associativity,”
in Proc. MICRO-43, 2010.
[58] D. Sanchez and C. Kozyrakis, “Vantage: Scalable and Efficient Fine-Grain Cache
Partitioning,” in Proc. ISCA-38, 2011.
[59] D. Sanchez and C. Kozyrakis, “ZSim: Fast and accurate microarchitectural simulation of thousand-core systems,” in Proc. ISCA-40, 2013.
[60] J. Sim, J. Lee, M. K. Qureshi, and H. Kim, “FLEXclusion: Balancing cache
capacity and on-chip bandwidth via flexible exclusion,” in Proc. ISCA-39, 2012.
[61] A. Snavely and D. M. Tullsen, “Symbiotic jobscheduling for a simultaneous
multithreading processor,” in Proc. ASPLOS-IX, 2000.
[62] A. Sodani, R. Gramunt, J. Corbal, H.-S. Kim, K. Vinod, S. Chinthamani, S. Hutsell,
R. Agarwal, and Y.-C. Liu, “Knights Landing: Second-generation Intel Xeon Phi
product,” IEEE Micro, vol. 36, no. 2, 2016.
[63] J. Stuecheli, “POWER8,” in HotChips-25, 2013.
[64] D. H. Woo, N. H. Seong, D. L. Lewis, and H.-H. Lee, “An optimized 3D-stacked
memory architecture by exploiting excessive, high-density TSV bandwidth,” in
Proc. HPCA-16, 2010.
[65] L. Yavits, A. Morad, and R. Ginosar, “Cache hierarchy optimization,” IEEE CAL,
vol. 13, no. 2, 2014.
[66] M. Zhang and K. Asanovic, “Victim replication: Maximizing capacity while
hiding wire delay in tiled chip multiprocessors,” in Proc. ISCA-32, 2005.
