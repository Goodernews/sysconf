[1] 2015. Performance Scaled Messaging 2 (Intel). https://www.intel.
com/content/dam/support/us/en/documents/network/omni-adptr/sb/
Intel_PSM2_PG_H76473_v1_0.pdf. (2015).

[2] 2015. Score-P User Manual.
current/pdf/scorep.pdf. (2015).

[3] 2017. Catalyst (LLNL). https://hpc.linl.gov/hardware/platforms/catalyst. (2017).

[4] 2017. MFEM: Modular finite element methods. mfem.org. (2017).

[5] 2017. MULARD. (2017). https://codesign [In| gov/mulard.php.

[6] 2017. Open Trace Format 2. (2017). https://sile.zih.tu-dresden.de/otf2-current/
index.html.

[7] 2017. Quartz (LLNL). https://hpc.lInl.gov/hardware/platforms/Quartz. (2017).

[8] 2017. The Sierra Advanced Technology System. http://computation.IInl.gov/
computers/sierra-advanced-technology-system. (2017).

[9] 2017. Stampede (TACC). https://www.tacc.utexas.edu/stampede/. (2017).

[10] 2017. Summit (OLCF). http://www.olcf.ornl. gov/summit. (2017).

[11] Bilge Acun, Nikhil Jain, Abhinav Bhatele, Misbah Mubarak, Christopher D.
Carothers, and Laxmikant V. Kale. 2015. Preliminary Evaluation of a Parallel Trace Replay Tool for HPC Network Simulations. In Proceedings of the 3rd
Workshop on Parallel and Distributed Agent-Based Simulations (PADABS ’15).
LLNL-CONF-667225.

[12] Albert Alexandrov, Mihai F. Ionescu, Klaus E. Schauser, and Chris Scheiman.
1995. LogGP: incorporating long messages into the LogP modelfi?!one step closer
towards a realistic model for parallel computation. In Proceedings of the seventh
annual ACM symposium on Parallel algorithms and architectures (SPAA °95). ACM,
New York, NY, USA, 95-105. DOT: http://dx.doi.org/10.1145/215399.215427

[13] A. Arsenlis, W. Cai, M. Tang, M. Rhee, T. Oppelstrup, G. Hommes, T. G. Pierce,
and V. V. Bulatov. 2007. Enabling strain hardening simulations with dislocation
dynamics. Modelling and Simulation in Materials Science and Engineering 15, 6
(2007).

[14] David W. Bauer Jr., Christopher D. Carothers, and Akintayo Holder. 2009. Scalable Time Warp on Blue Gene Supercomputers. In Proceedings of the 2009

https://silc.zih.tu-dresden.de/scorepS$C17, November 12-17, 2017, Denver, CO, USA
ACM/IEEE/SCS 23rd Workshop on Principles of Advanced and Distributed Simulation (PADS ’09). IEEE Computer Society, Washington, DC, USA.
[15] Claude Bernard, Tom Burch, "omas A. DeGrand, Carleton DeTar, Steven Gottlieb, Urs M. Heller, James E. Hetrick, Kostas Orginos, Bob Sugar, and Doug
Toussaint. 2000. Scaling tests of the improved Kogut-Susskind quark action.
Physical Review D 61 (2000).
[16] Patrick S. Brantley, Shawn A. Dawson, Michael Sco! McKinley, Ma!hew J.
O’Brien, David E. Stevens, Bret R. Beck, Eric D. Jurgenson, Chris A. Ebbers, and
James M. Hall. 2013. Recent Advances in the Mercury Monte Carlo Particle
Transport Code. In International Conference on Mathematics and Computational
Methods Applied to Nuclear Science & Engineering (M&C’13). Sun Valley, ID.
[17] Ron Brightwell and Keith Underwood. 2003. Evaluation of an eager protocol
optimization for MPI. In European Parallel Virtual Machine/Message Passing
Interface Users! Group Meeting. Springer, 327–334.
[18] Henri Casanova, Arnaud Giersch, Arnaud Legrand, Martin'inson, and Fred´ eric ´
Suter. 2014. Versatile, Scalable, and Accurate Simulation of Distributed Applications and Platforms. J. Parallel and Distrib. Comput. 74, 10 (June 2014), 2899–2917.
[19] Dong Chen, N.A. Eisley, P. Heidelberger, R.M. Senger, Y. Sugawara, S. Kumar, V.
Salapura, D.L. Sa!er#eld, B. Steinmacher-Burow, and J.J. Parker. 2011. "e IBM
Blue Gene/Q interconnection network and message unit. In High Performance
Computing, Networking, Storage and Analysis (SC), 2011 International Conference
for. 1–10.
[20] Salvador Coll, Eitan Frachtenberg, Fabrizio Petrini, Adolfy Hoisie, and Leonid
Gurvits. 2003. Using multirail networks in high-performance clusters. Concurrency and Computation: Practice and Experience 15, 7-8 (2003), 625–651.
[21] Greg Faanes, Abdulla Bataineh, Duncan Roweth, Tom Court, Edwin Froese,
Bob Alverson, Tim Johnson, Joe Kopnick, Mike Higgins, and James Reinhard.
2012. Cray Cascade: A Scalable HPC System Based on a Dragon&y Network.
In Proceedings of the International Conference on High Performance Computing,
Networking, Storage and Analysis (SC ’12). IEEE Computer Society Press, Los
Alamitos, CA, USA.
[22] R.D. Falgout, J.E. Jones, and U.M. Yang. 2006. "e Design and Implementation
of hypre, a Library of Parallel High Performance Preconditioners. In Numerical
Solution of Partial Di"erential Equations on Parallel Computers, A.M. Bruaset and
A. Tveito (Eds.). Vol. 51. Springer-Verlag, 267–294.
[23] F. Gygi, E. W. Draeger, B. R. De Supinski, R. K. Yates, F. Franche!i, S. Kral, J.
Lorenz, C. W. Ueberhuber, J. A. Gunnels, and J. C. Sexton. 2005. Large-Scale FirstPrinciples Molecular Dynamics Simulations on the Blue Gene/L Platform using
the Qbox Code. In Proceedings of Supercomputing 2005 4 (2005), 24. Conference
on High Performance Networking and Computing, Gordon Bell Prize #nalist.
[24] John P. Hayes, Trevor N. Mudge, and 'entin F. Stout. 1986. Architecture of a
Hypercube Supercomputer. In ICPP. 653–660.
[25] Chao Huang, Gengbin Zheng, Sameer Kumar, and Laxmikant V. Kale. 2006. ´
Performance Evaluation of Adaptive MPI. In Proceedings of ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming 2006.
[26] Nikhil Jain, Abhinav Bhatele, Xiang Ni, Nicholas J. Wright, and Laxmikant V. Kale.
2014. Maximizing "roughput on a Dragon&y Network. In Proceedings of the
ACM/IEEE International Conference for High Performance Computing, Networking,
Storage and Analysis (SC ’14). IEEE Computer Society. LLNL-CONF-653557.
[27] Nikhil Jain, Abhinav Bhatele, Samuel T. White, Todd Gamblin, and Laxmikant V.
Kale. 2016. Evaluating HPC Networks via Simulation of Parallel Workloads.
In Proceedings of the ACM/IEEE International Conference for High Performance
Computing, Networking, Storage and Analysis (SC ’16). IEEE Computer Society.
LLNL-CONF-690662.
[28] Nan Jiang, Daniel U. Becker, George Michelogiannakis, James Balfour, Brian
Towles, John Kim, and William J. Dally. 2013. A Detailed and Flexible CycleAccurate Network-on-Chip Simulator. In IEEE International Symposium on Performance Analysis of Systems and So#ware.
[29] John Kim, Wiliam J. Dally, Steve Sco!, and Dennis Abts. 2008. TechnologyDriven, Highly-Scalable Dragon&y Topology. SIGARCH Comput. Archit. News 36
(June 2008), 77–88. Issue 3.
[30] C.E. Leiserson. 1985. Fat-trees: Universal Networks for Hardware-E%cient
Supercomputing. IEEE Transactions on Computers 34, 10 (October 1985).
[31] Charles E. Leiserson. 1985. Fat-trees: Universal Networks for Hardware-e%cient
Supercomputing. IEEE Trans. Comput. 34, 10 (Oct. 1985), 892–901.
[32] Edgar A. Leon, Ian Karlin, Abhinav Bhatele, Steven H. Langer, Chris Chambreau,
Louis H. Howell, Trent D’Hooge, and Ma!hew L. Leininger. 2016. Characterizing
Parallel Scienti#c Applications on Commodity Clusters: An Empirical Study
of a Tapered Fat-tree. In Proceedings of the ACM/IEEE International Conference
for High Performance Computing, Networking, Storage and Analysis (SC ’16).
IEEE Computer Society, Article 78, 12 pages. h!p://dl.acm.org/citation.cfm?id=
3014904.3015009 LLNL-CONF-681011.
[33] M.Blumrich, D.Chen, P.Coteus, A.Gara, M.Giampapa, P.Heidelberger, S.Singh,
B.Steinmacher-Burow, T.Takken, and P.Vranas. 2003. Design and Analysis of the
Blue Gene/L Torus Interconnection Network. IBM Research Report (December
2003).
[34] George Michelogiannakis, Khalid Ibrahim, Jeremiah Shalf, John anWilke, Samuel
Knight, and Joseph Kenny. 2017. APHiD: Hierarchical Task Placement to Enable a
Tapered Fat Tree Topology for Lower Power and Cost in HPC Networks. CCGrid
2017 (to appear) (2017).
[35] Misbah Mubarak, Christopher D. Carothers, Robert B. Ross, and Philip Carns.
2016. Enabling Parallel Simulation of Large-Scale HPC Network Systems. IEEE
Trans. Parallel Distrib. Syst. (2016). DOI:h!p://dx.doi.org/10.1109/TPDS.2016.
2543725
[36] Mohamed Ould-Khaoua and Hamid Sarbazi-Azad. 2001. An Analytical Model of
Adaptive Wormhole Routing in Hypercubes in the Presence of Hot Spot Tra%c.
IEEE Transactions on Parallel and Distributed Systems 12, 3 (2001), 283–292.
[37] S. Shende and A. D. Malony. 2005. "e TAU Parallel Performance System. International Journal of High Performance Computing Applications, ACTS Collection
Special Issue (2005).
[38] Kyle L. Spa$ord and Je$rey S. Ve!er. 2012. Aspen: A Domain Speci#c Language
for Performance Modeling. In Proceedings of the International Conference on
High Performance Computing, Networking, Storage and Analysis (SC ’12). IEEE
Computer Society Press, Los Alamitos, CA, USA, Article 84, 11 pages. h!p:
//dl.acm.org/citation.cfm?id=2388996.2389110
[39] C. H. Still, R. L. Berger, A. B. Langdon, D. E. Hinkel, L. J. Suter, and E. A. Williams.
2000. Filamentation and forward Brillouin sca!er of entire smoothed and aberrated laser beams. Physics of Plasmas 7, 5 (2000), 2023–2032.
[40] Rajeev "akur, Rolf Rabenseifner, and William Gropp. 2005. Optimization of
Collective Communication Operations in MPICH. International Journal of High
Performance Computing Applications 19, 1 (2005), 49–66.
[41] K.D. Underwood, M. Levenhagen, and A. Rodrigues. 2007. Simulating Red Storm:
Challenges and Successes in Building a System Simulation. In IEEE International
Parallel and Distributed Processing Symposium (IPDPS ’07).
[42] Noah Wolfe, Misbah Mubarak, Nikhil Jain, Jens Domke, Abhinav Bhatele, Christopher Carothers, and Rob Ross. 2017. Methods for E$ective Utilization of MultiRail Fat-Tree Interconnects (CCGrid 2017 (to appear)).
[43] Xu Yang, John Jenkins, Misbah Mubarak, Robert B. Ross, and Zhiling Lan. 2016.
Watch Out for the Bully! Job Interference Study on Dragon&y Network. In
Supercomputing.
