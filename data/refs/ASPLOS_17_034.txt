
[1] A. Ahmed, M. Aly, J. Gonzalez, S. Narayanamurthy, and A. J.
Smola. Scalable inference in latent variable models. In
Proceedings of the fifth ACM international conference on Web
search and data mining, pages 123-132. ACM, 2012.

[2] A. Asuncion and D. Newman. Uci machine learning repository, 2007.

[3] D. M. Blei, A. Y. Ng, and M. I. Jordan. Latent dirichlet
allocation. JMLR, 3:993-1022, 2003.

[4] J. L. Boyd-Graber, D. M. Blei, and X. Zhu. A topic model for
word sense disambiguation. In EMNLP-CoNLL, 2007.

[5] L. Cao and L. Fei-Fei. Spatially coherent latent topic model
for concurrent segmentation and classification of objects and
scenes. In ICCV, 2007.

[6] J. Chang and D. Blei. Relational topic models for document
networks. In AISTATS, 2009.

[7] J. Chen, K. Li, J. Zhu, and W. Chen. Warplda: a cache efficient
o (1) algorithm for latent dirichlet allocation. In VLDB, 2016.

[8] N. Chen, J. Zhu, F. Xia, and B. Zhang. Discriminative relational topic models. IEEE Trans. on Pattern Analysis and
Machine Intelligence, 37(5):973-986, 2015.

[9] W.-Y. Chen, J.-C. Chu, J. Luan, H. Bai, Y. Wang, and E. Y.
Chang. Collaborative filtering for orkut communities: discovery of user latent behavior. In WWW, 2009.

[10] Z. Ghahramani. Probabilistic machine learning and artificial
intelligence. Nature, 521:452-459, 2015.

[11] T. L. Griffiths and M. Steyvers. Finding scientific topics.
Proceedings of the National academy of Sciences, 101(suppl
1):5228-5235, 2004.

[12] T. Iwata, T. Yamada, and N. Ueda. Probabilistic latent semantic visualization: topic model for visualizing documents. In
KDD, 2008.

[13] Z. G. Kingsley. Selective studies and the principle of relative
frequency in language, 1932.

[14] A. Q. Li, A. Ahmed, S. Ravi, and A. J. Smola. Reducing the
sampling complexity of topic models. In KDD, 2014.

[15] J. D. O. Mark Harris, Shubhabrata Sengupta. Parallel prefix
sum (scan) with cuda. http: //http.developer nvidia.
com/GPUGems3/gpugems3_ch39 .htm1, 2007.

[16] NVIDIA. Segmented reduction. https: //nvlabs. github.
io/moderngpu/segreduce. html, 2013.

[17] NVIDIA. Segmented sort and locality sort. https://
nvlabs.github.io/moderngpu/segsort .htm1, 2013.

[18] NVIDIA. Cuda c programming guide. http://docs.
nvidia.com/cuda/cuda-c-programming-guide/
index .html#warp-vote-functions, 2015.

[19] J.-B. Tristan, J. Tassarotti, and G. Steele. Efficient training of
Ida on a gpu by mean-for-mode estimation. In Proceedings
of the 32nd International Conference on Machine Learning
(ICML-15), pages 59-68, 2015.

[20] A. J. Walker. An efficient method for generating discrete random variables with general distributions. ACM Transactions
on Mathematical Software (TOMS), 3(3):253-256, 1977.

[21] H. M. Wallach, I. Murray, R. Salakhutdinov, and D. Mimno.
Evaluation methods for topic models. In Proceedings of the
26th Annual International Conference on Machine Learning,
pages 1105-1112. ACM, 2009.

[22] Y. Wang, X. Zhao, Z. Sun, H. Yan, L. Wang, Z. Jin, L. Wang,
Y. Gao, J. Zeng, Q. Yang, et al. Towards topic modeling
for big data. ACM Transactions on Intelligent Systems and
Technology, 2014.

[23] FE Yan, N. Xu, and Y. Qi. Parallel inference for latent dirichlet
allocation on graphics processing units. In Advances in Neural
Information Processing Systems, pages 2134-2142, 2009.

[24] L. Yao, D. Mimno, and A. McCallum. Efficient methods for
topic model inference on streaming document collections. In
Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 937946. ACM, 2009.

[25] H.-F. Yu, C.-J. Hsieh, H. Yun, S. Vishwanathan, and I. S.
Dhillon. A scalable asynchronous distributed algorithm for
topic modeling. In Proceedings of the 24th International Conference on World Wide Web, pages 1340-1350. International
World Wide Web Conferences Steering Committee, 2015.

[26] J. Yuan, F Gao, Q. Ho, W. Dai, J. Wei, X. Zheng, E. P.
Xing, T.-Y. Liu, and W.-Y. Ma. Lightlda: Big topic models
on modest compute clusters. In WWW, 2015.

[27] M. Zaheer. Dmlc experimental-Ida. https: //github.com/
dnlc/experimental-1da, 2016.

[28] M. Zaheer, M. Wick, J.-B. Tristan, A. Smola, and G. L.
Steele Jr. Exponential stochastic cellular automata for massively parallel inference. In AISTATS, 2015.

[29] H. Zhao, B. Jiang, J. F. Canny, and B. Jaros. Same but different: Fast and high quality gibbs parameter estimation. In Proceedings of the 21th ACM SIGKDD International Conference
on Knowledge Discovery and Data Mining, pages 1495-1502.
ACM, 2015.

[30] J. Zhu, A. Ahmed, and E. Xing. Medlda: maximum margin
supervised topic models. Journal of Machine Learning Research, 13:2237â€”2278, 2012.

[31] J. Zhu, J. Chen, and W. Hu. Big learning with bayesian
methods. arXiv: 141 1.6370, 2014.