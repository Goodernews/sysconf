[1] F Zheng, H. Yu, C. Hantas, M. Wolf, G. Eisenhauer, K. Schwan,
H. Abbasi, and S. Klasky, “Goldrush: Resource efficient in situ scientific data analytics using fine-grained interference aware execution,”
in Proceedings of the International Conference on High Performance
Computing, Networking, Storage and Analysis. ACM, 2013, pp. 78:1—
78:12.

[2] D. Tiwari, S. S. Vazhkudai, Y. Kim, X. Ma, S. Boboila, and P. J.
Desnoyers, “Reducing data movement costs using energy-efficient, active
computation on ssd,” in 2012 Workshop on Power-Aware Computing and
Systems. USENIX, 2012.

[3] J. C. Bennett, H. Abbasi, P. Bremer, R. Grout, A. Gyulassy, T. Jin,
S. Klasky, H. Kolla, M. Parashar, V. Pascucci, P. Pebay, D. Thompson,
H. Yu, F. Zhang, and J. Chen, “Combining in-situ and in-transit processing to enable extreme-scale scientific analysis,” in Proceedings of the
International Conference on High Performance Computing, Networking,
Storage and Analysis. TEEE Computer Society Press, 2012, pp. 49:149:9.

[4] M. Dreher and B. Raffin, “A flexible framework for asynchronous in
situ and in transit analytics for scientific simulations,” in IEEE/ACM
International Symposium on Cluster, Cloud and Grid Computing, May
2014, pp. 277-286.

[5] J. Sima and P. Orponen, “General-purpose computation with neural
networks: A survey of complexity theoretic results,’ Neural Computing,
vol. 15, no. 12, pp. 2727-2778, 2003.

[6] R. Salakhutdinov and G. Hinton, “Semantic hashing,” Int. J. Approx.
Reasoning, vol. 50, no. 7, pp. 969-978, 2009.

[7] J. Zhou, L. Chen, C. L. P. Chen, Y. Wang, and H. X. Li, “Uncertain
data clustering in distributed peer-to-peer networks,” IEEE Transactions
on Neural Networks and Learning Systems, vol. PP, no. 99, pp. 1-15,
2017.

[8] H. Kargupta, W. Huang, K. Sivakumar, and E. Johnson, “Distributed
clustering using collective principal component analysis,’ Knowledge
and Information Systems, vol. 3, no. 4, pp. 422-448, 2001.

[9] S. Boyd, N. Parikh, E. Chu, B. Peleato, and J. Eckstein, “Distributed
optimization and statistical learning via the alternating direction method
of multipliers,” Found. Trends Mach. Learn., vol. 3, no. 1, pp. 1-22,
2011.

[10] T.-Y. Liu, W. Chen, and T. Wang, “Distributed machine learning: Foundations, trends, and practices,” in Proceedings of the 26th International
Conference on World Wide Web Companion, ser. WWW ’17 Companion,
2017, pp. 913-915.

[11] S. Bandyopadhyay, C. Giannella, U. Maulik, H. Kargupta, K. Liu, and
S. Datta, “Clustering distributed data streams in peer-to-peer environments,” Information Sciences, vol. 176, no. 14, 2006.

[12] M. Abadi, P. Barham, J. Chen, Z. Chen, A. Davis, J. Dean, M. Devin,
S. Ghemawat, G. Irving, M. Isard, M. Kudlur, J. Levenberg, R. Monga,
S. Moore, D. G. Murray, B. Steiner, P. Tucker, V. Vasudevan, P. Warden,
M. Wicke, Y. Yu, and X. Zheng, “Tensorflow: A system for large-scale
machine learning,” in Proceedings of the 12th USENIX Conference on
Operating Systems Design and Implementation, ser. OSDI’16, 2016, pp.
265-283.

[13] M. Abadi, “Tensorflow: Learning functions at scale,’ in Proceedings
of the 21st ACM SIGPLAN International Conference on Functional
Programming, ser. ICFP 2016, 2016.

[14] T. Estrada and M. Taufer, “On the effectiveness of application-aware selfmanagement for scientific discovery in volunteer computing systems,”
in Proceedings of the International Conference on High Performance
Computing, Networking, Storage and Analysis. TEEE Computer Society
Press, 2012, pp. 80:1-80:11.

[15] H. Kawashima, R. R. Sato, and H. Kitagawa, “Models and issues on
probabilistic data streams with Bayesian Networks,” in Proc. of the
International Symposium on Applications and the Internet (SAINT),
2008.

[16] Y. Liu, L. C. Jiao, F. Shang, F Yin, and F Liu, “An efficient matrix
bi-factorization alternative optimization method for low-rank matrix
recovery and completion,” Neural Netw., vol. 48, 2013.

[17] A. Gionis, P. Indyk, and R. Motwani, “Similarity search in high dimensions via hashing,” in Proceedings of the 25th International Conference
on Very Large Data Bases. Morgan Kaufmann Publishers Inc., 1999,
pp. 518-529.

[18] C. C. Aggarwal, J. L. Wolf, P. S. Yu, C. Procopiuc, and J. S. Park, “Fast
algorithms for projected clustering,” SIGMOD Rec., vol. 28, no. 2, pp.
61-72, 1999,

[19] A. Quiroz, M. Parashar, N. Gnanasambandam, and N. Sharma, “Design
and evaluation of decentralized online clustering,” ACM Trans. Auton.
Adapt. Syst., vol. 7, no. 3, pp. 34:1-34:31, 2012.

[20] P. Indyk and R. Motwani, “Approximate nearest neighbors: Towards
removing the curse of dimensionality,” in Proceedings of the Thirtieth
Annual ACM Symposium on Theory of Computing.
604-613.

[21] P. Zhang, B. J. Gao, X. Zhu, and L. Guo, “Enabling fast lazy learning for
data streams,” IEEE International Conference on Data Mining, vol. 0,
Re 932-941, 2011.

[22] Barrena, E. Jurado, P. Marquez-Neila, and C. Pachén, “A flexible
framework to ease nearest neighbor search in multidimensional data
spaces,” Data Knowl. Eng., vol. 69, no. 1, pp. 116-136, 2010.

[23] D. Omercevic, O. Drbohlav, and A. Leonardis, “High-dimensional feature matching: Employing the concept of meaningful nearest neighbors,”
in IEEE Ith International Conference on Computer Vision, 2007, pp.
1-8.

[24] S. Boyd, “Convex optimization: From embedded real-time to large-scale
distributed,” in Proceedings of the 17th ACM SIGKDD International
Conference on Knowledge Discovery and Data Mining, ser. KDD ’11,
2011.

[25] M. Ester, H.-P. Kriegel, J. Sander, X. Xu, and Others, “A density-based
algorithm for discovering clusters in large spatial databases with noise.”
in Kdd, vol. 96, no. 34, 1996, pp. 226-231.

[26] M. M. A. Patwary, S. Byna, N. R. Satish, N. Sundaram, Z. Lukié,
V. Roytershteyn, M. J. Anderson, Y. Yao, P. Dubey et al., “Bd-cats:
big data clustering at trillion particle scale,” in Proceedings of the
International Conference for High Performance Computing, Networking,
Storage and Analysis. ACM, 2015, p. 6.

[27] M. A. Patwary, D. Palsetia, A. Agrawal, W.-k. Liao, F. Manne, and
A. Choudhary, “A new scalable parallel dbscan algorithm using the
disjoint-set data structure,” in Proceedings of the International ConJerence on High Performance Computing, Networking, Storage and
Analysis, YEEE Computer Society Press, 2012, p. 62.

[28] Q. Zhang, L. T. Yang, Z. Chen, and P. Li, “Pphopcm: Privacy-preserving
high-order possibilistic c-means algorithm for big data clustering with
cloud computing,” IEEE Transactions on Big Data, vol. PP, no. 99, 2017.
[29] Z. Gheid and Y. Challal, “Efficient and privacy-preserving k-means clustering for big data mining,” in 2016 IEEE Trustcom/BigDataSE/SPA,
Aug 2016, pp. 791-798.

[30] R. R. Gupta, G. Mishra, S. Katara, A. Agarwal, M. K. Sarkar, R. Das,
and S. Kumar, “Data storage security in cloud computing using container
clustering,” in 2016 IEEE 7th Annual Ubiquitous Computing, Electronics
Mobile Communication Conference (UEMCON), Oct 2016, pp. 1-7.
[31] H. Kargupta, S. Datta, Q. Wang, and K. Sivakumar, “Random-data
perturbation techniques and privacy-preserving data mining,” Knowledge
and Information Systems, vol. 7, no. 4, pp. 387-414, 2005.

[32] P. Jin and Q. Song, “A novel index structure r*q-tree based on lazy
splitting and clustering,” in IEEE International Conference on Computer
Science and Automation Engineering (CSAE), 2011, pp. 405-407.

[33] M. Bendechache, N. A. Le-Khac, and M. T. Kechadi, “Hierarchical
aggregation approach for distributed clustering of spatial datasets,” in
2016 IEEE 16th International Conference on Data Mining Workshops
(ICDMW), Dec 2016, pp. 1098-1103.

[34] M. Rahmani and G. K. Atia, “In pursuit of novelty: A decentralized
approach to subspace clustering,” in 2016 54th Annual Allerton Conference on Communication, Control, and Computing (Allerton), Sept 2016,
pp. 447-451.

[35] R. Agrawal, J. Gehrke, D. Gunopulos, and P. Raghavan, “Automatic subspace clustering of high dimensional data for data mining applications,”
ACM SIGMOD Record, vol. 27, no. 2, pp. 94-105, 1998.

[36] S. Goil, H. Nagesh, and A. Choudhary, “MAFIA: Efficient and
scalable subspace clustering for very large data sets,” ... Discovery
and Data Mining, vol. 5, pp. 443-452, 1999. [Online]. Available:
http://mrl.cecsresearch.org/Resources/papers/goil99mafia.pdf

[37] R. Agrawal, R. Srikant, and Others, “Fast algorithms for mining association rules,” in Proc. 20th int. conf. very large data bases, VLDB, vol.
1215, 1994, pp. 487-499.

[38] H. W. Lilliefors, “On the kolmogorov-smirnov test for normality with
mean and variance unknown,” Journal of the American statistical
Association, vol. 62, no. 318, pp. 399-402, 1967.

[39] A. Adinetz, J. Kraus, J. Meinke, and D. Pleiter, GPUMAFIA: Efficient
Subspace Clustering with MAFIA on GPUs. Springer Berlin Heidelberg,
2013, pp. 838-849.