[1] N. Agarwal, D. Nellans, M. Stephenson, M. O’Connor, and S. W. Keckler,
“Page Placement Strategies for GPUs Within Heterogeneous Memory Systems,”
in International Conference on Architectural Support for Programming Languages
and Operating Systems (ASPLOS), 2015.
[2] B. Wang, B. Wu, D. Li, X. Shen, W. Yu, Y. Jiao, and J. S. Vetter, “Exploring Hybrid
Memory for GPU Energy Efficiency through Software-Hardware Co-Design,” in
PACT, 2013.
[3] F. X. Lin and X. Liu, “Memif: Towards Programming Heterogeneous Memory
Asynchronously,” in International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), 2016.
[4] G. Chen, B. Wu, D. Li, and X. Shen, “PORPLE: An Extensible Optimizer for
Portable Data Placement on GPU,” in IEEE/ACM International Symposium on
Microarchitecture, 2014.
[5] B. Jang, D. Schaa, P. Mistry, and D. Kaeli, “Exploiting Memory Access Patterns to
Improve Memory Performance in Data-Parallel Architectures,” IEEE Transactions
on Parallel and Distributed Systems, vol. 22, no. 1, pp. 105–118, 2011.
[6] S. Hong and H. Kim, “An Analytical Model for a GPU Architecture with Memorylevel and Thread-level Parallelism Awareness,” in Proceedings of the 36th Annual
International Symposium on Computer Architecture, ser. ISCA ’09, 2009.
[7] J. Sim, A. Dasgupta, H. Kim, and R. Vuduc, “A Performance Analysis Framework
for Identifying Potential Benefits in GPGPU Applications,” in ACM SIGPLAN
Symposium on Principles and Practice of Parallel Programming (PPoPP), 2012.
[8] Y. Zhang and J. D. Owens, “A Quantitative Performance Analysis Model for GPU
Architectures,” in Proceedings of International Symposium on High Performance
Computer Architecture (HPCA), 2011.
[9] G. Chen and X. Shen, “Coherence-Free Multiview: Enabling Reference-Discerning
Data Placement on GPU,” in International Conference on Supercomputing (ICS),
2016.
[10] N. Fauzia, L.-N. Pouchet, and P. Sadayappan, “Characterizing and Enhancing
Global Memory Data Coalescing on GPUs,” in International Symposium on Code
Generation and Optimization (CGO), 2015.
[11] S. Ryoo, C. I. Rodrigues, S. S. Baghsorkhi, S. S. Stone, D. B. Kirk, and W.m. W. Hwu, “Optimization Principles and Application Performance Evaluation of
a Multithreaded GPU Using CUDA,” in ACM SIGPLAN Symposium on Principles
and Practice of Parallel Programming (PPoPP), 2008.
[12] Y. Huang and D. Li, “Performance Modeling for Optimal Data Placement on
GPU with Heterogeneous Memory Systems,” 2016, Technical Report, PASA Lab,
University of California, Merced.
[13] A. Singhal, “Modern Information Retrieval: A Brief Overview,” Bulletin of the
IEEE Computer Society Technical Committee on Data Engineering, vol. 24, no. 4,
2001.
[14] A. Danalis, G. Marin, C. McCurdy, J. S. Meredith, P. C. Roth, K. Spafford,
V. Tipparaju, and J. S. Vetter, “The Scalable Heterogeneous Computing (SHOC)
benchmark suite,” in GPGPU, 2010.
[15] “CUDA
C
Programming
Guide,”
http://docs.nvidia.com/cuda/cuda-cprogramming-guide.
[16] H. Wong, M.-M. Papadopoulou, M. Sadooghi-Alvandi, and A. Moshovos, “Demystifying GPU Microarchitecture through Microbenchmarking,” in ISPASS. IEEE
Computer Society, 2010, pp. 235–246.
[17] X. Mei and X. Chu, “Dissecting GPU Memory Hierarchy through Microbenchmarking,” CoRR, vol. abs/1509.02308, 2015.
[18] S. Rixner, W. J. Dally, U. J. Kapasi, P. Mattson, and J. D. Owens, “Memory Access
Scheduling,” in International Symposium on Computer Architecture (ISCA), 2000.
[19] N. Gulur, M. Mehendale, R. Manikantan, and R. Govindarajan, “ANATOMY:
An Analytical Model of Memory System Performance,” in ACM International
Conference on Measurement and Modeling of Computer Systems (SIGMETRICS),
2014.
[20] N. Gulur, M. Mehendale, and R. Govindarajan, “A Comprehensive Analytical
Performance Model of DRAM Caches,” in ACM/SPEC International Conference
on Performance Engineering (ICPE), 2015.
[21] Y. Bao, M. Chen, Y. Ruan, L. Liu, J. Fan, Q. Yuan, B. Song, and J. Xu, “HMTT:
A Platform Independent Full-system Memory Trace Monitoring System,” in ACM
International Conference on Measurement and Modeling of Computer Systems
(SIGMETRICS), 2008.
[22] L. Liu, Z. Cui, M. Xing, Y. Bao, M. Chen, and C. Wu, “A Software Memory
Partition Approach for Eliminating Bank-level Interference in Multicore Systems,”
in International Conference on Parallel Architectures and Compilation Techniques
(PACT), 2012.
[23] A. Bakhoda, G. L. Yuan, W. W. L. Fung, H. Wong, and T. M. Aamodt, “Analyzing
CUDA Workloads Using a Detailed GPU Simulator,” in ISPASS, 2009.
[24] J. Kingman, “On the Algebra of Queues,” Journal of Applied Probability, vol. 3,
pp. 285–326, 1996.
[25] M. Stephenson, S. K. Sastry Hari, Y. Lee, E. Ebrahimi, D. R. Johnson, D. Nellans,
M. O’Connor, and S. W. Keckler, “Flexible Software Profiling of GPU Architectures,” in International Symposium on Computer Architecture (ISCA), 2015.
[26] S. S. Baghsorkhi, M. Delahaye, S. J. Patel, W. D. Gropp, and W.-m. W. Hwu, “An
Adaptive Performance Modeling Tool for GPU Architectures,” in ACM SIGPLAN
Symposium on Principles and Practice of Parallel Programming (PPoPP), 2010.
[27] J.-C. Huang, J. H. Lee, H. Kim, and H.-H. S. Lee, “GPUMech: GPU Performance
Modeling Technique Based on Interval Analysis,” in IEEE/ACM International
Symposium on Microarchitecture (MICRO), 2014.
[28] T. Tang, X. Yang, and Y. Lin, “Cache Miss Analysis for GPU Programs Based
on Stack Distance Profile,” in International Conference on Distributed Computing
Systems (ICDCS), 2011.
[29] C. Nugteren, G. J. van den Braak, H. Corporaal, and H. Bal, “A Detailed GPU
Cache Model Based on Reuse Distance Theory,” in International Symposium on
High Performance Computer Architecture (HPCA), 2014.
[30] J. W. Choi, A. Singh, and R. W. Vuduc, “Model-Driven Autotuning of Sparse
Matrix-vector Multiply on GPUs,” in ACM SIGPLAN Symposium on Principles
and Practice of Parallel Programming (PPoPP), 2010.
[31] W. Ma and G. Agrawal, “An Integer Programming Framework for Optimizing
Shared Memory Use on GPUs,” in International Conference on Parallel Architectures and Compilation Techniques (PACT), 2010.
