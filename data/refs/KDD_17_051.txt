[1] 2017. Supplementary material. (2017). www.cs.cmu.edu/⇠zhitingh/kddsupp [2] Amr Ahmed and Eric Xing. 2007. On tight approximate inference of the logistic-
normal topic admixture model. In AISTATS.
[3] Kayhan Batmanghelich, Ardavan Saeedi, Karthik Narasimhan, and Sam Gersh-
man. 2016. Nonparametric Spherical Topic Modeling with Word Embeddings. In
ACL.
[4] David M Blei,￿ omas L Gri￿ths, and Michael I Jordan. 2010.￿ e nested Chinese
restaurant process and Bayesian nonparametric inference of topic hierarchies. J.
ACM 57, 2 (2010), 7.
[5] David M Blei and John D La￿erty. 2007. A correlated topic model of science. ￿e
Annals of Applied Statistics (2007), 17–35.
[6] David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent Dirichlet
allocation. JMLR 3, Jan (2003), 993–1022.
[7] Jordan L Boyd-Graber, David M Blei, and Xiaojin Zhu. 2007. A Topic Model for
Word Sense Disambiguation.. In EMNLP-CoNLL. 1024–1033.
[8] Jianfei Chen, Kaiwei Li, Jun Zhu, and Wenguang Chen. 2016. WarpLDA: a Simple and E￿cient O(1) Algorithm for Latent Dirichlet Allocation. In VLDB.
[9] Jianfei Chen, Jun Zhu, Zi Wang, Xun Zheng, and Bo Zhang. 2013. Scalable inference for logistic-normal topic models. In NIPS. 2445–2453.
[10] Rajarshi Das, Manzil Zaheer, and Chris Dyer. 2015. Gaussian LDA for topic models with word embeddings. In ACL.
[11] Kumar Dubey, Qirong Ho, Sinead A Williamson, and Eric P Xing. 2014. Depen- dent nonparametric trees for dynamic hierarchical clustering. In NIPS. 1152– 1160.
[12] Yarin Gal and Zoubin Ghahramani. 2014. Pitfalls in the use of Parallel Inference for the Dirichlet Process.. In ICML. 208–216.
[13] Prasoon Goyal, Zhiting Hu, Xiaodan Liang, Chenyu Wang, and Eric Xing. 2017. Nonparametric Variational Auto-encoders for Hierarchical Representation Learn- ing. arXiv preprint arXiv:1703.07027 (2017).
[14] Aditya Grover and Jure Leskovec. 2016. node2vec: Scalable feature learning for networks. In KDD. ACM, 855–864.
[15] Geo￿rey E Hinton and Ruslan R Salakhutdinov. 2009. Replicated so￿max: an undirected topic model. In NIPS. 1607–1614.
[16] Ma￿hew D Ho￿man, David M Blei, Chong Wang, and John William Paisley. 2013. Stochastic variational inference. JMLR 14, 1 (2013), 1303–1347.
[17] Zhiting Hu, Qirong Ho, Avinava Dubey, and Eric P Xing. 2015. Large-scale Distributed Dependent Nonparametric Trees.. In ICML. 1651–1659.
[18] Zhiting Hu, Poyao Huang, Yuntian Deng, Yingkai Gao, and Eric P Xing. 2015. Entity Hierarchy Embedding.. In ACL. 1292–1300.
[19] Zhiting Hu, Gang Luo, Mrinmaya Sachan, Eric Xing, and Zaiqing Nie. 2016. Grounding topic models with knowledge bases. In IJCAI.
[20] Zhiting Hu, Zichao Yang, Xiaodan Liang, Ruslan Salakhutdinov, and Eric P Xing. 2017. Controllable Text Generation. ICML (2017).
[21] Zhiting Hu, Zichao Yang, Ruslan Salakhutdinov, and Eric P Xing. 2017. On Unifying Deep Generative Models. arXiv preprint arXiv:1706.00550 (2017).
[22] Di Jiang, Rongzhong Lian, Lei Shi, and Hua Wu. 2016. Latent Topic Embedding.
In COLING.
[23] Diederik P Kingma and Max Welling. 2013. Auto-encoding variational Bayes.
arXiv preprint arXiv:1312.6114 (2013).
[24] Miguel La ́zaro-Gredilla. 2014. Doubly stochastic variational Bayes for non-
conjugate inference. ICML.
[25] Tuan Le and Hady W Lauw. 2014. Semantic visualization for spherical represen-
tation. In KDD. ACM, 1007–1016.
[26] Tuan Minh Van LE and Hady W Lauw. 2014. Manifold learning for jointly
modeling topic and visualization. (2014).
[27] Tao Lei, Yuan Zhang, Regina Barzilay, and Tommi Jaakkola. 2014. Low-rank
tensors for scoring dependency structures. ACL.
[28] Aaron Q Li, Amr Ahmed, Sujith Ravi, and Alexander J Smola. 2014. Reducing
the sampling complexity of topic models. In KDD. ACM, 891–900.
[29] Shaohua Li, Tat-Seng Chua, Jun Zhu, and Chunyan Miao. 2016. Generative topic
embedding: a continuous representation of documents. In ACL.
[30] Wei Li and Andrew McCallum. 2006. Pachinko allocation: DAG-structured
mixture models of topic correlations. In ICML. ACM, 577–584.
[31] Yuezhang Li, Ronghuo Zheng, Tian Tian, Zhiting Hu, Rahul Iyer, and Katia Sycara. 2016. Joint Embedding of Hierarchical Categories and Entities for Concept
Categorization and Dataless Classi￿cation. In COLING.
[32] Xiaodan Liang, Zhiting Hu, Hao Zhang, Chuang Gan, and Eric P Xing. 2017.
Recurrent Topic-Transition GAN for Visual Paragraph Generation. arXiv preprint
arXiv:1703.07022 (2017).
[33] Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado, and Je￿rey Dean. 2013.
Distributed Representations of Words and Phrases and￿ eir Compositionality.
In NIPS.
[34] David Mimno, Ma￿Ho￿ man, and David Blei. 2012. Sparse stochastic inference
for latent Dirichlet allocation. arXiv preprint arXiv:1206.6425 (2012).
[35] John Paisley, Chong Wang, David M Blei, et al. 2012.￿ e discrete in￿nite logistic
normal distribution. Bayesian Analysis 7, 4 (2012), 997–1034.
[36] Duangmanee Pew Pu￿hividhya, Hagai T A￿ias, and Srikantan Nagarajan. 2009.
Independent factor topic models. In ICML. ACM, 833–840.
[37] Rajesh Ranganath and David M Blei. 2016. Correlated random measures. JASA
(2016).
[38] Jian Tang, Meng￿ , and Qiaozhu Mei. 2015. PTE: Predictive text embedding
through large-scale heterogeneous text networks. In KDD. ACM, 1165–1174.
[39] Michalis K Titsias. 2009. Variational Learning of Inducing Variables in Sparse
Gaussian Processes. In AISTATS, Vol. 5. 567–574.
[40] Yi Wang, Xuemin Zhao, Zhenlong Sun, Hao Yan, Lifeng Wang, Zhihui Jin, Liubin
Wang, Yang Gao, Ching Law, and Jia Zeng. 2015. Peacock: Learning long-tail
topic features for industrial applications. TIST 6, 4 (2015), 47.
[41] Andrew G Wilson, Zhiting Hu, Ruslan R Salakhutdinov, and Eric P Xing. 2016.
Stochastic Variational Deep Kernel Learning. In NIPS. 2586–2594.
[42] Jinhui Yuan, Fei Gao, Qirong Ho, Wei Dai, Jinliang Wei, Xun Zheng, Eric Po Xing, Tie-Yan Liu, and Wei-Ying Ma. 2015. LightLDA: Big topic models on modest
computer clusters. In WWW. ACM, 1351–1361.
