[1] N. Asadi and J. Lin. 2013. Document Vector Representations for Feature Extrac- tion in Multi-Stage Document Ranking. Inf. Retr. 16, 6 (2013), 747–768.
[2] N. Asadi and J. Lin. 2013. Training e￿cient tree-based models for document ranking. In Proc. ECIR. 146–157.
[3] N. Asadi, J. Lin, and A. P. De Vries. 2014. Runtime optimizations for tree-based machine learning models. Trans. on Know. and Data Eng. 26, 9 (2014), 2281–2292.
[4] James Bergstra and Yoshua Bengio. 2012. Random search for hyper-parameter
optimization. Journal of Machine Learning Research 13, Feb (2012), 281–305.
[5] C. Burges. 2010. From ranknet to lambdarank to lambdamart: An overview.
Learning 11, 23-581 (2010), 81.
[6] B. B. Cambazoglu, H. Zaragoza, O. Chapelle, J. Chen, C. Liao, Z. Zheng, and
J. Degenhardt. 2010. Early Exit Optimizations for Additive Machine Learned
Ranking Systems.. In Proc. WSDM. 411–420.
[7] G. Capannini, C. Lucchese, F. M. Nardini, S. Orlando, R. Perego, and N. Tonello￿o.
2016.￿ ality versus e￿ciency in document scoring with learning-to-rank
models. Inf. Proc. & Man. 52, 6 (2016), 1161–1177.
[8] D. Carmel and E. Yom-Tov. 2010. Estimating the￿ ery Di￿culty for Information
Retrieval. Morgan & Claypool.
[9] O. Chapelle and Y. Chang. 2011. Yahoo! Learning to Rank Challenge Overview.
14 (2011), 1–24.
[10] C. L. A. Clarke, J. S. Culpepper, and A. Mo￿at. 2016. Assessing e￿ciency–
e￿ectiveness tradeo￿s in multi-stage retrieval systems without using relevance
judgments. Inf. Retr. 19, 4 (2016), 351–377.
[11] J. S. Culpepper, C. L. A. Clarke, and J. Lin. 2016. Dynamic Cuto￿ Prediction in
Multi-Stage Retrieval Systems. In Proc. ADCS. 17–24.
[12] J. Friedman. 2001. Greedy function approximation: a gradient boosting machine.
Annals of statistics (2001), 1189–1232.
[13] S. Huston, J. S. Culpepper, and W. B. Cro￿. 2014. Indexing Word-Sequences for
Ranked Retrieval. ACM Trans. Information Systems 32, 1 (2014), 3.1–3.26.
[14] X. Jin, T. Yang, and X. Tang. 2016. A Comparison of Cache Blocking Methods for Fast Execution of Ensemble-based Score Computation. In Proc. SIGIR. 629–638.
[15] T.-Y. Liu. 2009. Learning to Rank for Information Retrieval. Foundations and
Trends in Information Retrieval 3, 3 (2009), 225–331.
[16] X. Lu, A. Mo￿at, and J. S. Culpepper. 2015. On the Cost of Extracting Proximity Features for Term-Dependency Models. In Proc. CIKM. 293–302.
[17] X. Lu, A. Mo￿at, and J. S. Culpepper. 2016. E￿cient and E￿ective Higher Order Proximity Modeling. In Proc. ICTIR. 21–30.
[18] C. Lucchese, F. M. Nardini, S. Orlando, R. Perego, F. Silvestri, and S. Trani. 2016. Post-learning optimization of tree ensembles for e￿cient ranking. In Proc. SIGIR. 949–952.
[19] C. Lucchese, F. M. Nardini, S. Orlando, R. Perego, N. Tonello￿o, and R. Ven- turini. 2015.￿ ickScorer: A Fast Algorithm to Rank Documents with Additive Ensembles of Regression Trees. In Proc. SIGIR. 73–82.
[20] C. Lucchese, F. M. Nardini, S. Orlando, R. Perego, N. Tonello￿o, and R. Venturini. 2016. Exploiting CPU SIMD extensions to speed-up document scoring with tree ensembles. In Proc. SIGIR. 833–836.
[21] C. Macdonald, R. L. T. Santos, and I. Ounis. 2012. On the Usefulness of￿ ery Features for Learning to Rank. In Proc. CIKM. 2559–2562.
[22] C. Macdonald, R. L. T. Santos, and I. Ounis. 2013.￿ e whens and hows of learning to rank for web search. Inf. Retr. 16, 5 (2013), 584–628.
[23] C. Macdonald, R. L. T. Santos, I. Ounis, and B. He. 2013. About learning models with multiple query-dependent features. ACM Trans. Information Systems 31, 3 (2013), 11:1–11:39.
[24] D. Metzler and W. B. Cro￿. 2005. A Markov random￿ eld model for term dependencies.. In Proc. SIGIR. 472–479.
[25] A. Mohan, Z. Chen, and K. Q. Weinberger. 2011. Web-Search Ranking with Initialized Gradient Boosted Regression Trees. Journal of Machine Learning Research 14 (2011), 77–89.
[26] J. Pedersen. 2010.￿ ery understanding at Bing. Invited talk, SIGIR (2010).
[27] M. Petri, A. Mo￿at, and J. S. Culpepper. 2014. Score-safe term dependency
processing with hybrid indexes. In Proc. SIGIR. 899–902.
[28] V. C. Raykar, B. Krishnapuram, and S. Yu. 2010. Designing e￿cient cascaded
classi￿ers: tradeo￿ between accuracy and cost. In Proc. KDD. 853–860.
[29] S. E. Robertson, S. Walker, S. Jones, M. Hancock-Beaulieu, and M. Gatford. 1994.
Okapi at TREC-3.. In Proc. TREC-3.
[30] N. Tax, S. Bockting, and D. Hiemstra. 2015. A cross-benchmark comparison of
87 learning to rank methods. Inf. Proc. & Man. 51, 6 (2015), 757–772.
[31] R. Tibshirani. 1994. Regression Shrinkage and Selection Via the Lasso. Journal
of the Royal Statistical Society, Series B 58 (1994), 267–288.
[32] A. Trotman, C. L. A. Clarke, I. Ounis, J. S. Culpepper, M.-A. Cartright, and S. Geva.
2012. Open source information retrieval: a report on the SIGIR 2012 workshop.
SIGIR Forum 46, 2 (2012), 95–101.
[33] Y. Tsuruoka, J. Tsujii, and S. Ananiadou. 2009. Stochastic Gradient Descent
Training for L1-regularized Log-linear Models with Cumulative Penalty. In Proc.
ACL. 477–485.
[34] S. Tyree, K. Q. Weinberger, K. Agrawal, and J. Paykin. 2011. Parallel Boosted
Regression Trees for Web Search Ranking. In Proc. WWW. 387–396.
[35] L. Wang, J. Lin, and D. Metzler. 2010. Learning to e￿ciently rank. In Proc. SIGIR.
138–145.
[36] L. Wang, J. Lin, and D. Metzler. 2011. A Cascade Ranking Model for E￿cient
Ranked Retrieval. In Proc. SIGIR. 105–114.
[37] L. Wang, J. Lin, D. Metzler, and J. Han. 2014. Learning to e￿ciently rank on big
data. In Proc. WWW (Companion Volume). 209–210.
[38] Z. Xu, M. J. Kusner, K. Q. Weinberger, and M. Chen. 2013. Cost-Sensitive Tree of
Classi￿ers.. In Proc. ICML. 133–141.
[39] Z. Xu, M. J. Kusner, K. Q. Weinberger, M. Chen, and O. Chapelle. 2014. Classi￿er
Cascades and Trees for Minimizing Feature Evaluation Cost. Journal of Machine
Learning Research 15 (2014), 2113–2144.
[40] C. Zhai and J. La￿erty. 2004. A Study of Smoothing Methods for Language
Models Applied to Information Retrieval. ACM Trans. Information Systems 22, 2 (April 2004), 179–214.
