[1] CCCC - C and C++ code counter. http://cccc.sourceforge.net/.

[2] Chromium - the chromium projects. https://www.chromium.org/Home.

[3] Common vulnerability scoring system v3.0: Specification document. https://www.
first.org/cvss/specification- document.

[4] Common weakness enumeration (CWE). https://ewe.mitre.org/data/index.html.

[5] CVE - common vulnerabilities and exposures. https://cve.mitre.org/.

[6] CWE-121: Stack-based buffer overflow. https://cwe.mitre.org/data/definitions/
121.html.

[7] E.W. Dijkstra archive: On the reliability of programs. https://www.cs.utexas.edu/
users/EWD/transcriptions/EWD03xx/EWD303.html.

[8] ISO/IEC 27004:2016: Monitoring, measurement, analysis and evaluation. http:
//www.iso27001security.com/html/27004 html.

[9] JLint. Online at http://artho.com/jlint/.

[10] Metrix++ project. metrixplusplus.sourceforge.net/.

[11] PMD. Online at https://pmd.github.io/.

[12] Weka 3: Data mining software in java. http://www.cs.waikato.ac.nz/ml/weka/.

[13] Chrome owned by exploits in hacker contests, but google’s $1m purse still safe |
wired. March 2012.

[14] Pwn2Own 2016: Windows, OS X, Chrome, Edge, Safari all hacked - gHacks tech
news. March 2016. (Accessed on 04/25/2017).

[15] F. E. Allen. Control flow analysis. In ACM Sigplan Notices, volume 5, pages 1-19.
ACM, 1970.

[16] B. Alshammari, C. Fidge, and D. Corney. Security metrics for object-oriented
class designs. In Quality Software, 2009. QSIC’09. 9th International Conference on,
pages 11-20. IEEE, 2009.

[17] F. ans Kunst. Lint, a c program checker. 1988.

[18] N. Ayewah, D. Hovemeyer, J. D. Morgenthaler, J. Penix, and W. Pugh. Using static
analysis to find bugs. IEEE software, 25(5):22-29, 2008.

[19] R. Barbuti, C. Bernardeschi, and N. De Francesco. Checking security of java
bytecode by abstract interpretation. In Proceedings of the 2002 ACM Symposium
on Applied Computing, SAC ’02, 2002.

[20] Y. Bertot, G. Huet, P. Castéran, and C. Paulin-Mohring. Interactive Theorem Proving
and Program Development: Coq’Art: The Calculus of Inductive Constructions. Texts
in Theoretical Computer Science. An EATCS Series. Springer Berlin Heidelberg,
2013.

[21] Y. Brun and M. D. Ernst. Finding latent code errors via machine learning over
program executions. In Proceedings of the 26th International Conference on Software
Engineering, pages 480-490. IEEE Computer Society, 2004.

[22] C. Cadar, D. Dunbar, D. R. Engler, et al. Klee: Unassisted and automatic generation
of high-coverage tests for complex systems programs. In OSDI, volume 8, pages
209-224, 2008.

[23] F. Camilo, A. Meneely, and M. Nagappan. Do bugs foreshadow vulnerabilities?
a study of the chromium project. In Mining Software Repositories (MSR), 2015
IEEE/ACM 12th Working Conference on, pages 269-279. IEEE, 2015.

Bhushan Jain, Chia-Che Tsai, and Donald E. Porter

[24] H. Chen, D. Dean, and D. Wagner. Model checking one million lines of c code. In
NDSS, volume 4, pages 171-185, 2004.

[25] H. Chen and D. Wagner. Mops: an infrastructure for examining security properties
of software. In CCS, pages 235-244. ACM, 2002.

[26] J. C. Corbett, M. B. Dwyer, J. Hatcliff, S. Laubach, C. S. Pasareanu, H. Zheng,
et al. Bandera: Extracting finite-state models from java source code. In Software
Engineering, 2000. Proceedings of the 2000 International Conference on, pages 439448. IEEE, 2000.

[27] P. Cousot and R. Cousot. Abstract interpretation: a unified lattice model for static
analysis of programs by construction or approximation of fixpoints. In Proceedings of the 4th ACM SIGACT-SIGPLAN symposium on Principles of programming
languages, pages 238-252. ACM, 1977.

[28] C. Couto, P. Pires, M. T. Valente, R. Bigonha, A. Hora, and N. Anquetil. Bugmapsgranger: A tool for causality analysis between source code metrics and bugs. In
Brazilian Conference on Software: Theory and Practice (CBSoft’13), 2013.

[29] A. Danial. cloc. https://github.com/AlDanial/cloc.

[30] D. Dean, S. Gaurino, L. Eusebi, A. Keplinger, T. Pavlik, R. Watro, A. Cammarata,
J. Murray, K. McLaughlin, J. Cheng, et al. Lessons learned in game development
for crowdsourced software formal verification. 2015 USENIX Summit on Gaming,
Games, and Gamification in Security Education (3GSE 15), 2015.

[31] J. Dolby, M. Vaziri, and F. Tip. Finding bugs efficiently with a sat solver. In
Proceedings of the the 6th joint meeting of the European software engineering
conference and the ACM SIGSOFT symposium on The foundations of software
engineering, pages 195-204. ACM, 2007.

[32] M. B. Dwyer, G. S. Avrunin, and J. C. Corbett. Property specification patterns for
finite-state verification. In Proceedings of the second workshop on Formal methods
in software practice, pages 7-15. ACM, 1998.

[33] D. Engler, D. Y. Chen, S. Hallem, A. Chou, and B. Chelf. Bugs as deviant behavior:
A general approach to inferring errors in systems code. In ACM SIGOPS Operating
Systems Review, volume 35, pages 57-72. ACM, 2001.

[34] C. Flanagan, K. R. M. Leino, M. Lillibridge, G. Nelson, J. B. Saxe, and R. Stata.
Extended static checking for java. SIGPLAN Not., 37(5):234—245, May 2002.

[35] R. Gerth, D. Peled, M. Y. Vardi, and P. Wolper. Simple on-the-fly automatic verification of linear temporal logic. In Protocol Specification, Testing and Verification
XV, pages 3-18. Springer, 1996.

[36] M. J. C. Gordon and T. F. Melham. Introduction to HOL: a theorem proving environment for higher order logic. Cambridge University Press, 1993.

[37] M. H. Halstead. Elements of software science, volume 7. Elsevier New York, 1977.

[38] C. Hawblitzel, J. Howell, M. Kapritsos, J. R. Lorch, B. Parno, M. L. Roberts, S. Setty,
and B. Zill. Ironfleet: proving practical distributed systems correct. In Proceedings
of the 25th Symposium on Operating Systems Principles, pages 1-17. ACM, 2015.

[39] C. Hawblitzel, J. Howell, J. R. Lorch, A. Narayan, B. Parno, D. Zhang, and B. Zill.
Ironclad apps: End-to-end security via automated full-system verification. In
OSDI, pages 165-181, 2014.

[40] D. Hovemeyer and W. Pugh. Finding bugs is easy. ACM Sigplan Notices, 39(12).92—
106, 2004.

[41] M. Howard, J. Pincus, and J. M. Wing. Measuring relative attack surfaces. In
Computer Security in the 21st Century, pages 109-137. Springer, 2005.

[42] P. B. Jackson, B. J. Ellis, and K. Sharp. Using smt solvers to verify high-integrity
programs. In Proceedings of the second workshop on Automated formal methods,
pages 60-68. ACM, 2007.

[43] M. Kaufmann, P. Manolios, and J. S. Moore. Computer-aided reasoning: ACL2 case
studies, volume 4. Springer Science & Business Media, 2013.

[44] G. Klein, K. Elphinstone, G. Heiser, J. Andronick, D. Cock, P. Derrin, D. Elkaduwe,
K. Engelhardt, R. Kolanski, M. Norrish, T. Sewell, H. Tuch, and $. Winwood. seL4:
Formal verification of an OS kernel. In SOSP, 2009.

[45] C. Marinescu, R. Marinescu, P. F. Mihancea, and R. Wettel. iplasma: An integrated
platform for quality assessment of object-oriented design. In In ICSM (Industrial
and Tool Volume, pages 77-80. Society Press, 2005.

[46] R. Marinescu and D. Ratiu. Quantifying the quality of object-oriented design: The
factor-strategy model. In Proceedings of the 11th Working Conference on Reverse
Engineering, WCRE ’04, 2004.

[47] T. J. McCabe. A complexity measure. JEEE Transactions on software Engineering,
(4):308-320, 1976.

[48] D. Mellado, E. Fernandez-Medina, and M. Piattini. A comparison of software
design security metrics. In Proceedings of the Fourth European Conference on
Software Architecture: Companion Volume, pages 236-242. ACM, 2010.

[49] N. Moha and Y.-G. Guéhéneuc. Decor: A tool for the detection of design defects. In
Proceedings of the Twenty-second IEEE/ACM International Conference on Automated
Software Engineering, ASE ’07, 2007.

[50] D. M. Nicol, W. H. Sanders, and K. S. Trivedi. Model-based evaluation: from
dependability to security. IEEE Transactions on dependable and secure computing,
1(1):48-65, 2004.

[51] T. Nipkow, M. Wenzel, and L. C. Paulson. Isabelle/HOL: A Proof Assistant for
Higher-order Logic. Springer-Verlag, Berlin, Heidelberg, 2002.

[52] Nist and E. Aroms. NIST Special Publication 800-55 Revi Security Metrics Guide
for Information Technology Systems. CreateSpace, Paramount, CA, 2012.
A Clairvoyant Approach to Evaluating Software (In)Security

[53] K. Pan, S. Kim, and E. J. Whitehead Jr. Bug classification using program slicing
metrics. In IEEE International Workshop on Source Code Analysis and Manipulation,
pages 31—42. IEEE, 2006.

[54] S.C. P. Profile. Common criteria for information technology security evaluation.
2001.

[55] G. Rasool and Z. Arshad. A review of code smell mining techniques. J. Softw. Evol.
Process, 27(11):867-895, Nov. 2015.

[56] T. Reps, S. Horwitz, and M. Sagiv. Precise interprocedural dataflow analysis via
graph reachability. In Proceedings of the 22Nd ACM SIGPLAN-SIGACT Symposium
on Principles of Programming Languages, POPL "95, pages 49-61, New York, NY,
USA, 1995. ACM.

[57] T. Ridge, D. Sheets, T. Tuerk, A. Giugliano, A. Madhavapeddy, and P. Sewell.
Sibylfs: formal specification and oracle-based testing for posix and real-world file
systems. In Proceedings of the 25th Symposium on Operating Systems Principles,
pages 38-53. ACM, 2015.

[58] N. Roperia. JSmell: A Bad Smell detection tool for Java systems. California State
University, Long Beach, 2009.

[59] N. Rutar, C. B. Almazan, and J. S. Foster. A comparison of bug finding tools
for java. In Software Reliability Engineering, 2004. ISSRE 2004. 15th International
Symposium on, pages 245-256. IEEE, 2004.

[60] ©. Sheyner, J. Haines, S. Jha, R. Lippmann, and J. M. Wing. Automated generation
and analysis of attack graphs. In Security and privacy, 2002. Proceedings. 2002 IEEE
Symposium on, pages 273-284. IEEE, 2002.

HotO$’17, May 2017, British Columbia, Canada

[61] Y. Shin, A. Meneely, L. Williams, and J. A. Osborne. Evaluating complexity, code
churn, and developer activity metrics as indicators of software vulnerabilities.
IEEE Transactions on Software Engineering, 37(6):772—787, 2011.

[62] H. Sigurbjarnarson, J. Bornholt, E. Torlak, and X. Wang. Push-button verification
of file systems via crash refinement. In OSDE, 2016.

[63] R. Sinha, S. Rajamani, S. Seshia, and K. Vaswani. Moat: Verifying confidentiality of
enclave programs. In Proceedings of the 22nd ACM SIGSAC Conference on Computer
and Communications Security, pages 1169-1184. ACM, 2015.

[64] S. Slinger, D. Ing, L. M. F. Moonen, S. Slinger, S. Dr, and I. L. M. F. Moonen. Title:
Code Smell Detection in Eclipse. 2005.

[65] N. Tsantalis, T. Chaikalis, and A. Chatzigeorgiou. Jdeodorant: Identification and
removal of type-checking bad smells. In Proceedings of the 2008 12th European
Conference on Software Maintenance and Reengineering, CSMR ’08, 2008.

[66] A.J. A. Wang. Information security models and metrics. In Proceedings of the 43rd
annual Southeast regional conference-Volume 2, pages 178-184. ACM, 2005.

[67] J. A. Wang, H. Wang, M. Guo, and M. Xia. Security metrics for software systems.
In Proceedings of the 47th Annual Southeast Regional Conference, page 47. ACM,
2009.

[68] N. Zazworka and C. Ackermann. Codevizard: A tool to aid the analysis of software evolution. In Proceedings of the 2010 ACM-IEEE International Symposium on
Empirical Software Engineering and Measurement, ESEM °10, 2010.

[69] F. Zeng. A machine learning approach to finding bugs.