[1] D. A. Reed and J. Dongarra, “Exascale computing and big data,”
Communications of the ACM, vol. 58, no. 7, pp. 56–68, 2015.
[2] R. Leland, R. Murphy, B. Hendrickson, K. Yelick, J. Johnson, and
J. Berry, “Large-Scale Data Analytics and Its Relationship to Simulation,” Sandia National Laboratories, Tech. Rep., 2016.
[3] S. Jha, J. Qiu, A. Luckow, P. K. Mantha, and G. C. Fox, “A tale of two
data-intensive paradigms: Applications, abstractions, and architectures,”
in Proceedings of the 3rd International Congress on Big Data, 2014.
[4] J. Qiu, S. Jha, A. Luckow, and G. C. Fox, “Towards hpc-abds: An initial
high-performance big data stack,” Building Robust Big Data Ecosystem
ISO/IEC JTC 1 Study Group on Big Data, pp. 18–21, 2014.
[5] M. W. ur Rahman, N. S. Islam, X. Lu, J. Jose, H. Subramoni, H. Wang,
and D. K. D. Panda, “High-performance rdma-based design of hadoop
mapreduce over inﬁniband,” in Parallel and Distributed Processing
Symposium Workshops PhD Forum (IPDPSW), 2013 IEEE 27th International, May 2013, pp. 1908–1917.
[6] G. C. Fox, J. Qiu, S. Kamburugamuve, S. Jha, and A. Luckow, “Hpcabds high performance computing enhanced apache big data stack,” in
2015 15th IEEE/ACM International Symposium on Cluster, Cloud and
Grid Computing, May 2015, pp. 1057–1066.
[7] J. Dongarra, H. Meuer, and E. Strohmaier, “Top 500 supercomputers,”
website, November 2013.
[8] J. R. Lange, K. Pedretti, P. Dinda, P. G. Bridges, C. Bae, P. Soltero,
and A. Merritt, “Minimal-overhead virtualization of a large scale supercomputer,” in ACM SIGPLAN Notices, vol. 46, no. 7. ACM, 2011, pp.
169–180.
[9] A. J. Younge, J. P. Walters, S. P. Crago, and G. C. Fox, “Supporting high
performance molecular dynamics in virtualized clusters using iommu,
sr-iov, and gpudirect,” in ACM Virtual Execution Environments (VEE)
2015, in conjunction with ACM ASPLOS, vol. 50, no. 7. ACM, 2015,
pp. 31–38.
[10] N. Chaimov, A. Malony, S. Canon, C. Iancu, K. Z. Ibrahim, and
J. Srinivasan, “Performance evaluation of apache spark on cray xc
systems,” in Cray User Group 2016 (CUG), 2016.
[11] G. M. Amdahl, “Validity of the single processor approach to achieving
large scale computing capabilities,” in Proceedings of the April 18-20,
1967, spring joint computer conference. ACM, 1967, pp. 483–485.
[12] T. Sterling, Beowulf cluster computing with Linux. The MIT Press,
2001.
[13] K. Hwang, J. Dongarra, and G. C. Fox, Distributed and cloud computing: from parallel processing to the internet of things. Morgan
Kaufmann, 2013.
[14] J. Moore, D. Irwin, L. Grit, S. Sprenkle, and J. Chase, “Managing mixeduse clusters with cluster-on-demand,” Duke University Department of
Computer Science Technical Report, 2002.
[15] J. S. Chase, D. E. Irwin, L. E. Grit, J. D. Moore, and S. E. Sprenkle,
“Dynamic virtual clusters in a grid site manager,” in High Performance
Distributed Computing, 2003. Proceedings. 12th IEEE International
Symposium on. IEEE, 2003, pp. 90–100.
[16] K. Keahey, I. Foster, T. Freeman, and X. Zhang, “Virtual workspaces:
Achieving quality of service and quality of life in the grid,” Scientiﬁc
programming, vol. 13, no. 4, pp. 265–275, 2005.
[17] I. Foster, T. Freeman, K. Keahy, D. Scheftner, B. Sotomayer, and
X. Zhang, “Virtual clusters for grid communities,” in Cluster Computing
and the Grid, 2006. CCGRID 06. Sixth IEEE International Symposium
on, vol. 1. IEEE, 2006, pp. 513–520.
[18] T. Bell, B. Bompastor, S. Bukowiec, J. C. Leon, M. Denis, J. van Eldik,
M. F. Lobo, L. F. Alvarez, D. F. Rodriguez, A. Marino et al., “Scaling
the cern openstack cloud,” in Journal of Physics: Conference Series,
vol. 664, no. 2. IOP Publishing, 2015, p. 022003.
[19] R. Brightwell, R. Oldﬁeld, A. B. Maccabe, and D. E. Bernholdt,
“Hobbes: Composition and virtualization as the foundations of an
extreme-scale os/r,” in Proceedings of the 3rd International Workshop
on Runtime and Operating Systems for Supercomputers. ACM, 2013.
[20] J. Lange, K. Pedretti, T. Hudson, P. Dinda, Z. Cui, L. Xia, P. Bridges,
A. Gocke, S. Jaconette, M. Levenhagen et al., “Palacios and kitten: New
high performance operating systems for scalable virtualized and native
supercomputing,” in Parallel & Distributed Processing (IPDPS), 2010
IEEE International Symposium on. IEEE, 2010, pp. 1–12.
[21] S. M. Kelly and R. Brightwell, “Software architecture of the light weight
kernel, catamount,” in Proceedings of the 2005 Cray User Group Annual
Technical Conference. Citeseer, 2005, pp. 16–19.
[22] A. J. Younge, R. Henschel, J. T. Brown, G. von Laszewski, J. Qiu,
and G. C. Fox, “Analysis of Virtualization Technologies for High
Performance Computing Environments,” in Proceedings of the 4th International Conference on Cloud Computing (CLOUD 2011). Washington,
DC: IEEE, July 2011.
[23] K. Keahey, “Chameleon: Building an experimental instrument for computer science as application of cloud computing,” HEPiX at LBNL, Tech.
Rep., Oct 2016.
[24] P. Barham, B. Dragovic, K. Fraser, S. Hand, T. L. Harris, A. Ho,
R. Neugebauer, I. Pratt, and A. Warﬁeld, “Xen and the art of virtualization.” in SOSP, M. L. Scott and L. L. Peterson, Eds. ACM, 2003,
pp. 164–177.
[25] D. Merkel, “Docker: lightweight linux containers for consistent development and deployment,” Linux Journal, vol. 2014, no. 239, p. 2, 2014.
[26] D. M. Jacobsen and R. S. Canon, “Contain this, unleashing docker for
hpc,” Proceedings of the Cray User Group, 2015.
[27] S. Ekanayake, S. Kamburugamuve, and G. Fox, “Spidal: High performance data analytics with java and mpi on large multicore hpc clusters,”
in Proceedings of 24th High Performance Computing Symposium (HPC
2016), 2016.
[28] F. Tian and K. Chen, “Towards optimal resource provisioning for running
mapreduce programs in public clouds,” in Cloud Computing (CLOUD),
2011 IEEE International Conference on. IEEE, 2011, pp. 155–162.
[29] T. Gunarathne, J. Qiu, and D. Gannon, “Towards a collective layer in
the big data stack,” in Cluster, Cloud and Grid Computing (CCGrid),
2014 14th IEEE/ACM International Symposium on. IEEE, 2014, pp.
236–245.
[30] N. S. Islam, M. Rahman, J. Jose, R. Rajachandrasekar, H. Wang,
H. Subramoni, C. Murthy, and D. K. Panda, “High performance rdmabased design of hdfs over inﬁniband,” in Proceedings of the International
Conference on High Performance Computing, Networking, Storage and
Analysis. IEEE Computer Society Press, 2012, p. 35.
[31] S. K. andKarthik Ramasamy, M. Swany, and G. Fox, “Low latency
stream processing: Twitter heron with inﬁniband and omni-path,” Indiana University Bloomington, Tech. Rep., 2017.
[32] L. Kaplan, “Cray cnl,” FastOS PI Meeting & Workshop, Tech.
Rep. [Online]. Available: http://www.cs.unm.edu/fastos/07meeting/CNL
FASTOS.pdf
[33] K. S. Hemmert, M. W. Glass, S. D. Hammond, R. Hoekstra, M. Rajan,
S. Dawson, M. Vigil, D. Grunau, J. Lujan, D. Morton et al., “Trinity:
Architecture and early experience,” in Cray Users Group, 2016.
[34] B. Geroﬁ, M. Takagi, A. Hori, G. Nakamura, T. Shirasawa, and
Y. Ishikawa, “On the scalability, performance isolation and device driver
transparency of the ihk/mckernel hybrid lightweight kernel,” in Parallel and Distributed Processing Symposium, 2016 IEEE International.
IEEE, 2016, pp. 1041–1050.
[35] R. W. Wisniewski, T. Inglett, P. Keppel, R. Murty, and R. Riesen, “mos:
An architecture for extreme-scale operating systems,” in Proceedings of
the 4th International Workshop on Runtime and Operating Systems for
Supercomputers. ACM, 2014, p. 2.
[36] O. Sefraoui, M. Aissaoui, and M. Eleuldj, “Openstack: toward an opensource solution for cloud computing,” International Journal of Computer
Applications, vol. 55, no. 3, 2012.
[37] R. Bhargava, B. Serebrin, F. Spadini, and S. Manne, “Accelerating twodimensional page walks for virtualized systems,” in ACM SIGARCH
Computer Architecture News, vol. 36, no. 1. ACM, 2008, pp. 26–35.
[38] R. Russell, “virtio: towards a de-facto standard for virtual i/o devices,”
ACM SIGOPS Operating Systems Review, vol. 42, no. 5, pp. 95–103,
2008.
[39] M. Musleh, V. Pai, J. P. Walters, A. J. Younge, and S. P. Crago,
“Bridging the Virtualization Performance Gap for HPC using SR-IOV
for InﬁniBand,” in Proceedings of the 7th IEEE International Conference
on Cloud Computing (CLOUD 2014). Anchorage, AK: IEEE, 2014.
[40] A. Tirumala, F. Qin, J. Dugan, J. Ferguson, and K. Gibbs, “Iperf:
The tcp/udp bandwidth measurement tool,” Webpage, 2005. [Online].
Available: http://iperf. sourceforge. net
[41] P. R. Luszczek, D. H. Bailey, J. J. Dongarra, J. Kepner, R. F. Lucas, R. Rabenseifner, and D. Takahashi, “The hpc challenge (hpcc)
benchmark suite,” in Proceedings of the 2006 ACM/IEEE conference
on Supercomputing. Citeseer, 2006, p. 213.
[42] J. Dongarra, M. A. Heroux, and P. Luszczek, “Hpcg benchmark: A new
metric for ranking high performance computing systems,” Knoxville,
Tennessee, 2015.
[43] M. Zaharia, M. Chowdhury, T. Das, A. Dave, J. Ma, M. McCauley,
M. J. Franklin, S. Shenker, and I. Stoica, “Resilient distributed datasets:
A fault-tolerant abstraction for in-memory cluster computing,” in Proceedings of the 9th USENIX conference on Networked Systems Design
and Implementation. USENIX Association, 2012, pp. 2–2.
[44] O. OMalley, “Terabyte sort on apache hadoop,” Yahoo, available online
at: http://sortbenchmark. org/Yahoo-Hadoop. pdf,(May), pp. 1–3, 2008.
[45] K. Antypas, N. Wright, N. P. Cardo, A. Andrews, and M. Cordery, “Cori:
a cray xc pre-exascale system for nersc,” Cray User Group Proceedings.
Cray, 2014.
[46] P. W. et al., “Spark-perf: Performance tests for spark,” Webpage, 2016.
[Online]. Available: https://github.com/databricks/spark-perf
[47] X. Meng, J. Bradley, B. Yavuz, E. Sparks, S. Venkataraman, D. Liu,
J. Freeman, D. Tsai, M. Amde, S. Owen et al., “Mllib: Machine learning
in apache spark,” Journal of Machine Learning Research, vol. 17, no. 34,
pp. 1–7, 2016.
[48] J. Jose, M. Li, X. Lu, K. C. Kandalla, M. D. Arnold, and D. K.
Panda, “Sr-iov support for virtualization on inﬁniband clusters: Early
experience,” in Cluster, Cloud and Grid Computing (CCGrid), 2013 13th
IEEE/ACM International Symposium on. IEEE, 2013, pp. 385–392.
[49] T. Hey, S. Tansley, K. M. Tolle et al., The fourth paradigm: dataintensive scientiﬁc discovery. Microsoft research Redmond, WA, 2009,
vol. 1.