[1] InfiniBand Trade Association, http://www.infinibandta.com.

[2] M. Luo, M. Li, A. Venkatesh, X. Lu, and D. K. Panda, “Upc on mic:
Early experiences with native and symmetric modes,” in Proceedings of
the 7th International Conference on Partitioned Global Address Space
Programming Models, ser. PGAS 713, 2013.

[3] J. Lin, K. Hamidouche, X. Lu, M. Li, and D. K. Panda, “Highperformance coarray fortran support with mvapich2-x: Initial experience
and evaluation,’ in 20/5 IEEE International Parallel and Distributed
Processing Symposium Workshop, May 2015.

[4] S. Potluri, K. Kandalla, D. Burdeey, M. Li, and D. K. Panda, “Efficient
intranode desgins for openshmem on multicore clusters,” in Proceedings
of the 6th International Conference on Partitioned Global Address
Space Programming Models, ser. PGAS 712, 2012.

[5] M. J. Koop, J. K. Sridhar, and D. K. Panda, “Scalable MPI Design over
InfiniBand using eXtended Reliable Connection,” JEEE Int’! Conference
on Cluster Computing (Cluster 2008), September 2008.

[6] H. Subramoni, K. Hamidouche, A. Venkatesh, S. Chakraborty, and D. K.
Panda, “Designing MPI Library with Dynamic Connected Transport
(DCT) of InfiniBand: Early Experiences,” in International Supercomputing Conference (ISC), 2014.

[7] M. Li, K. Hamidouche, X. Lu, H. Subramoni, J. Zhang, and D. K.
Panda, “Designing MPI Library with On-demand Paging (ODP) of Infiniband: Challenges and Benefits,” in Proceedings of the International
Conference for High Performance Computing, Networking, Storage and
Analysis, ser. SC °16, 2016.

[8] J. Liu, J. Wu, and D. K. Panda, “High Performance RDMA-Based MPI
Implementation over InfiniBand,” in 17th Annual ACM International
Conference on Supercomputing, June 2003.

[9] M. Li, H. Subramoni, K. Hamidouche, X. Lu, and D. K. Panda, “High
Performance MPI Datatype Support with User-Mode Memory Registration: Challenges, Designs, and Benefits,” in 2015 IEEE International
Conference on Cluster Computing, Sept 2015.

[10] H. Tezuka, F. O. Carroll, A. Hori, and Y. Ishikawa, “Pin-down Cache:
A Virtual Memory Management Technique for Zero-copy Communication,” in Proceedings of 12th Int. Parallel Processing Symposium,
March 1998.

[11] M. Li, S. Potluri, K. Hamidouche, J. Jose, and D. K. Panda, “Efficient
and Truly Passive MPI-3 RMA Using InfiniBand Atomics,” in Proceedings of the 20th European MPI Users’ Group Meeting, ser. EuroMPI
°13, 2013.

[12] M. Li, K. Hamidouche, X. Lu, J. Zhang, J. Lin, and D. K. Panda,
“High Performance OpenSHMEM Strided Communication Support
with InfiniBand UMR,” in 2015 IEEE 22nd International Conference
on High Performance Computing (HiPC), Dec 2015.

[13] M. Li, K. Hamidouche, X. Lu, J. Lin, and D. K. D. Panda, HighPerformance and Scalable Design of MPI-3 RMA on Xeon Phi Clusters.
Berlin, Heidelberg: Springer Berlin Heidelberg, 2015.

[14] S. Raindel, H. Eran, L. Liss, and N. Bloch, “Look-ahead Handling of
Page Faults in I/O Operations,” Dec. 16 2014, uS Patent 8,914,458.
[Online]. Available: https://www.google.com/patents/US8914458

[15] N. Bloch, S. Raindel, H. Eran, and L. Liss, “Use of Free Pages in
Handling of Page Faults,” Jun. 3 2014, uS Patent 8,745,276. [Online].
Available: https://www.google.com/patents/US8745276

[16] D. K. Panda, K. Tomko, K. Schulz, and A. Majumdar, “The MVAPICH
Project: Evolution and Sustainability of an Open Source Production
Quality MPI Library for HPC,’ in Int’! Workshop on Sustainable
Software for Science: Practice and Experiences, held in conjunction
with Int’l Conference on Supercomputing (SC ’13), November 2013.

[17] Network Based Computing Laboratory, “OSU Micro-benchmarks,”
http://mvapich.cse.ohio-state.edu/benchmarks/.

[18] R. C. Murphy, K. B. Wheeler, B. W. Barrett, and J. A. Ang, “Introducing
the Graph 500,” Cray User Group, 2010.

[19] M. J. Koop, S. Sur, Q. Gao, and D. K. Panda, “High Performance MPI
Design using Unreliable Datagram for Ultra-scale InfiniBand Clusters,”
in ICS ’07: Proceedings of the 21st annual international conference on
Supercomputing. New York, NY, USA: ACM, 2007, pp. 180-189.

[20] M. J. Rashti, R. E. Grant, A. Afsahi, and P. Balaji, “iWARP Redefined:
Scalable Connectionless Communication over High-speed Ethernet,” in
High Performance Computing (HiPC), 2010 International Conference
on. YEEE, 2010, pp. 1-10.

[21] G. M. Shipman, T. S. Woodall, R. L. Graham, A. B. Maccabe, and
P. G. Bridges, “InfiniBand Scalability in Open MPI,” in Parallel and
Distributed Processing Symposium, 2006. IPDPS 2006. 20th International. YEEE, 2006, pp. 10-pp.

[22] G. M. Shipman, R. Brightwell, B. Barrett, J. M. Squyres, and G. Bloch,
“Investigations on InfiniBand: Efficient Network Buffer Utilization at
Scale,” in Proceedings, Euro PVM/MPI, Paris, France, October 2007.

[23] M. J. Koop, T. Jones, and D. K. Panda, “MVAPICH-Aptus: Scalable
High-performance Multi-transport MPI over InfiniBand,” in JPDPS’08,
2008, pp. 1-12.

[24] B. Erimli, “Arrangement in an InfiniBand Channel Adapter for Sharing
Memory Space for Work Queue Entries using Multiply-linked Lists,”
Mar. 18 2008, uS Patent 7,346,707.

[25] H. J. Marc Perache, Patrick Carribault, “MPC-MPI: An MPI Implementation Reducing the Overall Memory Consumption,” in Proceedings,
Euro PVM/MPI, Helsinki, Finland, October 2009.

[26] B. Alverson, E. Froese, L. Kaplan, and D. Roweth, “Cray XC Series
Network,” Tech. Rep., 2012.

[27] J. Beecroft, M. Homewood, and M. McLaren, “Meiko cs-2 interconnect
elan-elite design,” Parallel Computing, vol. 20, no. 10, pp. 1627 — 1638,
1994.

[28] C. Hong, W. Bao, A. Cohen, S. Krishnamoorthy, L.-N. Pouchet,
F. Rastello, J. Ramanujam, and P. Sadayappan, “Effective padding of
multidimensional arrays to avoid cache conflict misses,” SIGPLAN Not.,
Jun. 2016.

[29] M. Welsh, A. Basu, and T. von Eicken, “Incorporating memory management into user-level network interfaces,” Ithaca, NY, USA, Tech.
Rep., 1997.

[30] F. Petrini, W.-c. Feng, A. Hoisie, S. Coll, and E. Frachtenberg, “The
Quadrics Network: High-Performance Clustering Technology,” [EEE
Micro, vol. 22, no. 1, pp. 46-57, Jan. 2002. [Online]. Available:
http://dx.doi.org/10.1109/40.988689

[31] W. Yu, T. S. Woodall, R. L. Graham, and D. K. Panda, “Design
and Implementation of Open MPI over Quadrics/Elan4,” in Parallel
and Distributed Processing Symposium, 2005. Proceedings. 19th IEEE
International, April 2005, pp. 96a—-96a.

[32] T. S. Woodall, G. M. Shipman, G. Bosilca, R. L. Graham,
and A. B. Maccabe, “High Performance RDMA Protocols in
HPC,” in Proceedings of the 13th European PVM/MPI User’s
Group Conference on Recent Advances in Parallel Virtual Machine
and Message Passing Interface, ser. EuroPVM/MPI’06. — Berlin,
Heidelberg: Springer-Verlag, 2006, pp. 76-85. [Online]. Available:
http://dx.doi.org/10.1007/11846802_18

[33] D. Li, K. W. Cameron, D. S. Nikolopoulos, B. R. d. Supinski, and
M. Schulz, “Scalable Memory Registration for High Performance
Networks Using Helper Threads,” in ACM International Conference on
Computing Frontiers Supercomputing (CF 11), Ischia, Italy, May 2011.

[34] W. Bao, C. Hong, S. Chunduri, S. Krishnamoorthy, L.-N. Pouchet,
EF. Rastello, and P. Sadayappan, “Static and dynamic frequency scaling
on multicore cpus,” ACM Trans. Archit. Code Optim., Dec. 2016.

[35] W. Bao, S. Tavarageri, F. Ozguner, and P. Sadayappan, “Pwcet: Poweraware worst case execution time analysis,” in 2014 43rd International
Conference on Parallel Processing Workshops, Sept 2014, pp. 439-447.

[36] W. Bao, S. Krishnamoorthy, L.-N. Pouchet, F. Rastello, and P. Sadayappan, “Polycheck: Dynamic verification of iteration space transformations on affine programs,” SIGPLAN Not., vol. 51.

[37] J. Zhang and X. Lu and D. K. Panda, “High-Performance Virtual
Machine Migration Framework for MPI Applications on SR-IOV enabled InfiniBand Clusters,’ in 2017 IEEE International Parallel and
Distributed Processing Symposium (IPDPS), Orlando, USA, May 2017.
[38] J. Zhang, X. Lu, J. Jose, M. Li, R. Shi, D. K. Panda, “High Performance
MPI Library over SR-IOV Enabled InfiniBand Clusters,” in Proceedings
of International Conference on High Performance Computing (HiPC),
Goa, India, December 17-20 2014.

[39] J. Zhang and X. Lu and D. K. Panda, “ High Performance MPI
Library for Container-based HPC Cloud on InfiniBand Clusters ,” in
The 45th International Conference on Parallel Processing (ICPP ’16),
Philadelphia, USA, August 2016.

[40] M. Li, X. Lu, K. Hamidouche, J. Zhang, and D. K. Panda, ““Mizan-rma:
Accelerating mizan graph processing framework with mpi rma,” in 2016
IEEE 23rd International Conference on High Performance Computing
(HiPC), Dec 2016, pp. 42-51.

[41] M. Li, X. Lu, S. Potluri, K. Hamidouche, J. Jose, K. Tomko, and
D. K. Panda, “Scalable Graph500 design with MPI-3 RMA,” in 2014
IEEE International Conference on Cluster Computing (CLUSTER), Sept
2014.

[42] M. Li, J. Lin, X. Lu, K. Hamidouche, K. Tomko, and D. K. Panda,
“Scalable MiniMD Design with Hybrid MPI and OpenSHMEM,” in
Proceedings of the 8th International Conference on Partitioned Global
Address Space Programming Models, ser. PGAS 14, 2014.