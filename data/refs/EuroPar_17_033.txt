[1] Barrett, B., Squyres, J.M., Lumsdaine, A., Graham, R.L., Bosilca, G.: Analysis of the component architecture overhead in open MPI. In: Martino, B., Kranzlmüller, D., Dongarra, J. (eds.) EuroPVM/MPI 2005. LNCS, vol. 3666, pp. 175–

182. Springer, Heidelberg (2005). doi:10.1007/11557265 25

[2] Barrett, R.F., Vaughan, C.T., Heroux, M.A.: MiniGhost: a miniapp for exploring

boundary exchange strategies using stencil computations in scientiﬁc parallel computing. Sandia National Laboratories, Technical report SAND2011-5294832 (2011)

[3] Bosilca, G., Foyer, C., Jeannot, E., Mercier, G., Papauré, G.: Online dynamic

monitoring of MPI communications: scientiﬁc user and developper guide. Research

Report RR-9038, Inria Bordeaux Sud-Ouest, March 2017. https://hal.inria.fr/

hal-01485243

[4] Broquedis, F., Clet-Ortega, J., Moreaud, S., Furmento, N., Goglin, B., Mercier,

G., Thibault, S., Namyst, R.: hwloc: a generic framework for managing hardware

aﬃnities in HPC applications. In: 2010 18th Euromicro International Conference

on Parallel, Distributed and Network-Based Processing (PDP), pp. 180–186. IEEE

(2010)

[5] Brown, K.A., Domke, J., Matsuoka, S.: Tracing data movements within MPI

collectives. In: Proceedings of the 21st European MPI Users’ Group Meeting,

EuroMPI/ASIA 2014, pp. 117:117–117:118. ACM, New York (2014). http://doi.

acm.org/10.1145/2642769.2642789

[6] Cores, I., Gonzalez, P., Jeannot, E., Martı́n, M., Rodriguez, G.: An application-level

solution for the dynamic reconﬁguration of MPI applications. In: 12th International

Meeting on High Performance Computing for Computational Science (VECPAR

2016), Porto, Portugal, June 2016 (to appear)

[7] Forum, M.P.I.: MPI: A Message-Passing Interface Standard. http://www.

mpi-forum.org/

[8] Gabriel, E., et al.: Open MPI: goals, concept, and design of a next generation MPI implementation. In: Kranzlmüller, D., Kacsuk, P., Dongarra, J. (eds.)

EuroPVM/MPI 2004. LNCS, vol. 3241, pp. 97–104. Springer, Heidelberg (2004).

doi:10.1007/978-3-540-30218-6 19

[9] Hoeﬂer, T., Jeannot, E., Mercier, G.: An overview of topology mapping algorithms

and techniques in high-performance computing. In: High-Performance Computing

on Complex Environments, pp. 73–94 (2014)

[10]  Janssen, C.L., Adalsteinsson, H., Cranford, S., Kenny, J.P., Pinar, A., Evensky,

D.A., Mayo, J.: A simulator for large-scale parallel computer architectures. In:

Technology Integration Advancements in Distributed Systems and Computing, p.

179 (2012)

[11]  Jeannot, E., Mercier, G., Tessier, F.: Process placement in multicore clusters: algorithmic issues and practical techniques. IEEE Trans. Parallel Distrib. Syst. 25(4),

993–1002 (2014)

[12]  Keller, R., Bosilca, G., Fagg, G., Resch, M., Dongarra, J.J.: Implementation and

usage of the PERUSE-interface in open MPI. In: Mohr, B., Träﬀ, J.L., Worringen, J., Dongarra, J. (eds.) EuroPVM/MPI 2006. LNCS, vol. 4192, pp. 347–355.

Springer, Heidelberg (2006). doi:10.1007/11846802 48

[13]  Knüpfer, A., et al.: Score-P: a joint performance measurement run-time infrastructure for Periscope, Scalasca, TAU, and Vampir. In: Brunst, H., Müller, M., Nagel,

W., Resch, M. (eds.) Tools for High Performance Computing 2011, pp. 79–91.

Springer, Heidelberg (2012). doi:10.1007/978-3-642-31476-6 7

[14]  Open MPI development repository. https://github.com/open-mpi/ompi

[15]  Vetter, J.S., McCracken, M.O.: Statistical scalability analysis of communication

operations in distributed applications. In: ACM SIGPLAN Notices, vol. 36, pp.

123–132. ACM (2001)
