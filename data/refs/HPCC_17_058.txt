[1] Parboil Benchmark Suite. http://impact.crhc.illinois.edu/parboil.php.
[2] CUDA Programming Guide, Version 3.0. NVIDIA, 2010.
[3] J. Cavazos, G. Fursin, F. Agakov, E. Bonilla, M. F. P. O’Boyle, and
O. Temam. Rapidly Selecting Good Compiler Optimizations using
Performance Counters. In Proc. of the International Symposium on
Code Generation and Optimization (CGO ’07), Washington, DC, USA,
2007.
[4] R. Cochran, C. Hankendi, A. K. Coskun, and S. Reda. Pack & cap:
adaptive dvfs and thread packing under power caps. In Proc. of the
44th annual IEEE/ACM international symposium on microarchitecture,
2011.

[5] M. Curtis-Maury, A. Shah, F. Blagojevic, D. S. Nikolopoulos, B. R.
De Supinski, and M. Schulz. Prediction models for multi-dimensional
power-performance optimization on many cores. In Proc. of the
17th international conference on Parallel architectures and compilation
techniques, 2008.
[6] J. Demme and S. Sethumadhavan. Approximate graph clustering for
program characterization. ACM Transactions on Architecture and Code
Optimization (TACO), 8(4), 2012.
[7] M. K. Emani and M. F. P. O’Boyle. Celebrating diversity: a mixture
of experts approach for runtime mapping in dynamic environments. In
Proc. of the 36th ACM SIGPLAN Conference on Programming Language
Design and Implementation, Portland, OR, USA, 2015.
[8] G. Fursin, Y. Kashnikov, A. W. Memon, Z. Chamski, O. Temam,
M. Namolaru, E. Yom-Tov, B. Mendelson, A. Zaks, E. Courtois,
F. Bodin, P. Barnard, E. Ashton, E. Bonilla, J. Thomson, C. Williams,
and M. O’Boyle. Milepost GCC: Machine Learning Enabled SelfTuning Compiler. International Journal of Parallel Programming, 39,
2011.
[9] R. Gupta, I. Laguna, D. Ahn, T. Gamblin, S. Bagchi, and F. Lin.
Statuner: Efﬁcient tuning of cuda kernels parameters. In Supercomputing
Conference (SC 2015), poster, Nov 2015.
[10] N. Jain, A. Bhatele, M. P. Robson, T. Gamblin, and L. V. Kale.
Predicting application performance using supervised learning on communication features. In Proc. of the International Conference on High
Performance Computing, Networking, Storage and Analysis.
[11] S. Jayasena, S. Amarasinghe, A. Abeyweera, G. Amarasinghe,
H. De Silva, S. Rathnayake, X. Meng, and Y. Liu. Detection of false
sharing using machine learning. In Proc. of the International Conference
on High Performance Computing, Networking, Storage and Analysis,
2013.
[12] Y. Kashnikov, J. C. Beyler, and W. Jalby. Compiler optimizations:
Machine learning versus O3. In Languages and Compilers for Parallel
Computing, 25th International Workshop, LCPC 2012, Tokyo, Japan,
2012, Revised Selected Papers, 2012.
[13] S.-w. Liao, T.-H. Hung, D. Nguyen, C. Chou, C. Tu, and H. Zhou.
Machine Learning-Based Prefetch Optimization for Data Center Applications. In Proc. of the Conference on High Performance Computing
Networking, Storage and Analysis, 2009.
[14] A. Magni, C. Dubach, and M. F. P. O’Boyle. A large-scale crossarchitecture evaluation of thread-coarsening. In Proc. of the 2013
ACM/IEEE conf. on Supercomputing, 2013.
[15] A. Magni, D. Grewe, and N. Johnson. Input-aware auto-tuning for
directive-based gpu programming. In Proc. of the 6th Workshop on
General Purpose Processor Using Graphics Processing Units, 2013.
[16] C. McCurdy, G. Marin, and J. S. Vetter. Characterizing the impact of
prefetching on scientiﬁc application performance. In High Performance
Computing Systems. Performance Modeling, Benchmarking and Simulation. Springer, 2013.
[17] T. M. Mitchell. Machine Learning. McGraw-Hill, Inc., New York, NY,
USA, 1 edition, 1997.
[18] L. Nardi, B. Bodin, M. Z. Zia, J. Mawer, A. Nisbet, P. H. J. Kelly,
A. J. Davison, M. Luján, M. F. P. O’Boyle, G. Riley, N. Topham,
and S. Furber. Introducing SLAMBench, a performance and accuracy
benchmarking methodology for SLAM. In IEEE Intl. Conf. on Robotics
and Automation (ICRA), May 2015.
[19] S. Rahman, M. Burtscher, Z. Zong, and A. Qasem. Maximizing
hardware prefetch effectiveness with machine learning. In 17th IEEE
International Conference on High Performance Computing and Communications (HPCC15), Aug 2015.
[20] S. Seo, J. Lee, G. Jo, and J. Lee. Automatic opencl work-group
size selection for multicore cpus. In Proc. of the 22Nd International
Conference on Parallel Architectures and Compilation Techniques, 2013.
[21] N. P. Tran and M. Lee. Parameter tuning model for optimizing
application performance on gpu. In 2016 IEEE 1st International
Workshops on Foundations and Applications of Self* Systems (FAS*W),
Sept 2016.
[22] V. Volkov. Better performance at lower occupancy. 2010.
[23] R. Vuduc, J. Demmel, and J. Bilmes. Statistical Models for Empirical
Search-Based Performance Tuning. International Journal of High
Performance Computing Applications, 18(1), 2004.
[24] G. Wu, J. L. Greathouse, A. Lyashevsky, N. Jayasena, and D. Chiou.
Gpgpu performance and power estimation using machine learning.
In 2015 IEEE 21st International Symposium on High Performance
Computer Architecture (HPCA), Feb 2015.
