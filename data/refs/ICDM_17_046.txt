[1] R. He and J. McAuley, “VBPR: visual bayesian personalized ranking
from implicit feedback,” in AAAI, 2016.
[2] Y. Jia, E. Shelhamer, J. Donahue, S. Karayev, J. Long, R. B. Girshick,
S. Guadarrama, and T. Darrell, “Caffe: Convolutional architecture for
fast feature embedding,” in MM, 2014.
[3] R. He and J. McAuley, “Ups and downs: Modeling the visual evolution
of fashion trends with one-class collaborative filtering,” in WWW, 2016.
[4] R. He, C. Fang, Z. Wang, and J. McAuley, “Vista: A visually, socially,
and temporally-aware model for artistic recommendation,” in RecSys,
2016.
[5] A. Veit, B. Kovacs, S. Bell, J. McAuley, K. Bala, and S. Belongie, “Learning visual clothing style with heterogeneous dyadic cooccurrences,” in ICCV, 2015.
[6] H. Wang, N. Wang, and D.-Y. Yeung, “Collaborative deep learning for
recommender systems,” in SIGKDD, 2015.
[7] C. Lei, D. Liu, W. Li, Z.-J. Zha, and H. Li, “Comparative deep learning
of hybrid representations for image recommendations,” in CVPR, 2016.
[8] S. Rendle, C. Freudenthaler, Z. Gantner, and L. Schmidt-Thieme, “BPR:
bayesian personalized ranking from implicit feedback,” in UAI, 2009.
[9] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley,
S. Ozair, A. Courville, and Y. Bengio, “Generative adversarial nets,” in
NIPS, 2014.
[10] R. Hadsell, S. Chopra, and Y. LeCun, “Dimensionality reduction by
learning an invariant mapping,” in CVPR, 2006.
[11] A. Nguyen, A. Dosovitskiy, J. Yosinski, T. Brox, and J. Clune, “Synthesizing the preferred inputs for neurons in neural networks via deep
generator networks,” in NIPS, 2016.

[12] J. McAuley, C. Targett, Q. Shi, and A. van den Hengel, “Image-based
recommendations on style and substitutes,” in SIGIR, 2015.
[13] Y. Hu, Y. Koren, and C. Volinsky, “Collaborative filtering for implicit
feedback datasets,” in ICDM, 2008.
[14] R. Pan, Y. Zhou, B. Cao, N. N. Liu, R. Lukose, M. Scholz, and Q. Yang,
“One-class collaborative filtering,” in ICDM, 2008.
[15] J. Yang, C. Liu, M. Teng, H. Xiong, M. Liao, and V. Zhu, “Exploiting
temporal and social factors for B2B marketing campaign recommendations,” in ICDM, 2015.
[16] D. Lian, Y. Ge, F. Zhang, N. J. Yuan, X. Xie, T. Zhou, and Y. Rui,
“Content-aware collaborative filtering for location recommendation
based on human mobility data,” in ICDM, 2015.
[17] Z. Yao, Y. Fu, B. Liu, Y. Liu, and H. Xiong, “POI recommendation:
A temporal matching between POI popularity and user regularity,” in
ICDM, 2016.
[18] P. Covington, J. Adams, and E. Sargin, “Deep neural networks for
youtube recommendations,” in RecSys, 2016.
[19] S. Wang, Y. Wang, J. Tang, K. Shu, S. Ranganath, and H. Liu, “What
your images reveal: Exploiting visual contents for point-of-interest
recommendation,” in WWW, 2017.
[20] Y. Li, L. Cao, J. Zhu, and J. Luo, “Mining fashion outfit composition
using an end-to-end deep learning approach on set data,” TMM, 2017.
[21] X. Han, Z. Wu, Y. Jiang, and L. S. Davis, “Learning fashion compatibility with bidirectional lstms,” in MM, 2017.
[22] Z. Al-Halah, R. Stiefelhagen, and K. Grauman, “Fashion forward:
Forecasting visual style in fashion,” in ICCV, 2017.
[23] L. Bossard, M. Dantone, C. Leistner, C. Wengert, T. Quack, and
L. Van Gool, “Apparel classification with style,” in ACCV, 2013.
[24] A. C. Murillo, I. S. Kwak, L. Bourdev, D. Kriegman, and S. Belongie,
“Urban tribes: Analyzing group photos from a social perspective,” in
Computer Vision and Pattern Recognition Workshops (CVPRW), 2012.
[25] S. Vittayakorn, K. Yamaguchi, A. C. Berg, and T. L. Berg, “Runway to
realway: Visual analysis of fashion,” in WACV, 2015.
[26] A. Krizhevsky, I. Sutskever, and G. E. Hinton, “Imagenet classification
with deep convolutional neural networks,” in NIPS, 2012.
[27] J. Hu, J. Lu, and Y.-P. Tan, “Discriminative deep metric learning for
face verification in the wild,” in CVPR, 2014.
[28] S. Bell and K. Bala, “Learning visual similarity for product design with
convolutional neural networks,” in TOG, 2015.
[29] A. Veit, B. Kovacs, S. Bell, J. McAuley, K. Bala, and S. Belongie, “Learning visual clothing style with heterogeneous dyadic cooccurrences,” in ICCV, 2015.
[30] M. Mirza and S. Osindero, “Conditional generative adversarial nets,”
arXiv preprint arXiv:1411.1784, 2014.
[31] Y. Koren and R. Bell, “Advances in collaborative filtering,” in Recommender Systems Handbook. Springer, 2011.
[32] K. Chatfield, K. Simonyan, A. Vedaldi, and A. Zisserman, “Return of
the devil in the details: Delving deep into convolutional nets,” in BMVC,
2014.
[33] K. He, X. Zhang, S. Ren, and J. Sun, “Deep residual learning for image
recognition,” in CVPR, 2016.
[34] D. P. Kingma and J. Ba, “Adam: A method for stochastic optimization,”
in ICLR, 2015.
[35] A. Radford, L. Metz, and S. Chintala, “Unsupervised representation
learning with deep convolutional generative adversarial networks,” arXiv
preprint arXiv:1511.06434, 2015.
[36] A. Odena, C. Olah, and J. Shlens, “Conditional image synthesis with
auxiliary classifier gans,” in ICML, 2017.
[37] S. Reed, Z. Akata, X. Yan, L. Logeswaran, B. Schiele, and H. Lee,
“Generative adversarial text to image synthesis,” in ICML, 2016.
[38] X. Mao, Q. Li, H. Xie, R. Y. Lau, Z. Wang, and S. P. Smolley, “Least squares generative adversarial networks,” arXiv preprint
ArXiv:1611.04076, 2016.
[39] T. Salimans, I. J. Goodfellow, W. Zaremba, V. Cheung, A. Radford, and
X. Chen, “Improved techniques for training gans,” in NIPS, 2016.
[40] Z. Wang, A. C. Bovik, H. R. Sheikh, and E. P. Simoncelli, “Image
quality assessment: from error visibility to structural similarity,” TIP,
2004.
[41] J. Weston, S. Bengio, and N. Usunier, “Wsabie: Scaling up to large
vocabulary image annotation,” in IJCAI, 2011.
[42] S. Rendle, “Factorization machines,” in ICDM, 2010.
[43] M. Kula, “Metadata embeddings for user and item cold-start recommendations,” arXiv preprint arXiv:1507.08439, 2015.
