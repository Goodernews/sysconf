[1] ]R. Lucas et al., “Top ten exascale challenges,’ DOE
ASCAC Subcommittee Report, 2014.

[2] J. Bennett, H. Abbasi, P. T. Bremer, R. Grout, A. Gyulassy, T. Jin, S. Klasky, H. Kolla, M. Parashar, V. Pascucci, P. Pebay, D. Thompson, H. Yu, F. Zhang, and
J. Chen, “Combining in-situ and in-transit processing to
enable extreme-scale scientific analysis,” in 2012 International Conference for High Performance Computing,
Networking, Storage and Analysis (SC), 2012.

[3] C. Docan, M. Parashar, J. Cummings, and S. Klasky,
“Moving the code to the data - dynamic code deployment
using ActiveSpaces,” in 201] IEEE International Parallel
Distributed Processing Symposium (IPDPS), 2011.

[4] F. Zhang, M. Parashar, J. Cummings, and S. Klasky, “Enabling in-situ execution of coupled scientific workflow on
multi-core platform,” in 201] IEEE International Parallel
Distributed Processing Symposium (IPDPS), 2012.

[5] F. Zheng, H. Abbasi, C. Docan, J. Lofstead, Q. Liu,
S. Klasky, M. Parashar, N. Podhorszki, K. Schwan, and
M. Wolf, “PreDatA: preparatory data analytics on petascale machines,” in 2010 IEEE International Symposium
on Parallel Distributed Processing (IPDPS), 2010.
[6] Intel, “The Intel Xeon Phi product
family,” 2013. [Online]. Available:
http://www. intel.com/content/www/us/en/highperformance-computing/high-performance-xeon-phicoprocessor-brief.html

[7] M. Mattina, “The architecture and performance of
the TILE-Gx processor family.” [Online]. Available: — http://www.tilera.com/products/processors/TILEGx_Family

[8] D. Hackenberg, D. Molka, and W. E. Nagel, “Comparing
cache architectures and coherency protocols on x86-64
multicore SMP systems,” in Proceedings of the 42Nd
Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), 2009.

[9] G. Kestor, R. Gioiosa, D. J. Kerbyson, and A. Hoisie,
“Quantifying the energy cost of data movement in scientific applications,” in 20/3 IEEE International Symposium on Workload Characterization (IISWC), 2013.

[10] K. Hsieh, E. Ebrahim, G. Kim, N. Chatterjee,
M. O’Connor, N. Vijaykumar, O. Mutlu, and S. W.
Keckler, “Transparent offloading and mapping (TOM):
Enabling programmer-transparent near-data processing in
gpu systems,” in 2016 ACM/IEEE 43rd Annual International Symposium on Computer Architecture (ISCA),
2016.

[11] S. Pugsley, J. Jestes, H. Zhang, R. Balasubramonian,
V. Srinivasan, A. Buyuktosunoglu, A. Davis, and F. Li,
“NDC: Analyzing the impact of 3D-stacked memory+logic devices on mapreduce workloads,” in 20/4
IEEE International Symposium on Performance Analysis
of Systems and Software (ISPASS), 2014.

[12] A. Farmahini-Farahani, J. H. Ahn, K. Morrow, and

[13] N. S. Kim, “NDA: Near-DRAM acceleration architecture leveraging commodity DRAM devices and standard
memory modules,” in 20/5 IEEE 2Ist International
Symposium on High Performance Computer Architecture
(HPCA), 2015.

[14] J. B. Kotra, M. Arjomand, D. Guttman, M. T. Kandemir,
and C. R. Das, “Re-NUCA: A practical nuca architecture
for reram based last-level caches,” in 20/6 IEEE International Parallel and Distributed Processing Symposium
(IPDPS), 2016.

[15] P. Yedlapalli, J. Kotra, E. Kultursay, M. Kandemir,
C. R. Das, and A. Sivasubramaniam, “Meeting midway: Improving cmp performance with memory-side
prefetching,” in Proceedings of the 22nd International
Conference on Parallel Architectures and Compilation
Techniques (PACT), 2013.

[16] W. Ding, X. Tang, M. Kandemir, Y. Zhang, and E. Kultursay, “Optimizing off-chip accesses in multicores,” in
Proceedings of the 36th ACM SIGPLAN Conference
on Programming Language Design and Implementation
(PLDI), 2015.

[17] M. Kandemir, H. Zhao, X. Tang, and M. Karakoy,
“Memory row reuse distance and its role in optimizing
application performance,” in Proceedings of the 2015
ACM SIGMETRICS International Conference on Measurement and Modeling of Computer Systems (SIGMETRICS), 2015.

[18] K. Swaminathan, J. Kotra, H. Liu, J. Sampson, M. Kandemir, and V. Narayanan, “Thermal-aware application
scheduling on device-heterogeneous embedded architectures,’ in 2015 28th International Conference on VLSI
Design, 2015.

[19] J. D. Booth, J. B. Kotra, H. Zhao, M. Kandemir, and
P. Raghavan, “Phase detection with hidden markov models for dvfs on many-core processors,” in 20/5 [EEE
35th International Conference on Distributed Computing
Systems (ICDCS), 2015.

[20] O. Kislal, J. Kotra, X. Tang, M. Kandemir, and
M. Jung, “Location-aware computation mapping for
manycore processors.” in The 26th International Conference on Parallel Architectures and Compilation Techniques (PACT), 2017.

[21] J. Liu, J. Kotra, W. Ding, and M. Kandemir, “Network
footprint reduction through data access and computation
placement in noc-based manycores,” in Proceedings of
the 52nd Annual Design Automation Conference (DAC),
2015.

[22] O. Kislal, , M. T. Kandemir, and J. Kotra, “Cacheaware approximate computing for decision tree learning,”
in 2016 IEEE International Parallel and Distributed
Processing Symposium Workshops (IPDPSW), 2016.

[23] C. Kim et al., “An adaptive, non-uniform cache structure
for wire-delay dominated on-chip caches,” in Proc. of
ASPLOS, 2002.

[24] X. Tang, M. Kandemir, P. Yedlapalli, and J. Kotra,
“Improving bank-level parallelism for irregular applications,’ in 2016 49th Annual IEEE/ACM International
Symposium on Microarchitecture (MICRO), 2016.

[25] J. B. Kotra, N. Shahidi, Z. A. Chishti, and M. T. Kandemir, “Hardware-software co-design to mitigate dram
refresh overheads: A case for refresh-aware process
scheduling,” in Proceedings of the Twenty-Second International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS),
2017.

[26] S. Rixner, W. J. Dally, U. J. Kapasi, P. Mattson, and J. D.
Owens, “Memory access scheduling,” in Proceedings of
the 27th Annual International Symposium on Computer
Architecture (ISCA), 2000.

[27] A. Kumar, L.-S. Peh, P. Kundu, and N. K. Jha, “Express virtual channels: Towards the ideal interconnection
fabric,” in Proceedings of the 34th Annual International
Symposium on Computer Architecture (ISCA), 2007.

[28] S. K. Venkata, I. Ahn, D. Jeon, A. Gupta, C. Louie,
S. Garcia, S. Belongie, and M. B. Taylor, “SD-VBS:
The San Diego vision benchmark suite,” in 2009 IEEE
International Symposium on Workload Characterization
(IISWC), 2009.

[29] C. Bienia, “Benchmarking modern multiprocessors,”
Ph.D. dissertation, Princeton University, January 2011.
[30] J. A. Stratton et al., “Impact —_technical report,” 2012. [Online]. Available:
http://impact.crhc.illinois.edu/Parboil/parboil.aspx

[31] “The scalable heterogeneous computing benchmark suite.” [Online]. Available:
https://github.com/vetter/shoc-mic

[32] M. A. Heroux ef al., “Improving performance
via mini-applications,’ 2009. [Online]. Available:
https://mantevo.org/

[33] “SPEC CPU 2006.” [Online]. Available:

http://www.spec.org/cpu2006

[34] T. E. Carlson ef al., “Sniper: Exploring the level of
abstraction for scalable and accurate parallel multi-core
simulations,” in Proc. of SC, 2011.

[35] H. S. Stone, “A logic-in-memory computer,” IEEE Trans.
Comput., 1970.

[36] J. Draper, , J. Chame, M. Hall, C. Steele, T. Barrett,
J. LaCoss, J. Granacki, J. Shin, C. Chen, C. W. Kang,
I. Kim, and G. Daglikoca, “The architecture of the
diva processing-in-memory chip,” in Proceedings of the
16th International Conference on Supercomputing (ICS),
2002.

[37] A. De, M. Gokhale, R. Gupta, and S. Swanson, “Minerva:
Accelerating data analysis in next-generation SSDs,” in
Proceedings of the 2013 IEEE 21st Annual International
Symposium on Field-Programmable Custom Computing
Machines (FCCM), 2013.

[38] S. H. Pugsley, J. Jestes, H. Zhang, R. Balasubramonian,
V. Srinivasan, A. Buyuktosunoglu, A. Davis, and F. Li,
“Comparing implementations of near-data computing
with in-memory mapreduce workloads.” in JEEE Micro,
2014.

[39] M. Gao, J. Pu, X. Yang, M. Horowitz, and C. Kozyrakis,
“Tetris: Scalable and efficient neural network acceleration with 3d memory,” in Proceedings of the TwentySecond International Conference on Architectural Support for Programming Languages and Operating Systems
(ASPLOS), 2017.

[40] P. Chi, S. Li, C. Xu, T. Zhang, J. Zhao, Y. Liu, Y. Wang,
and Y. Xie, “Prime: A novel processing-in-memory architecture for neural network computation in reram-based
main memory,” in 2016 ACMJEEE 43rd Annual International Symposium on Computer Architecture (ISCA),
2016.