[1] Anzt, H., Tomov, S., Dongarra, J.: Implementing a sparse matrix vector product

for the SELL-C/SELL-C-σ formats on NVIDIA GPUs. Technical report, ut-eecs14-727, University of Tennessee (2014)

[2] Buluç, A., Fineman, J.T., Frigo, M., Gilbert, J.R., Leiserson, C.E.: Parallel sparse

matrix-vector and matrix-transpose-vector multiplication using compressed sparse

blocks. In: Proceedings of the 21st Annual Symposium on Parallelism in Algorithms

and Architectures, SPAA 2009, pp. 233–244. ACM (2009)

[3] Buono, D., Gunnels, J.A., Que, X., Checconi, F., Petrini, F., Tuan, T.C., Long, C.:

Optimizing sparse linear algebra for large-scale graph analytics. Computer 48(8),

26–34 (2015)

[4] Davis, T.A.: Direct Methods for Sparse Linear Systems. SIAM, Philadelphia (2006)

[5] Kreutzer, M., Hager, G., Wellein, G., Fehske, H., Bishop, A.R.: A uniﬁed sparse

matrix data format for eﬃcient general sparse matrix-vector multiplication on modern processors with wide SIMD units. SIAM J. Sci. Comput. 36(5), C401–C423

(2014)

[6] Langville, A.N., Meyer, C.D.: Google’s PageRank and Beyond: The Science of

Search Engine Rankings. Princeton University Press, Princeton (2011)

[7] Liu, W., Vinter, B.: CSR5: an eﬃcient storage format for cross-platform sparse

matrix-vector multiplication. In: Proceedings of the 29th ACM on International

Conference on Supercomputing, pp. 339–350. ACM (2015)

[8] Nathan, B., Michael, G.: Eﬃcient sparse matrix-vector multiplication on CUDA.

Technical report, NVIDIA Technical Report NVR-2008-004 (2008)

[9] NVIDIA. cuSPARSE library (2017). http://docs.nvidia.com/cuda/cusparse/

[10]  Saad, Y.: Iterative Methods for Sparse Linear Systems. SIAM, Philadelphia (2003)

[11]  Vázquez, F., Fernández, J.J., Garzón, E.M.: A new approach for sparse matrix

vector product on NVIDIA GPUs. Concur. Comput.: Pract. Exp. 23(8), 815–826

(2011)

[12]  Yan, S., Li, C., Zhang, Y., Zhou, H.: yaSpMV: yet another SPMV framework on

GPUs. In: ACM SIGPLAN Notices, vol. 49, pp. 107–118. ACM (2014)
