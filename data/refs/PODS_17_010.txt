[1] SAS Report on Analytics. sas.com/reg/wp/corp/23876.
[2] M. Anderson, D. Antenucci, V. Bittorf, M. Burgess, M. Cafarella, A. Kumar, F. Niu, Y. Park, C. R ́e, and C. Zhang. Brainwash: A Data System for Feature Engineering. In CIDR, 2013.
[3] M. R. Anderson, M. J. Cafarella, Y. Jiang, G. Wang, and B. Zhang. An integrated development environment for faster feature engineering. PVLDB, 7(13):1657–1660, 2014.
[4] M. Arias and R. Khardon. Complexity parameters for first order classes. Machine Learning, 64(1-3):121–144, 2006.
[5] F. Bacchus, A. J. Grove, J. Y. Halpern, and D. Koller. From statistical knowledge bases to degrees of belief. CoRR, cs.AI/0307056, 2003.
[6] S. H. Bach, M. Broecheler, B. Huang, and L. Getoor. Hinge-loss markov random fields and probabilistic soft logic. CoRR, abs/1505.04406, 2015.
[7] V. Ba ́ra ́ny, B. ten Cate, B. Kimelfeld, D. Olteanu, and Z. Vagena. Declarative probabilistic programming with datalog. In ICDT, volume 48 of LIPIcs, pages 7:1–7:19. Schloss Dagstuhl - Leibniz-Zentrum fuer Informatik, 2016.
[8] P. L. Bartlett and S. Mendelson. Rademacher and gaussian complexities: Risk bounds and structural results. In COLT, pages 224–240, 2001.
[9] Y. Bengio and A. C. Courville. Deep learning of representations. In Handbook on Neural Information Processing, volume 49 of Intelligent Systems Reference Library, pages 1–28. Springer, 2013.
[10] D. E. Boyce. Optimal Subset Selection: Multiple Regression, Interdependence, and Optimal Network Algorithms . Springer-Verlag, 1974.
[11] A. K. Chandra and P. M. Merlin. Optimal implementation of conjunctive queries in relational data bases. In J. E. Hopcroft, E. P. Friedman, and M. A. Harrison, editors, STOC, pages 77–90. ACM, 1977.
[12] C. Chekuri and A. Rajaraman. Conjunctive query containment revisited. Theor. Comput. Sci., 239(2):211–229, 2000.
[13] S. Cohen and Y. Y. Weiss. Learning tree patterns from example graphs. In ICDT, pages 127–143, 2015.
[14] C. Dwork, M. Hardt, T. Pitassi, O. Reingold, and R. S. Zemel. Fairness through awareness. In ITCS, pages 214–226. ACM, 2012.
[15] R. Fagin, J. Y. Halpern, and N. Megiddo. A logic for reasoning about probabilities. Inf. Comput., 87(1/2):78–128, 1990.
[16] R. Fagin, B. Kimelfeld, F. Reiss, and
S. Vansummeren. Spanners: a formal framework for information extraction. In PODS, pages 37–48, 2013.
[17] R. Fagin, B. Kimelfeld, F. Reiss, and S. Vansummeren. Document spanners: A formal approach to information extraction. J. ACM, 62(2):12, 2015.
[18] N. Friedman, L. Getoor, D. Koller, and A. Pfeffer. Learning probabilistic relational models. In IJCAI, pages 1300–1309, 1999.
[19] A. Gammerman, K. S. Azoury, and V. Vapnik.
Learning by transduction. In UAI, pages 148–155.
Morgan Kaufmann, 1998.
[20] I. Guyon and A. Elisseeff. An introduction to variable
and feature selection. Journal of Machine Learning
Research, 3:1157–1182, 2003.
[21] I. Guyon, S. Gunn, M. Nikravesh, and L. A. Zadeh.
Feature Extraction: Foundations and Applications (Studies in Fuzziness and Soft Computing). Springer-Verlag New York, Inc., Secaucus, NJ, USA, 2006.
[22] T. Hastie, R. Tibshirani, and J. Friedman. The Elements of Statistical Learning: Data mining, inference, and prediction. Springer, 2001.
[23] G. H. John, R. Kohavi, and K. Pfleger. Irrelevant features and the subset selection problem. In Machine Learning: Proceedings of the Eleventh International Conference, pages 121–129, 1994.
[24] S. Kandel, A. Paepcke, J. M. Hellerstein, and J. Heer. Enterprise data analysis and visualization: An interview study. IEEE Trans. Vis. Comput. Graph., 18(12):2917–2926, 2012.
[25] B. Kimelfeld and P. G. Kolaitis. The complexity of mining maximal frequent subgraphs. ACM Trans. Database Syst., 39(4):32:1–32:33, 2014.
[26] Y. LeCun, Y. Bengio, and G. Hinton. Deep learning. Nature, 521(7553):436–444, 2015.
[27] E. L. Lehmann and G. Casella. Theory of point estimation, volume 31. Springer, 1998.
[28] B. Milch, B. Marthi, S. J. Russell, D. Sontag, D. L. Ong, and A. Kolobov. Blog: Probabilistic models with unknown objects. In IJCAI, pages 1352–1359, 2005.
[29] M. Richardson and P. Domingos. Markov logic networks. Mach. Learn., 62(1-2):107–136, 2006.
[30] T. Sato and Y. Kameya. PRISM: A language for symbolic-statistical modeling. In IJCAI, pages 1330–1339, 1997.
[31] S. Shalev-Shwartz and S. Ben-David. Understanding Machine Learning: From Theory to Algorithms. Cambridge University Press, 2014.
[32] J. Shin, S. Wu, F. Wang, C. D. Sa, C. Zhang, and
C. R ́e. Incremental knowledge base construction using DeepDive. PVLDB, 8(11):1310–1321, 2015.
[33] V. Vapnik. An overview of statistical learning theory. IEEE Transactions on Neural Networks, 10(5):988–999, 1999.
[34] V. N. Vapnik and A. Y. Chervonenkis. On the uniform convergence of relative frequencies of events to their probabilities. Theory of Probability and its Applications, 16(2):264–280, 1971.
[35] M. J. Wainwright and M. I. Jordan. Graphical models, exponential families, and variational inference. Foundations and Trends in Machine Learning, 1(1-2):1–305, 2008.
[36] R. S. Zemel, Y. Wu, K. Swersky, T. Pitassi, and C. Dwork. Learning fair representations. In ICML, volume 28 of JMLR Proceedings, pages 325–333. JMLR.org, 2013.
[37] C. Zhang, A. Kumar, and C. RA ̃l’. Materialization optimizations for feature selection workloads. In SIGMOD Conference, pages 265–276, 2014.
