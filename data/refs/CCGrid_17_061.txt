[1] J. Dean et al., “Mapreduce: simplified data processing on large clusters,”
Communications of the ACM, vol. 51, no. 1, pp. 107–113, 2008.
[2] M. Isard et al., “Dryad: distributed data-parallel programs from sequential building blocks,” in ACM SIGOPS Operating Systems Review,
vol. 41, no. 3, 2007, pp. 59–72.
[3] M. Zaharia et al., “Resilient distributed datasets: A fault-tolerant abstraction for in-memory cluster computing,” in Proc. of the USENIX
NSDI 2012.
[4] “Flink,” https://flink.apache.org/.
[5] D. G. Murray et al., “Naiad: a timely dataflow system,” in Proc. of the
ACM SOSP 2013.
[6] X. Meng et al., “Mllib: Machine learning in apache spark,” JMLR,
vol. 17, no. 34, pp. 1–7, 2016.

[7] M. Abadi et al., “Tensorflow: Large-scale machine learning on heterogeneous distributed systems,” arXiv preprint arXiv:1603.04467, 2016.
[8] B. Hindman et al., “Mesos: A platform for fine-grained resource sharing
in the data center,” in Proc. of the USENIX NSDI 2011.
[9] M. Schwarzkopf et al., “Omega: Flexible, scalable schedulers for large
compute clusters,” in Proc. of the ACM EuroSys 2013.
[10] A. Verma et al., “Large-scale cluster management at Google with Borg,”
in Proc. of the EuroSys 2015.
[11] A. Goder et al., “Bistro: Scheduling data-parallel jobs against live
production systems,” in Proc. of the USENIX ATC 2015.
[12] T. Tannenbaum et al., “Beowulf cluster computing with linux,” 2002,
ch. Condor: A Distributed Job Scheduler.
[13] C. Delimitrou et al., “Hcloud: Resource-efficient provisioning in shared
cloud systems,” in Proc. of the ACM ASPLOS 2016.
[14] A. Kuzmanovska et al., “Koala-f: A resource manager for scheduling
frameworks in clusters,” in Proc. of the CCGrid 2016.
[15] C. Delimitrou et al., “Paragon: Qos-aware scheduling for heterogeneous
datacenters,” in Proc. of the ACM ASPLOS 2013.
[16] ——, “Quasar: Resource-efficient and qos-aware cluster management,”
in Proc. of the ACM ASPLOS 2014.
[17] M. Isard et al., “Quincy: fair scheduling for distributed computing
clusters,” in Proc. of the ACM SOSP 2009.
[18] K. Ousterhout et al., “Sparrow: distributed, low latency scheduling,” in
Proc. of the ACM SOSP 2013.
[19] C. Delimitrou et al., “Tarcil: Reconciling Scheduling Speed and Quality
in Large Shared Clusters,” in Proc. of the ACM SOCC 2015.
[20] B. Ghit et al., “Tyrex: Size-based resource allocation in mapreduce
frameworks,” in Proc. of the CCGrid 2016.
[21] V. K. Vavilapalli et al., “Apache hadoop yarn: Yet another resource
negotiator,” in Proc. of the ACM SoCC 2013.
[22] “Kubernetes,” http://kubernetes.io/.
[23] “Docker Swarm,” https://docs.docker.com/swarm/.
[24] C. Reiss et al., “Heterogeneity and dynamicity of clouds at scale: Google
trace analysis,” in Proc. of the SoCC 2012.
[25] “Google Public Traces,” https://github.com/google/cluster-data.
[26] “Spark,” http://spark.apache.org/.
[27] “TensorFlow,” https://www.tensorflow.org/.
[28] “Open MPI,” https://www.open-mpi.org/.
[29] M. Ragan-Kelley et al., “The jupyter/ipython architecture: a unified view
of computational research, from interactive exploration to communication and publication.” in AGU Fall Meeting Abstracts 2014, vol. 1.
[30] K. Pruhs et al., “Online scheduling,” Handbook of scheduling: algorithms, models, and performance analysis, pp. 15–1, 2004.