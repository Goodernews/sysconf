Research computing professionals rely on peer-reviewed conferences to publish their work and to receive feedback.
The impact of these peer-reviewed papers on researchers' careers can hardly be overstated. Yet conference organizers can make incompatible choices in their review process, even in the same subfield. These choices are rarely reviewed critically, and when they are, the emphasis revolves around the effects on the technical program, not the authors. In particular, the effects of conference policies on author experience and diversity are still not well understood.

As a first step toward addressing this knowledge gap, this paper presents a cross-sectional study of 56 conferences from one large subfield of research computing, namely computer systems. We introduce a large author survey (n=918), representing 809 unique papers. The goal of this paper is to expose this data and present an initial analysis of its findings. We primarily focus on quantitative relationships between the different survey questions, as well aswith information we collected on author demographics, conference policies, and paper statistics.  

Another focal point of this study is author diversity, especially in regards to gender and English proficiency. For the most part, these demographics exhibit no differences in their experience of the peer review process, suggesting no specific evidence of bias in single-blind reviews against women or non-native English speakers. Overall, we found poor gender and geographical author diversity but encouraging sector, experience, and English-proficiency diversity. We also found strong support for author rebuttal to reviewers' comments, especially among students and less experienced researchers, which may have implications for educators.
