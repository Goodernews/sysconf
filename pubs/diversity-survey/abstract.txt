Research computing professionals rely on peer-reviewed conferences to publish their work and to receive feedback on it.
The impact of these peer-reviewed papers on researchers' careers can hardly be overstated. Yet conference organizers can make inconsistent choices in their review process, even in the same subfield. These choices are rarely reviewed critically, and when they are, the emphasis revolves around the effects on the technical program, not the authors. In particular, the effects of conference policies on author experience and author diversity across are still not well understood.

As a first step toward address this problem, this paper presents a cross-sectional study of 56 conferences from one large subfield of research computing, namely computer systems. We introduce a large author survey (n=918), representing 810 unique papers. This data is combined with information we collected on author demographics, conference policies, and paper statistics.  The goal of this paper is to expose this data and present an initial analysis of its findings. We primarily analyze quantitative relationships between the different survey questions, as well as with the externally collected data.

A focal point of this study is author diversity. Our main results are negative, finding no specific evidence of bias in single-blind reviews against women or non-native English speakers. The subjective survey responses do, however, reveal small differences in the experience of these demographics. We also found strong support for author rebuttal to reviewers' comments, especially among students and less experienced researchers, which may have implications for educators.
