# Quantifying the Gender Gap {#sec:ratio}

```{r code = readLines("../load_data.R"), echo = F, cache = F, message = F}
```

We start our analysis by looking at the overall percentage of women across different conference roles. This paper focuses on authors, as the primary representatives of current researchers, but we also observe women's representation in service roles of the conferences, specifically:

 * program committee (PC) chairs, who coordinate the review activities.
 * PC members, who conduct most of the paper reviews and therefore have a direct influence on which papers get accepted.
 * Keynote speakers, panelists, and session chairs, who have no direct influence on the population of researchers, but represent the "face" of the conference to attendees, and by reputation, the leadership of its research population.

## Comparison Across Conference Roles

```{r pct-by-role, echo=F, cache=T, message=F}
repeated <- people_tidy %>%
  filter(!is.na(gender)) %>%
  mutate(role = factor(role, levels = c("author", "lead_author", "keynote", "panel", "chair", "pc", "session"))) %>%
 group_by(role) %>%
  summarize(pct_w = 100 * sum(gender=="F") / n()) %>%
  select(pct_w) %>%
  round(2)

unique <- lapply(c("as_author", "as_lead", "as_keynote", "as_panelist", "as_pc_chair", "as_pc", "as_session_chair"), function(role) {
                 filter(persons, !is.na(gender), get(role) > 0) %>%
                   summarize(pct_w = 100 * sum(gender == "F") / n()) %>%
                   round(2) })

tbl <- data.frame(Role = c("Author", "Lead author", "Keynote speaker", "Panelist", "PC chair", "PC member", "Session chair"),
                  Unique = unlist(unique),
                  Repeated = repeated$pct_w)

knitr::kable(tbl[c(1,5,6,3,4,7),], booktabs=TRUE, longtable=TRUE, align=c("r"),
             caption = "Percentage of women by role counting once per person (Unique) or once per appearance in role (Repeated).")

gender_table <- data.frame(female = c(nrow(filter(people_tidy, gender == "F", role == "author")), nrow(filter(people_tidy, gender == "F", role == "pc"))),
                             male = c(nrow(filter(people_tidy, gender == "M", role == "author")), nrow(filter(people_tidy, gender == "M", role == "pc"))),
                        row.names = c("authors", "PC members"))
```

Table \@ref(tab:pct-by-role) summarizes gender ratios in our dataset. The main observation we make is that women's representation among systems authors is particularly low, at about half or less than the rest of CS (Sec. \@ref(sec:intro)). The ratio of female authors is also significantly lower than the ratio of female PC members
(`r report_chi(chisq.test(gender_table))`).
It is not immediately clear why either difference should be so extreme, but we offer an in-depth exploration of these questions in Sec. \@ref(sec:discussion). The rest of the service roles also appear clustered in the range of 16%--20% women (with some higher variability for these smaller groups). The people in these roles are all selected by a small set of conference organizers, as opposed to authors who undergo blind peer review and compete for often low acceptance rates (averaging
`r round(100 * mean(all_confs$acceptance_rate, na.rm = T), 1)`%
in our dataset). The selection criteria for service roles can vary from conference to conference, and we discuss this variance in Sec. \@ref(sec:policies). For the rest of this section, however, we will focus on the two largest roles, who also most influence the research: the authors who produce it and the PC members who vet it.

A certain person can appear more than once in any given role. For example,
`r pct(nrow(filter(authors, as_author > 1)), nrow(authors), 2)`%
of authors are named in more than one paper. Counting authors one per paper or once per person could make a difference in the percentage of women if roles repeat differently across genders. We therefore computed the percentage of women across all roles with and without repetition, and found them to be very similar in our dataset. We also looked at authorship outliers, since these do vary significantly by gender [@huang19:historical]. For example, all
`r nrow(filter(authors, as_author > 7))`
authors with more than 7 papers in our dataset are men, and only
`r nrow(filter(authors, as_author > 4, gender=="F"))`
of the
`r nrow(filter(authors, as_author > 4))`
authors with more than 4 papers are women. But the total number of these outliers is small enough that removing them from our dataset would change women's representation by less than a percentage point. The effect of outliers on PC female representation is similarly small. We will therefore use the complete dataset of persons for the rest of this study (with repeats, unless otherwise noted).

Summarizing the distribution of women across roles with a single percentage can still hide significant variance. To better understand the distribution, we begin our exploration of sources of variance at the conference level.

## Comparison Across conferences

Fig. \@ref(fig:women-rep-author-vs-PC) shows the distributions of the percentage of women among authors and PC members by conference. Both distributions are long-tailed, meaning that a few conferences have an unusually larger female representation. But the majority of the conferences are centered around 10% female authors and 17% female PC members, approximately.

```{r women-rep-author-vs-PC, message = F, echo = F, cache = T, warning = F, fig.cap="Women's representation among authors and PC per conference."}
library(reshape2)
library(ggrepel)
library(cowplot)


data <- people_tidy %>%
  filter(!is.na(gender)) %>%
  group_by(role, conf) %>%
  summarize(pct_w = 100 * sum(gender=="F") / n()) %>%
  left_join(select(all_confs, c("conference", "npapers", "double_blind")), by = c("conf" = "conference")) %>%
  mutate(conf = as.factor(gsub("_\\d+", "", as.character(conf)))) %>%
  dcast(conf + npapers + double_blind ~ role, value.var = 'pct_w') %>%
  rename("PC" = "pc")

pmain <- data %>%
  ggplot(aes(x = PC, y = author, size = npapers, color=conf)) +
    geom_point(alpha = 0.5) +
    xlab("Percent women among PC members") +
    ylab("Percent women among authors") +
#    geom_smooth(method = "glm", se = F, show.legend = F) +
#    geom_rug(alpha=.2, sides="tr", size=1) +
    geom_text_repel(aes(label = conf), size=2.25) +
    guides(size = guide_legend(title = "Conference size (no. of papers)")) +
    scale_color_hue(guide = FALSE) +
    theme_minimal() +
    theme(legend.position = "bottom")

xdens <- axis_canvas(pmain, axis = "x") +
  geom_density(data = data, aes(x = PC), alpha = 0.7, size = 0.2)

ydens <- axis_canvas(pmain, axis = "y", coord_flip = T) +
  geom_density(data = data, aes(x = author), alpha = 0.7, size = 0.2) +
  coord_flip()

p1 <- insert_xaxis_grob(pmain, xdens, grid::unit(.2, "null"), position = "top")
p2 <- insert_yaxis_grob(p1, ydens, grid::unit(.2, "null"), position = "right")
ggdraw(p2)
```


Interestingly, this data suggests no correlation between the female author ratio and conference size
(`r report_cor(cor.test(data$author, data$npapers))`)
or ratio of women in the PC
(`r report_cor(cor.test(data$author, data$PC))`).
In fact, the ratio of women is not significantly correlated between any two roles, except between session chairs and PC members
(`r report_cor(cor.test(data$session, data$PC))`),
perhaps because the former group are typically selected from the latter group. We also looked at various conference policies such as diversity initiatives or double-blind reviews (Sec. \@ref(sec:policies)), but found no correlation to the ratio of female authors.

Since variance in female representation across conferences cannot be explained by conference size, policy, or representation in service roles, we next look at the topic, or systems sub-field, of each conference. 

## Comparison Across Subfields {#subsec:subfield-comparison}

TODO:

* Reorganize topics into 4-5 top-level

* Compare my conf data to [@cohoon11:cspapers]

* Compare to Taulbee: https://cra.org/crn/2012/09/taulbee_in-depth_phd_specialty_areas/

Compare (across all roles) to a case study of architecture: https://www.sigarch.org/gender-diversity-in-computer-architecture/

Topics may be the most important differentiator among conferences, because they represent different research communities with different gender characteristics, But they are also harder to define precisely. Additionally, conferences and even papers cannot always be easily delineated among topics, and there is a large degree of interdependence among topics. (In our systems dataset, nearly all conferences cite each other or their authors collaborate across all conferences, even if their research topics are distinct.)

Just like the gender representation statistics in the systems field can be starkly different than the rest of CS, so can be the different sub-fields within systems. To examine this variance, we skimmed every paper in our collection and tagged each with zero or more sub-field categories. We selected `r nrow(content_tags)` categories based on our experience in the field. Like the systems super-topic, the definition and scope of each sub-topic can be imprecise and controversial, as is the assignment of subtopics to each paper. We use this subjective method nevertheless as an approximation tool to better understand the trends in the field, rather than its precise statistics. A listing and brief explanation of the topics we selected can be found in Appendix B.

```{r women-rep-by-paper-topic, message = F, echo = F, cache = T, warning = F, fig.cap="Women's author representation by paper topic, ordered by percentage of women."}
gender_by_topic <- people_tidy %>%
  filter(role == "author", !is.na(gender)) %>%
  select(gender, key) %>%
  left_join(topics) %>%
  filter(!is.na(topic)) %>%
  group_by(topic) %>%
  summarize(Women = sum(gender == "F"), Men = sum(gender == "M"), pct_w = round(100 * sum(gender == "F") / n(), 2)) %>%
  melt(id.vars = c("topic", "pct_w")) %>%
  rename(Gender = variable) %>%
  rename(Count = value)

torder <- reorder(gender_by_topic$topic, gender_by_topic$pct_w)

gender_by_topic %>%
  ggplot(aes(x = factor(topic, levels = levels(torder)), y = Count, fill = forcats::fct_rev(Gender))) +
    geom_bar(stat = "identity") +
    geom_text(aes(x = topic, y = 1800, label = paste0('"', pct_w, '%"')), parse = TRUE) +
    scale_fill_manual(values = c("#C4AE5E", "#C7715F"), breaks = c("Women", "Men"), name = "Gender") +
    coord_flip() +
    theme_minimal() +
    ylab("Count and women's percentage") +
    xlab("Topic") +
    theme(legend.position = "bottom")
```

Fig. \@ref(fig:women-rep-by-paper-topic) shows the gender breakdown by topic. Although the sizes of the different interest groups vary by over 500%, the variance in women's relative representation is confined to a smaller range. It is nevertheless statistically significant around the extremes, such as between Data and Architecture 
(`r report_chi(chisq.test(data.frame(os = filter(gender_by_topic, topic == "Data")$Count, net = filter(gender_by_topic, topic == "Architecture")$Count)))`).
Keeping in mind that the definitions of these topics are somewhat imprecise and fluid, we can nevertheless try to generalize these differences by observing that the top-5 group ("Benchmark" through "Data") appears to concentrate more on software and users, whereas the bottom-10 group appears to concentrate more on hardware and machines. We will touch more on this distinction in Sec. \@ref(sec:discussion).

