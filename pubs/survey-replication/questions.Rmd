# Research Questions {#sec:questions}

Contains a mix of both replication questions and open questions. Replication questions look at published past results on peer review effects and attempts to replicate or refute these findings on our data set. Open questions look at some controversial questions on peer-review effects for which we found opinionated answers, but little or no prior studies.

## On double-blindness

\question{Does blinding affect the quality of the reviews?}{blind-quality}

(separate confounders like conference reputation). Does-double blind really help quality in any way?
How about non-blind review where reviewers "sign" their review?
Does it lead to more balanced geography/institution/gender bias?

 - https://jamanetwork.com/journals/jama/article-abstract/380957


\question{Does it lead to more citations?}{blind-citations}

Fit citations to conference reputation, then look at the residuals.

  - https://chairs-blog.acl2017.org/2017/03/02/arxiv-and-double-blind-reviewing-revisited/
  - https://2017.splashcon.org/track/splash-2017-OOPSLA#FAQ-on-Double-Blind-Reviewing
  - http://cra.org/statement-diversity-micro-50/
  - https://arxiv.org/pdf/1702.00502.pdf
  - http://www.cs.utexas.edu/users/mckinley/notes/blind-revised-2015.html
  - http://history.acm.org/pictures/tods/tods.acm.org/editorial.pdf
  - http://www.ncbi.nlm.nih.gov/pubmed/8015128
  - http://sc17.supercomputing.org/conference-overview/technical-papers/sc17-double-blind-review-policy/
  - https://publons.com/blog/who-is-using-open-peer-review/
  - http://www.cs.utexas.edu/users/mckinley/notes/blind-revised-2015.html
  - http://history.acm.org/pictures/tods/tods.acm.org/editorial.pdf
  - http://www.ncbi.nlm.nih.gov/pubmed/8015128
  - https://2017.splashcon.org/track/splash-2017-oopsla#FAQ-on-Double-Blind-Reviewing
  - https://www.sciencedirect.com/science/article/pii/S0169534707002704
  - https://scholarlykitchen.sspnet.org/2018/05/16/peer-review-autoers-reviewers-north-star/?informz=1
  - https://www.pnas.org/content/114/48/12708
  - https://arxiv.org/pdf/1802.02188.pdf
  - http://www.erinhengel.com/research/publishing_female.pdf
  - https://www.frontiersin.org/articles/10.3389/fnins.2015.00169/full
  - https://jamanetwork.com/journals/jama/article-abstract/376228


\question{Does blinding reduce the h-index of authors of accepted papers?}{blind-hindex}

  - https://www.usenix.org/sites/default/files/atc19_message.pdf

\question{Does double-blind at least bias less against junior faculty?}{blind-diversity}

fit author hindex against double-blind
What about country diversity? Sector diversity? Non-english speakers Low-prestige institutions? Content based? Other types of diversity?

  - https://www.frontiersin.org/articles/10.3389/fnins.2015.00169/full
  - https://www.researchgate.net/profile/Anthony_Tung/publication/220416127_Impact_of_double_blind_reviewing_on_SIGMOD_publication/links/55b8691d08ae9289a08d5678.pdf
  - https://arxiv.org/pdf/1802.02188.pdf
  - https://onlinelibrary.wiley.com/doi/full/10.1002/asi.22784
  - https://www.timeshighereducation.com/world-university-rankings/2019/world-ranking#!/page/0/length/25/sort_by/rank/sort_order/asc/cols/stats


--------------------------


## On review quality

\question{What is the relationship between review length and conference reputation?}{length-reputation}

  - https://publons.com/static/Publons-Global-State-Of-Peer-Review-2018.pdf

\question{How is review length related to quality?}{review-length}

  - http://retractionwatch.com/2017/11/27/make-reviews-public-says-peer-review-expert/


\question{Do authors "like" "kind" reviews?}{kind-reviews}

  - https://nlpers.blogspot.co.uk/2015/06/some-naacl-2013-statistics-on-author.html
  - [@anderson08:towards]
  - [@papagiannaki07:author]

\question{Problems and arbitrariness in peer review}{arbitrary}

  - http://blog.mrtz.org/2014/12/15/the-nips-experiment.html
  - https://cacm.acm.org/blogs/blog-cacm/181996-the-nips-experiment/fulltext
  - [@vardi09:conferences]
  - [@wallach11:rebooting]
  - [@vines11:cointoss]
  - https://scholarlykitchen.sspnet.org/2012/07/31/the-referee-that-wasnt-there-the-ghostly-tale-of-reviewer-3-3/
  - https://dl.acm.org/citation.cfm?id=1435430https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1420798/
  - ch. 5 of "women science and technology"
  - https://www.sigarch.org/r2-the-future-of-isca-or-not/
  - https://www.sigarch.org/a-common-standard-to-fix-our-review-process-and-oh-i-was-wrong-about-one-thing/
  - https://petsymposium.org/experiment.php


\question{Effect of review days on number of submissions or author author satisfaction}{review-days}

Authors want 3m or less for reviews

  - [@editage18:perspectives]
  - [@wallach11:rebooting]

\question{Does review time materially impact quality?}{time-quality}

Does it really take about 5/6 hours per review?
Most reviewers are done in 4 weeks

  - https://senseaboutscience.org/wp-content/uploads/2016/12/Peer_Review_Survey.pdf
  - https://www.sigmetrics.org/sigmetrics2017/SIGMETRICSInfoforAuthors.html)
  - http://www.ieee-security.org/TC/Reports/2017/SP2017-PCChairReport.pdf
  - https://cacm.acm.org/magazines/2009/5/24644-program-committee-overload-in-systems/abstract
  - https://publons.com/static/Publons-Global-State-Of-Peer-Review-2018.pdf
  - https://senseaboutscience.org/wp-content/uploads/2016/12/Peer_Review_Survey.pdf
  - http://www.ieee-security.org/TC/Reports/2017/SP2017-PCChairReport.pdf



\question{Effect of reviewer load}{reviewer-load}

  - [@beverly13:findings]

\question{Should we have post-publication review/comments?}{post-pub}

  - https://scholarlykitchen.sspnet.org/2013/03/27/how-rigorous-is-the-post-publication-review-process-at-f1000-research/
  - http://journals.plos.org/plosmedicine/article?id=10.1371/journal.pmed.1001772
  - https://link.springer.com/article/10.1007/s11948-016-9854-2
  - https://www.sciencedirect.com/science/article/pii/S016895251500044X
  - https://search.proquest.com/docview/1697484361?pq-origsite=gscholar

\question{Is a revision cycle effective?}{revision-cycle}

How long should it be?

  - http://www.ieee-security.org/TC/Reports/2017/SP2017-PCChairReport.pdf

\question{Open peer review--no one is doing it?}{open-peer}

  - http://www.nature.com/news/watch-out-for-cheats-in-citation-game-1.20246
  - http://www.nature.com/news/let-s-make-peer-review-scientific-1.20194

\question{Can we improve reviews from one venue to the next?}{improve-reviews}

  - https://www.nature.com/articles/546352a
  - https://www.sigarch.org/a-proposal-to-coordinate-reviewing-across-computer-architecture-conferences/

\question{How does the average number of reviews compare to other fields?}{reviews-num}

  - https://scholarlykitchen.sspnet.org/2018/09/12/guest-post-what-a-new-publons-report-on-peer-review-says-about-diversity-and-more/?informz=1

\question{Are reviews unfair?}{reviews-unfair}

  - https://www.sigarch.org/r2-the-future-of-isca-or-not/

\question{Effect of over-positive PC members}{positive-pc}

  - https://www.sigarch.org/overwhelming-statistical-evidence-that-our-review-process-is-broken/
  - https://www.sigarch.org/false-accepts-and-false-rejects/

\question{Does rebuttal/author response help?}{rebuttal-help}

Probably useless

  - https://chairs-blog.acl2017.org/2017/03/27/author-response-does-it-help/
  - https://nlpers.blogspot.co.uk/2015/06/some-naacl-2013-statistics-on-author.html
  - http://www.ieee-security.org/TC/Reports/2017/SP2017-PCChairReport.pdf
  - http://sc17.supercomputing.org/program/papers-faq/
  - https://www.sigops.org/sosp/sosp17/call-for-papers.html
  - https://www.sigarch.org/how-pc-chairs-and-pc-members-can-help-improve-our-process/
  - Dave Evans, CCS: "I think the author responses are valuable, even if they don't change paper decisions since (1) they make reviewers take the early reviews more seriously and know they risk being embarrassed if they say something incorrect/lazy, (2) they give authors a sense that they had an opportunity to respond, and (3) they help PC chairs decide if a paper needs additional reviews. I think the responses did change the outcomes of some papers for CCS - one for sure, that was considered dropped after the first round, but revived by the responses and eventually accepted, and for the borderline papers, the responses were considered seriously in making decisions (but can't know for sure how things would have gone without them). In some cases, the authors responses made it easier to reject papers since they made it clear that the problems reviewers found were legitimate, and a handful of papers were withdraw by the authors after seeing the early reviews.  We had a "Discussion Committee" that assigned a PC member to oversee each paper to ensure the reviewers took the author responses into consideration, which helped a lot since for a conference of this scale it would be too much for the PC chairs to check on all papers."

\question{Do reviewers want anonymity?}{reviewer-anon}

  - https://senseaboutscience.org/wp-content/uploads/2016/12/Peer_Review_Survey.pdf

\question{Effect of reviewer award on their own submission's grade?}{reviewer-award}

  - [Search references]

\question{Effect of shepherding, where known}{shepherd}

  - [Search references]

\question{Properties of "real" papers, based on Ulfar's email from 10/4/17}{real-papers}

  1) Reviewers are less likely to agree on "real" papers.
  2) Reviewers are less likely to state high confidence on "real" papers, especially if they're saying reject/strong reject.
  - [Search references]

\question{How does the average number of reviews compare to other fields?}{num-reviews}

  - https://scholarlykitchen.sspnet.org/2018/09/12/guest-post-what-a-new-publons-report-on-peer-review-says-about-diversity-and-more/?informz=1


--------------------------

## On conference quality

\question{What matters more for a conference: scope, review length, or impact factor?}{conf-metric}

  - https://www.editage.com/files/Editage-Global-Author-Survey.pdf
  - https://peerj.com/articles/365/#p-17

\question{Correlate everything with conference metrics and policies (features)}{conf-corr}
  
  - [Search references]

\question{Diversity of reviewers}{reviewer-diversity}

(first answer why diversity is needed). Also specifically when limited to HPC (look at whpc-summit paper)
  
  - https://scholarlykitchen.sspnet.org/2018/09/07/ask-the-chefs-diversity-in-peer-review/?informz=1
  - https://scholarlykitchen.sspnet.org/2018/09/13/eight-ways-to-tackle-diversity-and-inclusion-in-peer-review/?informz=1
  - https://www.nature.com/news/journals-invite-too-few-women-to-referee-1.21337

\question{Compare to other conferences}{conf-comp}

  - ATC'19  https://www.usenix.org/sites/default/files/atc19_message.pdf
  - Compare to SIGCOMM09  https://dl.acm.org/citation.cfm?id=1568623
  - What do authors in MICRO think about the review process?  https://www.sigmicro.org/2019/01/09/micro-survey-results/


\question{Quality is multi-dimensional}{quality-multidim}

https://scholarlykitchen.sspnet.org/2019/09/16/quality-is-multi-dimensional-how-many-ways-can-you-define-quality-in-peer-review/?unapproved=84111&moderation-hash=47b56366ddaf68dffef86ee501020c54#comment-84111

\question{Textual difference between 1st-version pre-print, last version, and published version}{ver-diff}

Not just similarity, but change in meaning

  - https://scholarlykitchen.sspnet.org/2018/03/15/a-comment-on-klein-et-als-comparing-articles-to-preprints/?informz=1

\question{Do authors aim for the highest possible venue that will still accept them?}{highest-venue}

Correlate conference prestige with no. of previous attempts.

  - https://scholarlykitchen.sspnet.org/2011/12/08/is-peer-review-a-coin-toss/

\question{Do two-cycle conferences lead to better papers? Is round-based reviewing better?}{two-cycle}

  - http://from-a-to-remzi.blogspot.com/2012/07/why-you-shouldnt-feel-too-badly-about.html

\question{Effect of submission Day-of-week and months-to-publish on submissions no. and acceptance rate}{day-of-week}

Correct for confounders, which you can find by plotting.

  - [Search references]

\question{Effect of "collisions" of multiple due dates next to each other, especially with similar paper topics}{collisions}

  - https://www.sigarch.org/r2-the-future-of-isca-or-not/

\question{Do conferences with strict data policies receive fewer submissions?}{data-policy}

  - https://scholarlykitchen.sspnet.org/2018/09/25/does-adopting-a-strict-data-sharing-policy-affect-submissions/?informz=1


--------------------------

## Misc

\question{What is the relationship between prior subs and conference quality?}{prior-subs-quality}


\question{Distribution of "paper readiness" and relationship to author experience}{paper-readiness}

  - http://www.ieee-security.org/TC/Reports/2017/SP2017-PCChairReport.pdf
  - https://www.nsf.gov/statistics/2018/nsb20181/assets/968/tables/tt05-18.pdf

\question{How is survey response rate affected by experience? acceptance?}{response-rate}

  - http://www.ieee-security.org/TC/Reports/2017/SP2017-PCChairReport.pdf
  - https://www.nsf.gov/statistics/2018/nsb20181/assets/968/tables/tt05-18.pdf

\question{Does submission order affect paper's chances?}{sub-order}

  - http://onlinelibrary.wiley.com/doi/10.1002/asi.22747/abstract

\question{Relationship between english mastery and presentation scores/overall scores}{english-present}

  - [previous paper]

\question{Compare "overall" average to confidence-weighted "overall" average}{confidence}

  - [Search references]

\question{Produce initial stats like these}{stats}

  - https://publons.com/community/gspr

\question{Explain negative correlation between prior_subs and gr_overall}{prior-overall}

  - [Search references]


\question{How to deal with publication bias?}{pub-bias}

  - https://www.nature.com/articles/s41562-016-0034
  - http://www.nature.com/news/let-s-think-about-cognitive-bias-1.18520
  - http://www.nature.com/news/how-scientists-fool-themselves-and-how-they-can-stop-1.18517
  - http://www.nature.com/news/tool-for-detecting-publication-bias-goes-under-spotlight-1.21728
  - http://www.nature.com/news/replication-studies-bad-copy-1.10634


\question{Predicting citations from reviews}{cites-reviews}

Hypothesis: high review scores and paper citations both measure some paper quality, and should therefore be correlated
Ignoring all other factors (some of which may be very useful, such as author metrics, conf metrics, paper topics, etc.)
Outcome variable: time to first citation, 1y, 2y citations.
Predictor variables: each review grade + award


----

